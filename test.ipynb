{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実行について\n",
    "上から順に実験コード前まで実行していきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目次\n",
    "\n",
    "- [誤差関数](#誤差関数)\n",
    "- [活性化関数](#活性化関数)\n",
    "- [最適化](#最適化)\n",
    "- [CNN util](#CNN-util)\n",
    "- [レイヤ](#レイヤ)\n",
    "- [レイヤマネージャ](#レイヤマネージャ)\n",
    "- [実験コード](#実験コード)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 誤差関数\n",
    "[目次へ戻る](#目次)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Error():\n",
    "    def __init__(self, *args, **kwds):\n",
    "        self.error = 0\n",
    "    \n",
    "    \n",
    "    def forward(self, *args, **kwds):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def backward(self, *args, **kwds):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def total_error(self, *args, **kwds):\n",
    "        return np.sum(self.error)/self.error.size\n",
    "\n",
    "\n",
    "class SquareError(Error):\n",
    "    def forward(self, y, t, *args, **kwds):\n",
    "        self.error = 0.5 * (y - t)**2\n",
    "        return self.error\n",
    "    \n",
    "    \n",
    "    def backward(self, y, t, *args, **kwds):\n",
    "        return y - t\n",
    "\n",
    "\n",
    "class BinaryCrossEntropy(Error):\n",
    "    def forward(self, y, t, *args, eps=1e-8, **kwds):\n",
    "        self.error = - t*np.log(y+eps) - (1 - t)*np.log(1-y+eps)\n",
    "        return self.error\n",
    "    \n",
    "    \n",
    "    def backward(self, y, t, *args, eps=1e-8, **kwds):\n",
    "        return (y - t) / (y*(1 - y) + eps)\n",
    "    \n",
    "\n",
    "class CrossEntropy(Error):\n",
    "    def forward(self, y, t, *args, eps=1e-8, **kwds):\n",
    "        self.error = - t*np.log(y+eps)\n",
    "        return self.error\n",
    "    \n",
    "    \n",
    "    def backward(self, y, t, *args, eps=1e-8, **kwds):\n",
    "        return - t/(y+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_err_dic = {\"Square\": SquareError,\n",
    "            \"Binary\": BinaryCrossEntropy,\n",
    "            \"Cross\": CrossEntropy,\n",
    "           }\n",
    "\n",
    "\n",
    "def get_err(name, *args, **kwds):\n",
    "    if name in _err_dic.keys():\n",
    "        errfunc = _err_dic[name](*args, **kwds)\n",
    "    else:\n",
    "        raise ValueError(name + \": Unknown error function\")\n",
    "\n",
    "    return errfunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 活性化関数\n",
    "[目次へ戻る](#目次)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Activator():\n",
    "    def __init__(self, *args, **kwds):\n",
    "        pass\n",
    "\n",
    "    def forward(self, *args, **kwds):\n",
    "        raise NotImplemented\n",
    "        #raise Exception(\"Not Implemented\")\n",
    "\n",
    "\n",
    "    def backward(self, *args, **kwds):\n",
    "        raise NotImplemented\n",
    "        #raise Exception(\"Not Implemented\")\n",
    "\n",
    "\n",
    "    def update(self, *args, **kwds):\n",
    "        raise NotImplemented\n",
    "        #pass\n",
    "\n",
    "\n",
    "class step(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return np.zeros_like(x)\n",
    "\n",
    "\n",
    "class identity(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return x\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return np.ones_like(x)\n",
    "\n",
    "\n",
    "class bentIdentity(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return 0.5*(np.sqrt(x**2 + 1) - 1) + x\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return 0.5*x/np.sqrt(x**2 + 1) + 1\n",
    "\n",
    "\n",
    "class hardShrink(Activator):\n",
    "    def __init__(self, lambda_=0.5, *args, **kwds):\n",
    "        self.lambda_ = lambda_\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return np.where((-self.lambda_ <= x) & (x <= self.lambda_), 0, x)\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return np.where((-self.lambda_ <= x) & (x <= self.lambda_), 0, 1)\n",
    "\n",
    "\n",
    "class softShrink(Activator):\n",
    "    def __init__(self, lambda_=0.5, *args, **kwds):\n",
    "        self.lambda_ = lambda_\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return np.where(x < -self.lambda_, x + self.lambda_,\n",
    "                        np.where(x > self.lambda_, x - self.lambda_, 0))\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return np.where((-self.lambda_ <= x) & (x <= self.lambda_), 0, 1)\n",
    "\n",
    "\n",
    "class threshold(Activator):\n",
    "    def __init__(self, threshold, value, *args, **kwds):\n",
    "        self.threshold = threshold\n",
    "        self.value = value\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return np.where(x > self.threshold, x, self.value)\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return np.where(x > self.threshold, 1, 0)\n",
    "\n",
    "\n",
    "class sigmoid(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "    def backward(self, x, y, *args, **kwds):\n",
    "        return y*(1 - y)\n",
    "\n",
    "\n",
    "class hardSigmoid(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return np.clip(0.2*x + 0.5, 0, 1)\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return np.where((x > 2.5) | (x < -2.5), 0, 0.2)\n",
    "\n",
    "\n",
    "class logSigmoid(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return -np.log(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return 1/(1 + np.exp(x))\n",
    "\n",
    "\n",
    "class act_tanh(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return np.tanh(x)\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return 1 - np.tanh(x)**2\n",
    "\n",
    "\n",
    "class hardtanh(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return np.clip(x, -1, 1)\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return np.where((-1 <= x) & (x <= 1), 1, 0)\n",
    "\n",
    "\n",
    "class tanhShrink(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return x - np.tanh(x)\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return np.tanh(x)**2\n",
    "\n",
    "\n",
    "class ReLU(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "\n",
    "class ReLU6(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return np.clip(x, 0, 6)\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return np.where((0 < x) & (x < 6), 1, 0)\n",
    "\n",
    "\n",
    "class leakyReLU(Activator):\n",
    "    def __init__(self, alpha=1e-2, *args, **kwds):\n",
    "        self.alpha = alpha\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return np.maximum(self.alpha * x, x)\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return np.where(x < 0, self.alpha, 1)\n",
    "\n",
    "\n",
    "class ELU(Activator):\n",
    "    def __init__(self, alpha=1., *args, **kwds):\n",
    "        self.alpha = alpha\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return np.where(x >= 0, x, self.alpha*(np.exp(x) - 1))\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return np.where(x >= 0, 1, self.alpha*np.exp(x))\n",
    "\n",
    "\n",
    "class SELU(Activator):\n",
    "    def __init__(self, lambda_=1.0507, alpha=1.67326, *args, **kwds):\n",
    "        self.lambda_ = lambda_\n",
    "        self.alpha = alpha\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return np.where(x >= 0, self.lambda_*x,\n",
    "                        self.lambda_*self.alpha*(np.exp(x)-1))\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return np.where(x >= 0, self.lambda_, self.lambda_*self.alpha*np.exp(x))\n",
    "\n",
    "\n",
    "class CELU(Activator):\n",
    "    def __init__(self, alpha=1., *args, **kwds):\n",
    "        self.alpha = alpha\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return np.where(x >= 0, x, self.alpha*(np.exp(x/self.alpha)-1))\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return np.where(x >= 0, 1, np.exp(x/self.alpha))\n",
    "\n",
    "\n",
    "class softmax(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        exp_x = np.exp(x-np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x/np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "    def backward(self, x, y, *args, **kwds):\n",
    "        return y*(1 - y)\n",
    "\n",
    "\n",
    "class softmin(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        exp_mx = np.exp(-x)\n",
    "        return exp_mx/np.sum(exp_mx, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "    def backward(self, x, y, *args, **kwds):\n",
    "        return -y*(1 - y)\n",
    "\n",
    "\n",
    "class logSoftmax(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        exp_x = np.exp(x)\n",
    "        return np.log(exp_x/np.sum(exp_x, axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "    def backward(self, x, y, *args, **kwds):\n",
    "        return 1 - np.exp(y)\n",
    "\n",
    "\n",
    "class softplus(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return np.logaddexp(x, 0)\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class softsign(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return x/(1 + np.abs(x))\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        return 1/(1 + np.abs(x))**2\n",
    "\n",
    "\n",
    "class Swish(Activator):\n",
    "    def __init__(self, beta=1, *args, **kwds):\n",
    "        self.beta = beta\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return x/(1 + np.exp(-self.beta*x))\n",
    "\n",
    "\n",
    "    def backward(self, x, y, *args, **kwds):\n",
    "        return self.beta*y + (1 - self.beta*y)/(1 + np.exp(-self.beta*x))\n",
    "\n",
    "\n",
    "    def d2y(self, x, *args, **kwds):\n",
    "        return (-0.25*self.beta*(self.beta*x*np.tanh(0.5*self.beta*x) - 2)\n",
    "                               *(1 - np.tanh(0.5*self.beta*x)**2))\n",
    "\n",
    "\n",
    "class Mish(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return x*np.tanh(np.logaddexp(x, 0))\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        omega = (4*(x + 1) + 4*np.exp(2*x)\n",
    "              + np.exp(3*x) + (4*x + 6)*np.exp(x))\n",
    "        delta = 2*np.exp(x) + np.exp(2*x) + 2\n",
    "        return np.exp(x)*omega/delta**2\n",
    "\n",
    "\n",
    "    def d2y(self, x, *args, **kwds):\n",
    "        omega = (2*(x + 2)\n",
    "                 + np.exp(x)*(np.exp(x)*(-2*np.exp(x)*(x - 1) - 3*x + 6)\n",
    "                              + 2*(x + 4)))\n",
    "        delta = np.exp(x)*(np.exp(x) + 2) + 2\n",
    "        return 4*np.exp(x)*omega/delta**3\n",
    "\n",
    "\n",
    "class tanhExp(Activator):\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        return x*np.tanh(np.exp(x))\n",
    "\n",
    "\n",
    "    def backward(self, x, *args, **kwds):\n",
    "        tanh_exp_x = np.tanh(np.exp(x))\n",
    "        return tanh_exp_x - x*np.exp(x)*(tanh_exp_x**2 - 1)\n",
    "\n",
    "\n",
    "    def d2y(self, x, *args, **kwds):\n",
    "        tanh_exp = np.tanh(np.exp(x))\n",
    "        return (np.exp(x)*(-x + 2*np.exp(x)*x*tanh_exp - 2)\n",
    "                         *(tanh_exp**2 - 1))\n",
    "\n",
    "\n",
    "class maxout(Activator):\n",
    "    def __init__(self, n_prev, n, k, wb_width=5e-2, *args, **kwds):\n",
    "        self.n_prev = n_prev\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.w = wb_width*np.random.rand((n_prev, n*k))\n",
    "        self.b = wb_width*np.random.rand(n*k)\n",
    "\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "\n",
    "    def forward(self, x, *args, **kwds):\n",
    "        self.x = x.copy()\n",
    "        self.z = np.dot(self.w.T, x) + self.b\n",
    "        self.z = self.z.reshape(self.n, self.k)\n",
    "        self.y = np.max(self.z, axis=1)\n",
    "        return self.y\n",
    "\n",
    "    def backward(self, g, *args, **kwds):\n",
    "        self.dw = np.sum(np.dot(self.w, self.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_act_dic = {\"step\": step,\n",
    "            \"identity\": identity,\n",
    "            \"bent-identity\": bentIdentity,\n",
    "            \"hard-shrink\": hardShrink,\n",
    "            \"soft-shrink\": softShrink,\n",
    "            \"threshold\": threshold,\n",
    "            \"sigmoid\": sigmoid,\n",
    "            \"hard-sigmoid\": hardSigmoid,\n",
    "            \"log-sigmoid\": logSigmoid,\n",
    "            \"tanh\": act_tanh,\n",
    "            \"tanh-shrink\": tanhShrink,\n",
    "            \"hard-tanh\":hardtanh,\n",
    "            \"ReLU\": ReLU,\n",
    "            \"ReLU6\": ReLU6,\n",
    "            \"leaky-ReLU\": leakyReLU,\n",
    "            \"ELU\": ELU,\n",
    "            \"SELU\": SELU,\n",
    "            \"CELU\": CELU,\n",
    "            \"softmax\": softmax,\n",
    "            \"softmin\": softmin,\n",
    "            \"log-softmax\": logSoftmax,\n",
    "            \"softplus\": softplus,\n",
    "            \"softsign\": softsign,\n",
    "            \"Swish\": Swish,\n",
    "            \"Mish\": Mish,\n",
    "            \"tanhExp\": tanhExp,\n",
    "           }\n",
    "\n",
    "\n",
    "def get_act(name, *args, **kwds):\n",
    "    if name in _act_dic.keys():\n",
    "        activator = _act_dic[name](*args, **kwds)\n",
    "    else:\n",
    "        raise ValueError(name + \": Unknown activator\")\n",
    "\n",
    "    return activator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適化\n",
    "[目次へ戻る](#目次)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Optimizer():\n",
    "    \"\"\"\n",
    "    最適化手法が継承するスーパークラス。\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwds):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def update(self, *args, **kwds):\n",
    "        pass\n",
    "\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, eta=1e-2, *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.eta = eta\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, *args, **kwds):\n",
    "        dw = -self.eta*grad_w\n",
    "        db = -self.eta*grad_b\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class MSGD(Optimizer):\n",
    "    def __init__(self, eta=1e-2, mu=0.9, *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.eta = eta\n",
    "        self.mu = mu\n",
    "\n",
    "        # 一つ前のステップの値を保持する\n",
    "        self.dw = 1e-8\n",
    "        self.db = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, *args, **kwds):\n",
    "        dw = self.mu*self.dw - (1-self.mu)*self.eta*grad_w\n",
    "        db = self.mu*self.db - (1-self.mu)*self.eta*grad_b\n",
    "\n",
    "        # コピーではなくビューで代入しているのは、これらの値が使われることはあっても\n",
    "        # 変更されることはないためです。\n",
    "        self.dw = dw\n",
    "        self.db = db\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class NAG(Optimizer):\n",
    "    def __init__(self, eta=1e-2, mu=0.9, *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.eta = eta\n",
    "        self.mu = mu\n",
    "\n",
    "        # 一つ前のステップの値を保持\n",
    "        self.dw = 1e-8\n",
    "        self.db = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, w=0, b=0, dfw=None, dfb=None,\n",
    "               nargs=2, *args, **kwds):\n",
    "        if nargs == 1:\n",
    "            grad_w = dfw(w + self.mu*self.dw)\n",
    "            grad_b = 1e-8\n",
    "        elif nargs == 2:\n",
    "            grad_w = dfw(w + self.mu*self.dw, b + self.mu*self.db)\n",
    "            grad_b = dfb(w + self.mu*self.dw, b + self.mu*self.db)\n",
    "\n",
    "        dw = self.mu*self.dw - (1-self.mu)*self.eta*grad_w\n",
    "        db = self.mu*self.db - (1-self.mu)*self.eta*grad_b\n",
    "\n",
    "        # コピーではなくビューで代入しているのは、これらの値が使われることはあっても\n",
    "        # 変更されることはないためです。\n",
    "        self.dw = dw\n",
    "        self.db = db\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class AdaGrad(Optimizer):\n",
    "    def __init__(self, eta=1e-3, *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.eta = eta\n",
    "\n",
    "        # 一つ前のステップの値を保持する\n",
    "        self.gw = 1e-8\n",
    "        self.gb = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, *args, **kwds):\n",
    "        self.gw += grad_w*grad_w\n",
    "        self.gb += grad_b*grad_b\n",
    "\n",
    "        dw = -self.eta*grad_w/np.sqrt(self.gw)\n",
    "        db = -self.eta*grad_b/np.sqrt(self.gb)\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class RMSprop(Optimizer):\n",
    "    def __init__(self, eta=1e-2, rho=0.99, eps=1e-8, *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.eta = eta\n",
    "        self.rho = rho\n",
    "        self.eps = eps\n",
    "\n",
    "        # 一つ前のステップの値を保持する\n",
    "        self.vw = 1e-8\n",
    "        self.vb = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, *args, **kwds):\n",
    "        self.vw += (1-self.rho)*(grad_w**2 - self.vw)\n",
    "        self.vb += (1-self.rho)*(grad_b**2 - self.vb)\n",
    "\n",
    "        dw = -self.eta*grad_w/np.sqrt(self.vw+self.eps)\n",
    "        db = -self.eta*grad_b/np.sqrt(self.vb+self.eps)\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class AdaDelta(Optimizer):\n",
    "    def __init__(self, rho=0.95, eps=1e-6, *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.rho = rho\n",
    "        self.eps = eps\n",
    "\n",
    "        # 一つ前のステップの値を保持する\n",
    "        self.vw = 1e-8\n",
    "        self.vb = 1e-8\n",
    "        self.uw = 1e-8\n",
    "        self.ub = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, *args, **kwds):\n",
    "        self.vw += (1-self.rho)*(grad_w**2 - self.vw)\n",
    "        self.vb += (1-self.rho)*(grad_b**2 - self.vb)\n",
    "\n",
    "        dw = -grad_w*np.sqrt(self.uw+self.eps)/np.sqrt(self.vw+self.eps)\n",
    "        db = -grad_b*np.sqrt(self.ub+self.eps)/np.sqrt(self.vb+self.eps)\n",
    "\n",
    "        self.uw += (1-self.rho)*(dw**2 - self.uw)\n",
    "        self.ub += (1-self.rho)*(db**2 - self.ub)\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class Adam(Optimizer):\n",
    "    def __init__(self, alpha=1e-3, beta1=0.9, beta2=0.999, eps=1e-8,\n",
    "                 *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "\n",
    "        # 一つ前のステップの値を保持する\n",
    "        self.mw = 1e-8\n",
    "        self.mb = 1e-8\n",
    "        self.vw = 1e-8\n",
    "        self.vb = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
    "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
    "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
    "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
    "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
    "\n",
    "        alpha_t = self.alpha*np.sqrt(1-self.beta2**t)/(1-self.beta1**t)\n",
    "\n",
    "        dw = -alpha_t*self.mw/(np.sqrt(self.vw+self.eps))\n",
    "        db = -alpha_t*self.mb/(np.sqrt(self.vb+self.eps))\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class RMSpropGraves(Optimizer):\n",
    "    def __init__(self, eta=1e-4, rho=0.95, eps=1e-4, *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.eta = eta\n",
    "        self.rho = rho\n",
    "        self.eps = eps\n",
    "\n",
    "        # 一つ前のステップの値を保持する\n",
    "        self.mw = 1e-8\n",
    "        self.mb = 1e-8\n",
    "        self.vw = 1e-8\n",
    "        self.vb = 1e-8\n",
    "\n",
    "\n",
    "    def update(self,grad_w, grad_b, *args, **kwds):\n",
    "        self.mw += (1-self.rho)*(grad_w - self.mw)\n",
    "        self.mb += (1-self.rho)*(grad_b - self.mb)\n",
    "        self.vw += (1-self.rho)*(grad_w**2 - self.vw)\n",
    "        self.vb += (1-self.rho)*(grad_b**2 - self.vb)\n",
    "\n",
    "        dw = -self.eta*grad_w/np.sqrt(self.vw - self.mw**2 + self.eps)\n",
    "        db = -self.eta*grad_b/np.sqrt(self.vb - self.mb**2 + self.eps)\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class SMORMS3(Optimizer):\n",
    "    def __init__(self, eta=1e-3, eps=1e-8, *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.eta = eta\n",
    "        self.eps = eps\n",
    "\n",
    "        # 一つ前のステップの値を保持する\n",
    "        self.zetaw = 1e-8\n",
    "        self.zetab = 1e-8\n",
    "        self.sw = 1\n",
    "        self.sb = 1\n",
    "        self.mw = 1e-8\n",
    "        self.mb = 1e-8\n",
    "        self.vw = 1e-8\n",
    "        self.vb = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, *args, **kwds):\n",
    "        rhow = 1/(1+self.sw)\n",
    "        rhob = 1/(1+self.sb)\n",
    "\n",
    "        self.mw += (1-rhow)*(grad_w - self.mw)\n",
    "        self.mb += (1-rhob)*(grad_b - self.mb)\n",
    "        self.vw += (1-rhow)*(grad_w**2 - self.vw)\n",
    "        self.vb += (1-rhob)*(grad_b**2 - self.vb)\n",
    "\n",
    "        self.zetaw = self.mw**2 / (self.vw + self.eps)\n",
    "        self.zetaw = self.mb**2 / (self.vb + self.eps)\n",
    "\n",
    "        dw = -grad_w*(np.minimum(self.eta, self.zetaw)\n",
    "                      /np.sqrt(self.vw + self.eps))\n",
    "        db = -grad_b*(np.minimum(self.eta, self.zetab)\n",
    "                      /np.sqrt(self.vb + self.eps))\n",
    "\n",
    "        self.sw = 1 + (1 - self.zetaw)*self.sw\n",
    "        self.sb = 1 + (1 - self.zetab)*self.sb\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class AdaMax(Optimizer):\n",
    "    def __init__(self, alpha=2e-3, beta1=0.9, beta2=0.999,\n",
    "                 *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "\n",
    "        # 一つ前のステップの値を保持する\n",
    "        self.mw = 1e-8\n",
    "        self.mb = 1e-8\n",
    "        self.uw = 1e-8\n",
    "        self.ub = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
    "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
    "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
    "        self.uw = np.maximum(self.beta2*self.uw, np.abs(grad_w))\n",
    "        self.ub = np.maximum(self.beta2*self.ub, np.abs(grad_b))\n",
    "\n",
    "        alpha_t = self.alpha/(1 - self.beta1**t)\n",
    "\n",
    "        dw = -alpha_t*self.mw/self.uw\n",
    "        db = -alpha_t*self.mb/self.ub\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class Nadam(Optimizer):\n",
    "    def __init__(self, alpha=2e-3, mu=0.975, nu=0.999, eps=1e-8,\n",
    "                 *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.mu = mu\n",
    "        self.nu = nu\n",
    "        self.eps = eps\n",
    "\n",
    "        # 一つ前のステップの値を保持する\n",
    "        self.mw = 1e-8\n",
    "        self.mb = 1e-8\n",
    "        self.vw = 1e-8\n",
    "        self.vb = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
    "        self.mw += (1-self.mu)*(grad_w - self.mw)\n",
    "        self.mb += (1-self.mu)*(grad_b - self.mb)\n",
    "        self.vw += (1-self.nu)*(grad_w**2 - self.vw)\n",
    "        self.vb += (1-self.nu)*(grad_b**2 - self.vb)\n",
    "\n",
    "        mhatw = (self.mu*self.mw/(1-self.mu**(t+1))\n",
    "                 + (1-self.mu)*grad_w/(1-self.mu**t))\n",
    "        mhatb = (self.mu*self.mb/(1-self.mu**(t+1))\n",
    "                 + (1-self.mu)*grad_b/(1-self.mu**t))\n",
    "        vhatw = self.nu*self.vw/(1-self.nu**t)\n",
    "        vhatb = self.nu*self.vb/(1-self.nu**t)\n",
    "\n",
    "        dw = -self.alpha*mhatw/np.sqrt(vhatw + self.eps)\n",
    "        db = -self.alpha*mhatb/np.sqrt(vhatb + self.eps)\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class Eve(Optimizer):\n",
    "    def __init__(self, alpha=1e-3, beta1=0.9, beta2=0.999, beta3=0.999,\n",
    "                 c=10, eps=1e-8, fstar=0, *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.beta3 = beta3\n",
    "        self.c = c\n",
    "        self.eps = eps\n",
    "\n",
    "        # 一つ前のステップの値を保持する\n",
    "        self.mw = 1e-8\n",
    "        self.mb = 1e-8\n",
    "        self.vw = 1e-8\n",
    "        self.vb = 1e-8\n",
    "        self.f = 0\n",
    "        self.fstar = fstar\n",
    "        self.dtilde_w = 1e-8\n",
    "        self.dtilde_b = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, t=1, f=1, *args, **kwds):\n",
    "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
    "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
    "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
    "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
    "\n",
    "        mhatw = self.mw/(1 - self.beta1**t)\n",
    "        mhatb = self.mb/(1 - self.beta1**t)\n",
    "        vhatw = self.vw/(1 - self.beta2**t)\n",
    "        vhatb = self.vb/(1 - self.beta2**t)\n",
    "\n",
    "        if t > 1:\n",
    "            d_w = (np.abs(f-self.fstar)\n",
    "                    /(np.minimum(f, self.f) - self.fstar))\n",
    "            d_b = (np.abs(f-self.fstar)\n",
    "                    /(np.minimum(f, self.f) - self.fstar))\n",
    "            dhat_w = np.clip(d_w, 1/self.c, self.c)\n",
    "            dhat_b = np.clip(d_b, 1/self.c, self.c)\n",
    "            self.dtilde_w += (1 - self.beta3)*(dhat_w - self.dtilde_w)\n",
    "            self.dtilde_b += (1 - self.beta3)*(dhat_b - self.dtilde_b)\n",
    "        else:\n",
    "            self.dtilde_w = 1\n",
    "            self.dtilde_b = 1\n",
    "\n",
    "        self.f = f\n",
    "\n",
    "        dw = -(self.alpha*mhatw\n",
    "               /(self.dtilde_w*(np.sqrt(vhatw) + self.eps)))\n",
    "        db = -(self.alpha*mhatb\n",
    "               /(self.dtilde_b*(np.sqrt(vhatb) + self.eps)))\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class SantaE(Optimizer):\n",
    "    def __init__(self, eta=1e-2, sigma=0.95, lambda_=1e-8,\n",
    "                 anne_func=lambda t, n: t**n, anne_rate=0.5,\n",
    "                 burnin=100, C=5, N=16,\n",
    "                 *args, **kwds):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            eta: Learning rate\n",
    "            sigma: Maybe in other cases;\n",
    "                    'rho' in RMSprop, AdaDelta, RMSpropGraves.\n",
    "                    'rhow' or 'rhob' in SMORMS3.\n",
    "                    'beta2' in Adam, Eve.\n",
    "                    'nu' in Nadam.\n",
    "                   To use calculation 'v'.\n",
    "            lambda_: Named 'eps'(ε) in other cases.\n",
    "            anne_func: Annealing function.\n",
    "                       To use calculation 'beta' at each timestep.\n",
    "                       Default is 'timestep'**'annealing rate'.\n",
    "                       The calculated value should be towards infinity\n",
    "                       as 't' increases.\n",
    "            anne_rate: Annealing rate.\n",
    "                       To use calculation 'beta' at each timestep.\n",
    "                       The second Argument of 'anne_func'.\n",
    "            burnin: Swith exploration and refinement.\n",
    "                    This should be specified by users.\n",
    "            C: To calculate first 'alpha'.\n",
    "            N: Number of minibatch.\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.eta = eta\n",
    "        self.sigma = sigma\n",
    "        self.lambda_ = lambda_\n",
    "        self.anne_func = anne_func\n",
    "        self.anne_rate = anne_rate\n",
    "        self.burnin = burnin\n",
    "        self.N = N\n",
    "\n",
    "        # Keep one step before and Initialize.\n",
    "        self.alpha_w = np.sqrt(eta)*C\n",
    "        self.alpha_b = np.sqrt(eta)*C\n",
    "        self.vw = 1e-8\n",
    "        self.vb = 1e-8\n",
    "        self.gw = 1e-8\n",
    "        self.gb = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
    "        try:\n",
    "            shape_w = grad_w.shape\n",
    "        except:\n",
    "            shape_w = (1, )\n",
    "        try:\n",
    "            shape_b = grad_b.shape\n",
    "        except:\n",
    "            shape_b = (1, )\n",
    "\n",
    "        if t == 1:\n",
    "            # Initialize uw, ub.\n",
    "            self.uw = np.sqrt(self.eta)*np.random.randn(*shape_w)\n",
    "            self.ub = np.sqrt(self.eta)*np.random.randn(*shape_b)\n",
    "\n",
    "        self.vw = (self.sigma*self.vw\n",
    "                   + grad_w*grad_w * (1 - self.sigma) / self.N**2)\n",
    "        self.vb = (self.sigma*self.vb\n",
    "                   + grad_b*grad_b * (1 - self.sigma) / self.N**2)\n",
    "\n",
    "        gw = 1/np.sqrt(self.lambda_ + np.sqrt(self.vw))\n",
    "        gb = 1/np.sqrt(self.lambda_ + np.sqrt(self.vb))\n",
    "\n",
    "        beta = self.anne_func(t, self.anne_rate)\n",
    "        if t < self.burnin:\n",
    "            # Exploration.\n",
    "            self.alpha_w += self.uw*self.uw - self.eta/beta\n",
    "            self.alpha_b += self.ub*self.ub - self.eta/beta\n",
    "\n",
    "            uw = (self.eta/beta * (1 - self.gw/gw)/self.uw\n",
    "                  + np.sqrt(2*self.eta/beta * self.gw)\n",
    "                  * np.random.randn(*shape_w))\n",
    "            ub = (self.eta/beta * (1 - self.gb/gb)/self.ub\n",
    "                  + np.sqrt(2*self.eta/beta * self.gb)\n",
    "                  * np.random.randn(*shape_b))\n",
    "        else:\n",
    "            # Refinement.\n",
    "            uw = 0\n",
    "            ub = 0\n",
    "\n",
    "        uw += (1 - self.alpha_w)*self.uw - self.eta*gw*grad_w\n",
    "        ub += (1 - self.alpha_b)*self.ub - self.eta*gb*grad_b\n",
    "\n",
    "        # Update values.\n",
    "        self.uw = uw\n",
    "        self.ub = ub\n",
    "        self.gw = gw\n",
    "        self.gb = gb\n",
    "\n",
    "        dw = gw*uw\n",
    "        db = gb*ub\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class SantaSSS(Optimizer):\n",
    "    def __init__(self, eta=1e-2, sigma=0.95, lambda_=1e-8,\n",
    "                 anne_func=lambda t, n: t**n, anne_rate=0.5,\n",
    "                 burnin=100, C=5, N=16,\n",
    "                 *args, **kwds):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            eta: Learning rate\n",
    "            sigma: Maybe in other cases;\n",
    "                    'rho' in RMSprop, AdaDelta, RMSpropGraves.\n",
    "                    'rhow' or 'rhob' in SMORMS3.\n",
    "                    'beta2' in Adam, Eve.\n",
    "                    'nu' in Nadam.\n",
    "                   To use calculation 'v'.\n",
    "            lambda_: Named 'eps'(ε) in other cases.\n",
    "            anne_func: Annealing function.\n",
    "                       To use calculation 'beta' at each timestep.\n",
    "                       Default is 'timestep'**'annealing rate'.\n",
    "                       The calculated value should be towards infinity\n",
    "                       as 't' increases.\n",
    "            anne_rate: Annealing rate.\n",
    "                       To use calculation 'beta' at each timestep.\n",
    "                       The second Argument of 'anne_func'.\n",
    "            burnin: Swith exploration and refinement.\n",
    "                    This should be specified by users.\n",
    "            C: To calculate first 'alpha'.\n",
    "            N: Number of minibatch.\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.eta = eta\n",
    "        self.sigma = sigma\n",
    "        self.lambda_ = lambda_\n",
    "        self.anne_func = anne_func\n",
    "        self.anne_rate = anne_rate\n",
    "        self.burnin = burnin\n",
    "        self.N = N\n",
    "\n",
    "        # Keep one step before and Initialize.\n",
    "        self.alpha_w = np.sqrt(eta)*C\n",
    "        self.alpha_b = np.sqrt(eta)*C\n",
    "        self.vw = 1e-8\n",
    "        self.vb = 1e-8\n",
    "        self.gw = 1e-8\n",
    "        self.gb = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
    "        try:\n",
    "            shape_w = grad_w.shape\n",
    "        except:\n",
    "            shape_w = (1, )\n",
    "        try:\n",
    "            shape_b = grad_b.shape\n",
    "        except:\n",
    "            shape_b = (1, )\n",
    "\n",
    "        if t == 1:\n",
    "            # Initialize uw, ub.\n",
    "            self.uw = np.sqrt(self.eta)*np.random.randn(*shape_w)\n",
    "            self.ub = np.sqrt(self.eta)*np.random.randn(*shape_b)\n",
    "\n",
    "        self.vw = (self.sigma*self.vw\n",
    "                   + grad_w*grad_w * (1 - self.sigma) / self.N**2)\n",
    "        self.vb = (self.sigma*self.vb\n",
    "                   + grad_b*grad_b * (1 - self.sigma) / self.N**2)\n",
    "\n",
    "        gw = 1/np.sqrt(self.lambda_ + np.sqrt(self.vw))\n",
    "        gb = 1/np.sqrt(self.lambda_ + np.sqrt(self.vb))\n",
    "\n",
    "        dw = 0.5*gw*self.uw\n",
    "        db = 0.5*gb*self.ub\n",
    "\n",
    "        beta = self.anne_func(t, self.anne_rate)\n",
    "        if t < self.burnin:\n",
    "            # Exploration.\n",
    "            self.alpha_w += (self.uw*self.uw - self.eta/beta)*0.5\n",
    "            self.alpha_b += (self.ub*self.ub - self.eta/beta)*0.5\n",
    "\n",
    "            uw = np.exp(-0.5*self.alpha_w)*self.uw\n",
    "            ub = np.exp(-0.5*self.alpha_b)*self.ub\n",
    "            uw += (-gw*grad_w*self.eta\n",
    "                        + np.sqrt(2*self.gw*self.eta/beta)\n",
    "                        * np.random.randn(*shape_w)\n",
    "                        + self.eta/beta*(1-self.gw/gw)/self.uw)\n",
    "            ub += (-gb*grad_b*self.eta\n",
    "                        + np.sqrt(2*self.gb*self.eta/beta)\n",
    "                        * np.random.randn(*shape_b)\n",
    "                        + self.eta/beta*(1-self.gb/gb)/self.ub)\n",
    "            uw *= np.exp(-0.5*self.alpha_w)\n",
    "            ub *= np.exp(-0.5*self.alpha_b)\n",
    "\n",
    "            self.alpha_w += (uw*uw - self.eta/beta)*0.5\n",
    "            self.alpha_b += (ub*ub - self.eta/beta)*0.5\n",
    "        else:\n",
    "            # Refinement.\n",
    "            uw = np.exp(-0.5*self.alpha_w)*self.uw\n",
    "            ub = np.exp(-0.5*self.alpha_b)*self.ub\n",
    "\n",
    "            uw -= gw*grad_w*self.eta\n",
    "            ub -= gb*grad_b*self.eta\n",
    "\n",
    "            uw *= np.exp(-0.5*self.alpha_w)\n",
    "            ub *= np.exp(-0.5*self.alpha_b)\n",
    "\n",
    "        # Update values.\n",
    "        self.uw = uw\n",
    "        self.ub = ub\n",
    "        self.gw = gw\n",
    "        self.gb = gb\n",
    "\n",
    "        dw = gw*uw*0.5\n",
    "        db = gb*ub*0.5\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class AMSGrad(Optimizer):\n",
    "    def __init__(self, alpha=1e-3, beta1=0.9, beta2=0.999, eps=1e-8,\n",
    "                 *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "\n",
    "        # 一つ前のステップの値を保持する\n",
    "        self.mw = 1e-8\n",
    "        self.mb = 1e-8\n",
    "        self.vw = 1e-8\n",
    "        self.vb = 1e-8\n",
    "        self.vhatw = 1e-8\n",
    "        self.vhatb = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
    "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
    "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
    "\n",
    "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
    "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
    "\n",
    "        self.vhatw = np.maximum(self.vhatw, self.vw)\n",
    "        self.vhatb = np.maximum(self.vhatb, self.vb)\n",
    "\n",
    "        alpha_t = self.alpha / np.sqrt(t)\n",
    "\n",
    "        dw = - alpha_t * self.mw/np.sqrt(self.vhatw + self.eps)\n",
    "        db = - alpha_t * self.mb/np.sqrt(self.vhatb + self.eps)\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class AdaBound(Optimizer):\n",
    "    def __init__(self, alpha=1e-3, eta=1e-1, beta1=0.9, beta2=0.999,\n",
    "                 eps=1e-8, *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.eta = eta\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "\n",
    "        # 一つ前のステップの値を保持する\n",
    "        self.mw = 1e-8\n",
    "        self.mb = 1e-8\n",
    "        self.vw = 1e-8\n",
    "        self.vb = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
    "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
    "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
    "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
    "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
    "\n",
    "        etal = self.eta*(1 - 1/((1-self.beta2)*t + 1))\n",
    "        etau = self.eta*(1 + 1/((1-self.beta2)*t + self.eps))\n",
    "\n",
    "        etahatw_t = np.clip(self.alpha/np.sqrt(self.vw), etal, etau)\n",
    "        etahatb_t = np.clip(self.alpha/np.sqrt(self.vb), etal, etau)\n",
    "\n",
    "        etaw_t = etahatw_t/np.sqrt(t)\n",
    "        etab_t = etahatb_t/np.sqrt(t)\n",
    "\n",
    "        dw = - etaw_t*self.mw\n",
    "        db = - etab_t*self.mb\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "\n",
    "class AMSBound(Optimizer):\n",
    "    def __init__(self, alpha=1e-3, eta=1e-1, beta1=0.9, beta2=0.999,\n",
    "                 eps=1e-8, *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.eta = eta\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "\n",
    "        # 一つ前のステップの値を保持する\n",
    "        self.mw = 1e-8\n",
    "        self.mb = 1e-8\n",
    "        self.vw = 1e-8\n",
    "        self.vb = 1e-8\n",
    "        self.vhatw = 1e-8\n",
    "        self.vhatb = 1e-8\n",
    "\n",
    "\n",
    "    def update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
    "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
    "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
    "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
    "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
    "        self.vhatw = np.maximum(self.vhatw, self.vw)\n",
    "        self.vhatb = np.maximum(self.vhatb, self.vb)\n",
    "\n",
    "        etal = self.eta*(1 - 1/((1-self.beta2)*t + 1))\n",
    "        etau = self.eta*(1 + 1/((1-self.beta2)*t + self.eps))\n",
    "\n",
    "        etahatw_t = np.clip(self.alpha/np.sqrt(self.vhatw), etal, etau)\n",
    "        etahatb_t = np.clip(self.alpha/np.sqrt(self.vhatb), etal, etau)\n",
    "\n",
    "        etaw_t = etahatw_t/np.sqrt(t)\n",
    "        etab_t = etahatb_t/np.sqrt(t)\n",
    "\n",
    "        dw = - etaw_t*self.mw\n",
    "        db = - etab_t*self.mb\n",
    "\n",
    "        return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_opt_dic = {\n",
    "    \"SGD\": SGD,\n",
    "    \"MSGD\": MSGD,\n",
    "    \"NAG\": NAG,\n",
    "    \"AdaGrad\": AdaGrad,\n",
    "    \"RMSprop\": RMSprop,\n",
    "    \"AdaDelta\": AdaDelta,\n",
    "    \"Adam\": Adam,\n",
    "    \"RMSpropGraves\": RMSpropGraves,\n",
    "    \"SMORMS3\": SMORMS3,\n",
    "    \"AdaMax\": AdaMax,\n",
    "    \"Nadam\": Nadam,\n",
    "    \"Eve\": Eve,\n",
    "    \"SantaE\": SantaE,\n",
    "    \"SantaSSS\": SantaSSS,\n",
    "    \"AMSGrad\": AMSGrad,\n",
    "    \"AdaBound\": AdaBound,\n",
    "    \"AMSBound\": AMSBound,\n",
    "}\n",
    "\n",
    "\n",
    "def get_opt(name, *args, **kwds):\n",
    "    if name in _opt_dic.keys():\n",
    "        optimizer = _opt_dic[name](*args, **kwds)\n",
    "    else:\n",
    "        raise ValueError(name + \": Unknown optimizer\")\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN util\n",
    "[目次へ戻る](#目次)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def im2col(images, filters, stride=1, pad=0):\n",
    "    if images.ndim == 2:\n",
    "        images = images.reshape(1, 1, *images.shape)\n",
    "    elif images.ndim == 3:\n",
    "        B, I_h, I_w = images.shape\n",
    "        images = images.reshape(B, 1, I_h, I_w)\n",
    "    B, C, I_h, I_w = images.shape\n",
    "    if isinstance(filters, tuple):\n",
    "        if len(filters) == 2:\n",
    "            filters = (1, 1, *filters)\n",
    "        elif len(filters) == 3:\n",
    "            M, F_h, F_w = filters\n",
    "            filters = (M, 1, F_h, F_w)\n",
    "        _, _, F_h, F_w = filters\n",
    "    else:\n",
    "        if filters.ndim == 2:\n",
    "            filters = filters.reshape(1, 1, *filters.shape)\n",
    "        elif filters.ndim == 3:\n",
    "            M, F_h, F_w = filters.shape\n",
    "            filters = filters.reshape(M, 1, F_h, F_w)\n",
    "        _, _, F_h, F_w = filters.shape\n",
    "    \n",
    "    if isinstance(stride, tuple):\n",
    "        stride_ud, stride_lr = stride\n",
    "    else:\n",
    "        stride_ud = stride\n",
    "        stride_lr = stride\n",
    "    if isinstance(pad, tuple):\n",
    "        pad_ud, pad_lr = pad\n",
    "    elif isinstance(pad, int):\n",
    "        pad_ud = pad\n",
    "        pad_lr = pad\n",
    "    elif pad == \"same\":\n",
    "        pad_ud = 0.5*((I_h - 1)*stride_ud - I_h + F_h)\n",
    "        pad_lr = 0.5*((I_w - 1)*stride_lr - I_w + F_w)\n",
    "    pad_zero = (0, 0)\n",
    "    \n",
    "    def get_O_shape(i, f, s, p):\n",
    "        return int((i - f + 2*p)//s + 1)\n",
    "    \n",
    "    O_h = get_O_shape(I_h, F_h, stride_ud, pad_ud)\n",
    "    O_w = get_O_shape(I_w, F_w, stride_lr, pad_lr)\n",
    "    \n",
    "    result_pad = (pad_ud, pad_lr)\n",
    "    pad_ud = int(np.ceil(pad_ud))\n",
    "    pad_lr = int(np.ceil(pad_lr))\n",
    "    pad_ud = (pad_ud, pad_ud)\n",
    "    pad_lr = (pad_lr, pad_lr)\n",
    "    images = np.pad(images, [pad_zero, pad_zero, pad_ud, pad_lr], \\\n",
    "                    \"constant\")\n",
    "    \n",
    "    cols = np.empty((B, C, F_h, F_w, O_h, O_w))\n",
    "    for h in range(F_h):\n",
    "        h_lim = h + stride_ud*O_h\n",
    "        for w in range(F_w):\n",
    "            w_lim = w + stride_lr*O_w\n",
    "            cols[:, :, h, w, :, :] \\\n",
    "                = images[:, :, h:h_lim:stride_ud, w:w_lim:stride_lr]\n",
    "    \n",
    "    results = []\n",
    "    results.append(cols.transpose(1, 2, 3, 0, 4, 5).reshape(C*F_h*F_w, B*O_h*O_w))\n",
    "    results.append((O_h, O_w))\n",
    "    results.append(result_pad)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def col2im(cols, I_shape, O_shape, stride=1, pad=0):\n",
    "    def get_f_shape(i, o, s, p):\n",
    "        return int(i + 2*p - (o - 1)*s)\n",
    "    \n",
    "    if len(I_shape) == 2:\n",
    "        B, C, I_h, I_w = 1, 1, *I_shape\n",
    "    elif len(I_shape) == 3:\n",
    "        C, B, I_h, I_w = 1, *I_shape\n",
    "    else:\n",
    "        B, C, I_h, I_w = I_shape\n",
    "    M, O_h, O_w = O_shape\n",
    "    \n",
    "    if isinstance(stride, tuple):\n",
    "        stride_ud, stride_lr = stride\n",
    "    else:\n",
    "        stride_ud = stride\n",
    "        stride_lr = stride\n",
    "    if isinstance(pad, tuple):\n",
    "        pad_ud, pad_lr = pad\n",
    "    elif isinstance(pad, int):\n",
    "        pad_ud = pad\n",
    "        pad_lr = pad\n",
    "    \n",
    "    F_h = get_f_shape(I_h, O_h, stride_ud, pad_ud)\n",
    "    F_w = get_f_shape(I_w, O_w, stride_lr, pad_lr)\n",
    "    pad_ud = int(np.ceil(pad_ud))\n",
    "    pad_lr = int(np.ceil(pad_lr))\n",
    "    cols = cols.reshape(C, F_h, F_w, B, O_h, O_w).transpose(3, 0, 1, 2, 4, 5)\n",
    "    images = np.zeros((B, C, I_h+2*pad_ud+stride_ud-1, I_w+2*pad_lr+stride_lr-1))\n",
    "    \n",
    "    for h in range(F_h):\n",
    "        h_lim = h + stride_ud*O_h\n",
    "        for w in range(F_w):\n",
    "            w_lim = w + stride_lr*O_w\n",
    "            images[:, :, h:h_lim:stride_ud, w:w_lim:stride_lr] += cols[:, :, h, w, :, :]\n",
    "    \n",
    "    return images[:, :, pad_ud : I_h+pad_ud, pad_lr : I_w+pad_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# レイヤ\n",
    "[目次へ戻る](#目次)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class BaseLayer():\n",
    "    \"\"\"\n",
    "    全ての元となるレイヤークラス\n",
    "    中間層と出力層で共通する処理を記述する。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *, prev=1, n=1,\n",
    "                 name=\"\", wb_width=5e-2,\n",
    "                 act=\"ReLU\", opt=\"Adam\",\n",
    "                 act_dic=None, opt_dic=None, **kwds):\n",
    "        if act_dic is None:\n",
    "            act_dic = {}\n",
    "        if opt_dic is None:\n",
    "            opt_dic = {}\n",
    "        \n",
    "        self.prev = prev  # 一つ前の層の出力数 = この層への入力数\n",
    "        self.n = n        # この層の出力数 = 次の層への入力数\n",
    "        self.name = name  # この層の名前\n",
    "\n",
    "        # 重みとバイアスを設定\n",
    "        self.w = wb_width*np.random.randn(prev, n)\n",
    "        self.b = wb_width*np.random.randn(n)\n",
    "\n",
    "        # 活性化関数(クラス)を取得\n",
    "        self.act = get_act(act, **act_dic)\n",
    "\n",
    "        # 最適化子(クラス)を取得\n",
    "        self.opt = get_opt(opt, **opt_dic)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        順伝播の実装\n",
    "        \"\"\"\n",
    "        # 入力を記憶しておく\n",
    "        self.x = x.copy()\n",
    "\n",
    "        # 順伝播\n",
    "        self.u = x@self.w + self.b\n",
    "        self.y = self.act.forward(self.u)\n",
    "        \n",
    "        return self.y\n",
    "\n",
    "\n",
    "    def backward(self, grad):\n",
    "        \"\"\"\n",
    "        逆伝播の実装\n",
    "        \"\"\"\n",
    "        dact = grad*self.act.backward(self.u, self.y)\n",
    "        self.grad_w = self.x.T@dact\n",
    "        self.grad_b = np.sum(dact, axis=0)\n",
    "        self.grad_x = dact@self.w.T\n",
    "\n",
    "        return self.grad_x\n",
    "\n",
    "\n",
    "    def update(self, **kwds):\n",
    "        \"\"\"\n",
    "        パラメータ学習の実装\n",
    "        \"\"\"\n",
    "        dw, db = self.opt.update(self.grad_w, self.grad_b, **kwds)\n",
    "\n",
    "        self.w += dw\n",
    "        self.b += db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class MiddleLayer(BaseLayer):\n",
    "    \"\"\"\n",
    "    中間層クラス\n",
    "    入力層も実装上は中間層の一つとして取り扱います。\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "softmax = type(get_act(\"softmax\"))\n",
    "sigmoid = type(get_act(\"sigmoid\"))\n",
    "cross = type(get_err(\"Cross\"))\n",
    "binary = type(get_err(\"Binary\"))\n",
    "\n",
    "\n",
    "class OutputLayer(BaseLayer):\n",
    "    \"\"\"\n",
    "    出力層クラス\n",
    "    \"\"\"\n",
    "    def __init__(self, *, err_func=\"Square\", **kwds):\n",
    "        # 損失関数(クラス)を取得\n",
    "        self.errfunc = get_err(err_func)\n",
    "\n",
    "        super().__init__(**kwds)\n",
    "    \n",
    "\n",
    "    def backward(self, t):\n",
    "        \"\"\"\n",
    "        逆伝播の実装\n",
    "        \"\"\"\n",
    "        # 出力層の活性化関数がsoftmax関数で損失関数が交差エントロピー誤差の場合\n",
    "        # 誤差の伝播を場合分けしておく\n",
    "        if isinstance(self.act, softmax) \\\n",
    "        and isinstance(self.errfunc, cross):\n",
    "            dact = self.y - t\n",
    "            self.grad_w = self.x.T@dact\n",
    "            self.grad_b = np.sum(dact, axis=0)\n",
    "            self.grad_x = dact@self.w.T\n",
    "\n",
    "            return self.grad_x\n",
    "        elif isinstance(self.act, sigmoid) \\\n",
    "         and isinstance(self.errfunc, binary):\n",
    "            dact = self.y - t\n",
    "            self.grad_w = self.x.T@dact\n",
    "            self.grad_b = np.sum(dact, axis=0)\n",
    "            self.grad_x = dact@self.w.T\n",
    "\n",
    "            return self.grad_x\n",
    "        else:\n",
    "            grad = self.errfunc.backward(self.y, t)\n",
    "            return super().backward(grad)\n",
    "\n",
    "\n",
    "    def get_error(self, t):\n",
    "        self.error = self.errfunc.forward(self.y, t) / t.shape[0]\n",
    "        return self.errfunc.total_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class ConvLayer(BaseLayer):\n",
    "    def __init__(self, *, I_shape=None, F_shape=None,\n",
    "                 stride=1, pad=\"same\",\n",
    "                 name=\"\", wb_width=5e-2,\n",
    "                 act=\"ReLU\", opt=\"Adam\",\n",
    "                 act_dic={}, opt_dic={}, **kwds):\n",
    "        self.name = name\n",
    "        \n",
    "        if I_shape is None:\n",
    "            raise KeyError(\"Input shape is None.\")\n",
    "        if F_shape is None:\n",
    "            raise KeyError(\"Filter shape is None.\")\n",
    "        \n",
    "        if len(I_shape) == 2:\n",
    "            C, I_h, I_w = 1, *I_shape\n",
    "        else:\n",
    "            C, I_h, I_w = I_shape\n",
    "        self.I_shape = (C, I_h, I_w)\n",
    "        \n",
    "        if len(F_shape) == 2:\n",
    "            M, F_h, F_w = 1, *F_shape\n",
    "        else:\n",
    "            M, F_h, F_w = F_shape\n",
    "        self.F_shape = (M, C, F_h, F_w)\n",
    "        \n",
    "        _, O_shape, self.pad_state = im2col(np.zeros((1, *self.I_shape)), self.F_shape,\n",
    "                                            stride=stride, pad=pad)\n",
    "        self.O_shape = (M, *O_shape)\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.n = np.prod(self.O_shape)\n",
    "        \n",
    "        # フィルタとバイアスを設定\n",
    "        self.w = wb_width*np.random.randn(*self.F_shape).reshape(M, -1).T\n",
    "        self.b = wb_width*np.random.randn(M)\n",
    "        \n",
    "        # 活性化関数(クラス)を取得\n",
    "        self.act = get_act(act, **act_dic)\n",
    "\n",
    "        # 最適化子(クラス)を取得\n",
    "        self.opt = get_opt(opt, **opt_dic)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        M, O_h, O_w = self.O_shape\n",
    "        \n",
    "        x, _, self.pad_state = im2col(x, self.F_shape,\n",
    "                                      stride=self.stride,\n",
    "                                      pad=self.pad_state)\n",
    "        super().forward(x.T)\n",
    "        return self.y.reshape(B, O_h, O_w, M).transpose(0, 3, 1, 2)\n",
    "    \n",
    "    \n",
    "    def backward(self, grad):\n",
    "        B = grad.shape[0]\n",
    "        I_shape = B, *self.I_shape\n",
    "        M, O_h, O_w = self.O_shape\n",
    "        \n",
    "        grad = grad.transpose(0, 2, 3, 1).reshape(-1, M)\n",
    "        super().backward(grad)\n",
    "        self.grad_x = col2im(self.grad_x.T, I_shape, self.O_shape,\n",
    "                             stride=self.stride, pad=self.pad_state)\n",
    "        return self.grad_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class PoolingLayer(BaseLayer):\n",
    "    def __init__(self, *, I_shape=None,\n",
    "                 pool=1, pad=0,\n",
    "                 name=\"\", **kwds):\n",
    "        self.name = name\n",
    "        \n",
    "        if I_shape is None:\n",
    "            raise KeyError(\"Input shape is None.\")\n",
    "        \n",
    "        if len(I_shape) == 2:\n",
    "            C, I_h, I_w = 1, *I_shape\n",
    "        else:\n",
    "            C, I_h, I_w = I_shape\n",
    "        self.I_shape = (C, I_h, I_w)\n",
    "        \n",
    "        _, O_shape, self.pad_state = im2col(np.zeros((1, *self.I_shape)), (pool, pool),\n",
    "                                            stride=pool, pad=pad)\n",
    "        self.O_shape = (C, *O_shape)\n",
    "        \n",
    "        self.n = np.prod(self.O_shape)\n",
    "        \n",
    "        self.pool = pool\n",
    "        self.F_shape = (pool, pool)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        C, O_h, O_w = self.O_shape\n",
    "        \n",
    "        self.x, _, self.pad_state = im2col(x, self.F_shape,\n",
    "                                           stride=self.pool,\n",
    "                                           pad=self.pad_state)\n",
    "        \n",
    "        self.x = self.x.T.reshape(B*O_h*O_w*C, -1)\n",
    "        self.max_index = np.argmax(self.x, axis=1)\n",
    "        self.y = np.max(self.x, axis=1).reshape(B, O_h, O_w, C).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return self.y\n",
    "    \n",
    "    \n",
    "    def backward(self, grad):\n",
    "        B = grad.shape[0]\n",
    "        I_shape = B, *self.I_shape\n",
    "        C, O_h, O_w = self.O_shape\n",
    "        \n",
    "        grad = grad.transpose(0, 2, 3, 1).reshape(-1, 1)\n",
    "        self.grad_x = np.zeros((grad.size, self.pool*self.pool))\n",
    "        self.grad_x[:, self.max_index] = grad\n",
    "        self.grad_x = self.grad_x.reshape(B*O_h*O_w, C*self.pool*self.pool).T\n",
    "        self.grad_x = col2im(self.grad_x, I_shape, self.O_shape,\n",
    "                             stride=self.pool, pad=self.pad_state)\n",
    "        \n",
    "        return self.grad_x\n",
    "    \n",
    "    \n",
    "    def update(self, **kwds):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# レイヤマネージャ\n",
    "[目次へ戻る](#目次)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerManagerError(Exception):\n",
    "    \"\"\"レイヤーモジュールにおけるユーザ定義エラーのベースクラス\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class AssignError(LayerManagerError):\n",
    "    def __init__(self, value=None):\n",
    "        if not value is None:\n",
    "            self.value = value\n",
    "            self.message = (str(value)\n",
    "                         + \": Assigning that value is prohibited.\")\n",
    "        else:\n",
    "            self.value = None\n",
    "            self.message = \"Assigning that value is prohibited.\"\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.message\n",
    "\n",
    "\n",
    "class UnmatchUnitError(LayerManagerError):\n",
    "    def __init__(self, prev, n):\n",
    "        self.prev = prev\n",
    "        self.n = n\n",
    "\n",
    "        self.message = \"Unmatch units: <{}> and <{}>.\".format(prev, n)\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.message\n",
    "\n",
    "\n",
    "class UndefinedLayerError(LayerManagerError):\n",
    "    def __init__(self, type_name):\n",
    "        self.type = type_name\n",
    "        self.message = \"<{}>: Undefined layer type.\".format(str(type_name))\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TypeManager():\n",
    "    \"\"\"\n",
    "    層の種類に関するマネージャクラス\n",
    "    \"\"\"\n",
    "    N_TYPE = 4  # 層の種類数\n",
    "\n",
    "    BASE = -1\n",
    "    MIDDLE = 0  # 中間層のナンバリング\n",
    "    OUTPUT = 1  # 出力層のナンバリング\n",
    "    CONV = 2    #畳み込み層のナンバリング\n",
    "    POOL = 3    #プーリング層のナンバリング\n",
    "    \n",
    "    REGULATED_DIC = {\"Middle\": MiddleLayer,\n",
    "                     \"Output\": OutputLayer,\n",
    "                     \"Conv\": ConvLayer,\n",
    "                     \"Pool\": PoolingLayer,\n",
    "                     \"BaseLayer\": None}\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def reg_keys(self):\n",
    "        return list(self.REGULATED_DIC.keys())\n",
    "    \n",
    "    \n",
    "    def name_rule(self, name):\n",
    "        name = name.lower()\n",
    "        if \"middle\" in name or name == \"mid\" or name == \"m\":\n",
    "            name = self.reg_keys[self.MIDDLE]\n",
    "        elif \"output\" in name or name == \"out\" or name == \"o\":\n",
    "            name = self.reg_keys[self.OUTPUT]\n",
    "        elif \"conv\" in name or name == \"c\":\n",
    "            name = self.reg_keys[self.CONV]\n",
    "        elif \"pool\" in name or name == \"p\":\n",
    "            name = self.reg_keys[self.POOL]\n",
    "        else:\n",
    "            raise UndefinedLayerError(name)\n",
    "        \n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = type(get_act(\"softmax\"))\n",
    "sigmoid = type(get_act(\"sigmoid\"))\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, x, y):\n",
    "        self.x_train, self.x_test = x\n",
    "        self.y_train, self.y_test = y\n",
    "        \n",
    "        self.make_anim = False\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "        n_batch = x.shape[0]\n",
    "        switch = True\n",
    "        for ll in self.layer_list:\n",
    "            if switch and not self.is_CNN(ll.name):\n",
    "                x_in = x_in.reshape(n_batch, -1)\n",
    "                switch = False\n",
    "            x_in = ll.forward(x_in)\n",
    "    \n",
    "    \n",
    "    def backward(self, t):\n",
    "        y_in = t\n",
    "        n_batch = t.shape[0]\n",
    "        switch = True\n",
    "        for ll in self.layer_list[::-1]:\n",
    "            if switch and self.is_CNN(ll.name):\n",
    "                y_in = y_in.reshape(n_batch, *ll.O_shape)\n",
    "                switch = False\n",
    "            y_in = ll.backward(y_in)\n",
    "    \n",
    "    \n",
    "    def update(self, **kwds):\n",
    "        for ll in self.layer_list:\n",
    "            ll.update(**kwds)\n",
    "    \n",
    "    \n",
    "    def training(self, epoch, n_batch=16, threshold=1e-8,\n",
    "                 show_error=True, show_train_error=False, **kwds):\n",
    "        if show_error:\n",
    "            self.error_list = []\n",
    "        if show_train_error:\n",
    "            self.train_error_list = []\n",
    "        if self.make_anim:\n",
    "            self.images = []\n",
    "        \n",
    "        n_train = self.x_train.shape[0]//n_batch\n",
    "        n_test = self.x_test.shape[0]\n",
    "        \n",
    "        # 学習開始\n",
    "        error = 0\n",
    "        error_prev = 0\n",
    "        rand_index = np.arange(self.x_train.shape[0])\n",
    "        for t in tqdm.tqdm(range(1, epoch+1)):\n",
    "            #シーン作成\n",
    "            if self.make_anim:\n",
    "                self.make_scene(t, epoch)\n",
    "            \n",
    "            # 訓練誤差計算\n",
    "            if show_train_error:\n",
    "                self.forward(self.x_train)\n",
    "                error = lm[-1].get_error(self.y_train)\n",
    "                self.train_error_list.append(error)\n",
    "            \n",
    "            # 誤差計算\n",
    "            self.forward(self.x_test)\n",
    "            error = lm[-1].get_error(self.y_test)\n",
    "            if show_error:\n",
    "                self.error_list.append(error)\n",
    "\n",
    "            # 収束判定\n",
    "            if np.isnan(error):\n",
    "                print(\"fail training...\")\n",
    "                break\n",
    "            if abs(error - error_prev) < threshold:\n",
    "                print(\"end learning...\")\n",
    "                break\n",
    "            else:\n",
    "                error_prev = error\n",
    "\n",
    "            np.random.shuffle(rand_index)\n",
    "            for i in range(n_train):\n",
    "                rand = rand_index[i*n_batch : (i+1)*n_batch]\n",
    "                \n",
    "                self.forward(self.x_train[rand])\n",
    "                self.backward(self.y_train[rand])\n",
    "                self.update(**kwds)\n",
    "        \n",
    "        if show_error:\n",
    "            # 誤差遷移表示\n",
    "            self.show_errors(show_train_error, **kwds)\n",
    "    \n",
    "    \n",
    "    def pred_func(self, y, threshold=0.5):\n",
    "        if isinstance(self[-1].act, softmax):\n",
    "            return np.argmax(y, axis=1)\n",
    "        elif isinstance(self[-1].act, sigmoid):\n",
    "            return np.where(y > threshold, 1, 0)\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "    \n",
    "    \n",
    "    def predict(self, x=None, y=None, threshold=0.5):\n",
    "        if x is None:\n",
    "            x = self.x_test\n",
    "        if y is None:\n",
    "            y = self.y_test\n",
    "        \n",
    "        self.forward(x)\n",
    "        self.y_pred = self.pred_func(self[-1].y, threshold)\n",
    "        y = self.pred_func(y, threshold)\n",
    "        print(y[:16], self.y_pred[:16])\n",
    "        print(\"accuracy rate:\", np.sum(self.y_pred == y, dtype=int)/y.shape[0]*100, \"%\",\n",
    "              \"({}/{})\".format(np.sum(self.y_pred == y, dtype=int), y.shape[0]))\n",
    "    \n",
    "    \n",
    "    def show_errors(self, show_train_error=False, title=\"error transition\",\n",
    "                    xlabel=\"epoch\", ylabel=\"error\", fname=\"error_transition.png\",\n",
    "                    log_scale=True, **kwds):\n",
    "        fig, ax = plt.subplots(1)\n",
    "        fig.suptitle(title)\n",
    "        if log_scale:\n",
    "            ax.set_yscale(\"log\")\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.grid()\n",
    "        if show_train_error:\n",
    "            ax.plot(self.train_error_list, label=\"train accuracy\")\n",
    "        ax.plot(self.error_list, label=\"test accuracy\")\n",
    "        ax.legend(loc=\"best\")\n",
    "        #fig.show()\n",
    "        if len(fname) != 0:\n",
    "            fig.savefig(fname)\n",
    "    \n",
    "    \n",
    "    def ready_anim(self, n_image, x, y, title=\"animation\",\n",
    "                   xlabel=\"x\", ylabel=\"y\", ex_color=\"r\", color=\"b\",\n",
    "                   x_left=0, x_right=0, y_down = 1, y_up = 1):\n",
    "        self.n_image = n_image\n",
    "        self.x = x\n",
    "        self.color = color\n",
    "        self.make_anim = True\n",
    "        \n",
    "        self.anim_fig, self.anim_ax = plt.subplots(1)\n",
    "        self.anim_fig.suptitle(title)\n",
    "        self.anim_ax.set_xlabel(xlabel)\n",
    "        self.anim_ax.set_ylabel(ylabel)\n",
    "        self.anim_ax.set_xlim(np.min(x) - x_left, np.max(x) + x_right)\n",
    "        self.anim_ax.set_ylim(np.min(y) - y_down, np.max(y) + y_up)\n",
    "        self.anim_ax.grid()\n",
    "        self.anim_ax.plot(x, y, color=ex_color)\n",
    "        \n",
    "        return self.anim_fig, self.anim_ax\n",
    "    \n",
    "    \n",
    "    def make_scene(self, t, epoch):\n",
    "        # シーン作成\n",
    "        if t % (epoch/self.n_image) == 1:\n",
    "            x_in = self.x.reshape(-1, 1)\n",
    "            for ll in self.layer_list:\n",
    "                x_in = ll.forward(x_in)\n",
    "            im, = self.anim_ax.plot(self.x, ll.y, color=self.color)\n",
    "            self.images.append([im])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import tqdm\n",
    "\n",
    "\n",
    "class LayerManager(_TypeManager, Trainer):\n",
    "    \"\"\"\n",
    "    層を管理するためのマネージャクラス\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__(x, y)\n",
    "        \n",
    "        self.__layer_list = []  # レイヤーのリスト\n",
    "        self.__name_list = []   # 各レイヤーの名前リスト\n",
    "        self.__ntype = np.zeros(self.N_TYPE, dtype=int)  # 種類別レイヤーの数\n",
    "        \n",
    "\n",
    "    def __repr__(self):\n",
    "        layerRepr= \"layer_list: \" + repr(self.__layer_list)\n",
    "        nameRepr = \"name_list: \" + repr(self.__name_list)\n",
    "        ntypeRepr = \"ntype: \" + repr(self.__ntype)\n",
    "        return (layerRepr + \"\\n\"\n",
    "                + nameRepr + \"\\n\"\n",
    "                + ntypeRepr)\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        layerStr = \"layer_list: \" + str(self.__layer_list)\n",
    "        nameStr = \"name_list: \" + str(self.__name_list)\n",
    "        ntypeStr = \"ntype: \" + str(self.__ntype)\n",
    "        return (layerStr + \"\\n\"\n",
    "                + nameStr + \"\\n\"\n",
    "                + ntypeStr)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Pythonのビルドイン関数`len`から呼ばれたときの動作を記述。\n",
    "        種類別レイヤーの数の総和を返します。\n",
    "        \"\"\"\n",
    "        return int(np.sum(self.__ntype))\n",
    "\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        例えば\n",
    "        lm = LayerManager()\n",
    "\n",
    "        +----------------+\n",
    "        | (lmに要素を追加) |\n",
    "        +----------------+\n",
    "\n",
    "        x = lm[3].~~\n",
    "        のように、リストや配列の要素にアクセスされたときに呼ばれるので、\n",
    "        そのときの動作を記述。\n",
    "        sliceやstr, intでのアクセスのみ許可します。\n",
    "        \"\"\"\n",
    "        if isinstance(key, slice):\n",
    "            # keyがスライスならレイヤーのリストをsliceで参照する。\n",
    "            # 異常な値(Index out of rangeなど)が入力されたら\n",
    "            # Pythonがエラーを出してくれます。\n",
    "            return self.__layer_list[key]\n",
    "        elif isinstance(key, str):\n",
    "            # keyが文字列なら各レイヤーの名前リストからインデックスを取得して、\n",
    "            # 該当するレイヤーのリストの要素を返す。\n",
    "            if key in self.__name_list:\n",
    "                index = self.__name_list.index(key)\n",
    "                return self.__layer_list[index]\n",
    "            else:\n",
    "                # keyが存在しない場合はKeyErrorを出す。\n",
    "                raise KeyError(\"{}: No such item\".format(key))\n",
    "        elif isinstance(key, int):\n",
    "            # keyが整数ならレイヤーのリストの該当要素を返す。\n",
    "            # 異常な値(Index out of rangeなど)が入力されたら\n",
    "            # Pythonがエラーを出してくれます。\n",
    "            return self.__layer_list[key]\n",
    "        else:\n",
    "            raise KeyError(key, \": Undefined such key type.\")\n",
    "\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        \"\"\"\n",
    "        例えば\n",
    "        lm = LayerManager()\n",
    "\n",
    "        +----------------+\n",
    "        | (lmに要素を追加) |\n",
    "        +----------------+\n",
    "\n",
    "        lm[1] = x\n",
    "        のように、リストや配列の要素にアクセスされたときに呼ばれるので、\n",
    "        そのときの動作を記述。\n",
    "        要素の上書きのみ認め、新規要素の追加などは禁止します。\n",
    "        \"\"\"\n",
    "        value_type = \"\"\n",
    "        if isinstance(value, list):\n",
    "            # 右辺で指定された'value'が'list'なら\n",
    "            # 全ての要素が'BaseLayer'クラスかそれを継承していなければエラー。\n",
    "            if not np.all(\n",
    "                np.where(isinstance(value, BaseLayer), True, False)):\n",
    "                self.AssignError()\n",
    "            value_type = \"list\"\n",
    "        elif isinstance(value, BaseLayer):\n",
    "            # 右辺で指定された'value'が'BaseLayer'クラスか\n",
    "            # それを継承していない場合はエラー。\n",
    "            self.AssignError(type(value))\n",
    "        if value_type == \"\":\n",
    "            value_type = self.reg_keys[self.BASE]\n",
    "\n",
    "        if isinstance(key, slice):\n",
    "            # keyがスライスならレイヤーのリストの要素を上書きする。\n",
    "            # ただし'value_type'が'list'でなければエラー。\n",
    "            # 異常な値(Index out of rangeなど)が入力されたら\n",
    "            # Pythonがエラーを出してくれます。\n",
    "            if value_type != \"list\":\n",
    "                self.AssignError(value_type)\n",
    "            self.__layer_list[key] = value\n",
    "        elif isinstance(key, str):\n",
    "            # keyが文字列なら各レイヤーの名前リストからインデックスを取得して、\n",
    "            # 該当するレイヤーのリストの要素を上書きする。\n",
    "            # ただし'value_type'が'BaseLayer'でなければエラー。\n",
    "            if value_type != self.reg_keys[self.BASE]:\n",
    "                raise AssignError(value_type)\n",
    "            if key in self.__name_list:\n",
    "                index = self.__name_list.index(key)\n",
    "                self.__layer_list[index] = value\n",
    "            else:\n",
    "                # keyが存在しない場合はKeyErrorを出す。\n",
    "                raise KeyError(\"{}: No such item\".format(key))\n",
    "        elif isinstance(key, int):\n",
    "            # keyが整数ならレイヤーのリストの該当要素を上書きする。\n",
    "            # ただし'value_type'が'BaseLayer'でなければエラー。\n",
    "            # また、異常な値(Index out of rangeなど)が入力されたら\n",
    "            # Pythonがエラーを出してくれます。\n",
    "            if value_type != self.reg_keys[self.BASE]:\n",
    "                raise AssignError(value_type)\n",
    "            self.__layer_list[key] = value\n",
    "        else:\n",
    "            raise KeyError(key, \": Undefined such key type.\")\n",
    "\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        \"\"\"\n",
    "        例えば\n",
    "        lm = LayerManager()\n",
    "\n",
    "        +----------------+\n",
    "        | (lmに要素を追加) |\n",
    "        +----------------+\n",
    "\n",
    "        del lm[2]\n",
    "        のように、del文でリストや配列の要素にアクセスされたときに呼ばれるので、\n",
    "        そのときの動作を記述。\n",
    "        指定要素が存在すれば削除、さらにリネームを行います。\n",
    "        \"\"\"\n",
    "        if isinstance(key, slice):\n",
    "            # keyがスライスならそのまま指定の要素を削除\n",
    "            # 異常な値(Index out of rangeなど)が入力されたら\n",
    "            # Pythonがエラーを出してくれます。\n",
    "            del self.__layer_list[slice]\n",
    "            del self.__name_list[slice]\n",
    "        elif isinstance(key, str):\n",
    "            # keyが文字列なら各レイヤーの名前リストからインデックスを取得して、\n",
    "            # 該当する要素を削除する。\n",
    "            if key in self.__name_list:\n",
    "                del self.__layer_list[index]\n",
    "                del self.__name_list[index]\n",
    "            else:\n",
    "                # keyが存在しない場合はKeyErrorを出す。\n",
    "                raise KeyError(\"{}: No such item\".format(key))\n",
    "        elif isinstance(key, int):\n",
    "            # keyが整数ならレイヤーのリストの該当要素を削除する。\n",
    "            # 異常な値(Index out of rangeなど)が入力されたら\n",
    "            # Pythonがエラーを出してくれます。\n",
    "            del self.__layer_list[key]\n",
    "        else:\n",
    "            raise KeyError(key, \": Undefined such key type.\")\n",
    "\n",
    "        # リネームする\n",
    "        self._rename()\n",
    "\n",
    "\n",
    "    def _rename(self):\n",
    "        \"\"\"\n",
    "        リスト操作によってネームリストのネーミングがルールに反するものになった場合に\n",
    "        改めてルールを満たすようにネーミングリストおよび各レイヤーの名前を変更する。\n",
    "\n",
    "        ネーミングルールは[レイヤーの種類][何番目か]とします。\n",
    "        レイヤーの種類はMiddleLayerならMiddle\n",
    "                     OutputLayerならOutput\n",
    "        のように略します。\n",
    "        何番目かというのは種類別でカウントします。\n",
    "\n",
    "        また、ここで改めて__ntypeのカウントを行います。\n",
    "        \"\"\"\n",
    "        # 種類別レイヤーの数を初期化\n",
    "        self.__ntype = np.zeros(self.N_TYPE)\n",
    "\n",
    "        # 再カウントと各レイヤーのリネーム\n",
    "        for i in range(len(self)):\n",
    "            for j, reg_name in enumerate(self.REGULATED_DIC):\n",
    "                if reg_name in self.__name_list[i]:\n",
    "                    self.__ntype[j] += 1\n",
    "                    self.__name_list[i] = (self.reg_keys[j]\n",
    "                                        + str(self.__ntype[j]))\n",
    "                    self.__layer_list[i].name = (self.reg_keys[j]\n",
    "                                              + str(self.__ntype[j]))\n",
    "                    break\n",
    "            else:\n",
    "                raise UndefinedLayerType(self.__name_list[i])\n",
    "    \n",
    "\n",
    "    def append(self, *, name=\"Middle\", **kwds):\n",
    "        \"\"\"\n",
    "        リストに要素を追加するメソッドでお馴染みのappendメソッドの実装。\n",
    "        \"\"\"\n",
    "        if \"prev\" in kwds:\n",
    "            # 'prev'がキーワードに含まれている場合、\n",
    "            # 一つ前の層の要素数を指定していることになります。\n",
    "            # 基本的に最初のレイヤーを挿入する時を想定していますので、\n",
    "            # それ以外は基本的に自動で決定するため指定しません。\n",
    "            if len(self) != 0:\n",
    "                if kwds[\"prev\"] != self.__layer_list[-1].n:\n",
    "                    # 最後尾のユニット数と一致しなければエラー。\n",
    "                    raise UnmatchUnitError(self.__layer_list[-1].n,\n",
    "                                           kwds[\"prev\"])\n",
    "        elif not self.is_CNN(name):\n",
    "            if len(self) == 0:\n",
    "                # 最初のDNNレイヤは必ず入力ユニットの数を指定する必要があります。\n",
    "                raise UnmatchUnitError(\"Input units\", \"Unspecified\")\n",
    "            else:\n",
    "                # 最後尾のレイヤのユニット数を'kwds'に追加\n",
    "                kwds[\"prev\"] = self.__layer_list[-1].n\n",
    "\n",
    "        # レイヤーの種類を読み取り、ネーミングルールに則った名前に変更する\n",
    "        name = self.name_rule(name)\n",
    "\n",
    "        # レイヤーを追加する。\n",
    "        for i, reg_name in enumerate(self.REGULATED_DIC):\n",
    "            if name in reg_name:\n",
    "                # 種類別レイヤーをインクリメントして\n",
    "                self.__ntype[i] += 1\n",
    "                # 名前に追加し\n",
    "                name += str(self.__ntype[i])\n",
    "                # ネームリストに追加し\n",
    "                self.__name_list.append(name)\n",
    "                # 最後にレイヤーを生成してリストに追加します。\n",
    "                self.__layer_list.append(self.REGULATED_DIC[reg_name](name=name, **kwds))\n",
    "\n",
    "\n",
    "    def extend(self, lm):\n",
    "        \"\"\"\n",
    "        extendメソッドでは既にある別のレイヤーマネージャ'lm'の要素を\n",
    "        全て追加します。\n",
    "        \"\"\"\n",
    "        if not isinstance(lm, LayerManager):\n",
    "            # 'lm'のインスタンスがLayerManagerでなければエラー。\n",
    "            raise TypeError(type(lm), \": Unexpected type.\")\n",
    "        if len(self) != 0:\n",
    "            if self.__layer_list[-1].n != lm[0].prev:\n",
    "                # 自分の最後尾のレイヤーのユニット数と\n",
    "                # 'lm'の最初のレイヤーの入力数が一致しない場合はエラー。\n",
    "                raise UnmatchUnitError(self.__layer_list[-1].n,\n",
    "                                       lm[0].prev)\n",
    "\n",
    "        # それぞれ'extend'メソッドで追加\n",
    "        self.__layer_list.extend(lm.layer_list)\n",
    "        self.__name_list.extend(lm.name_list)\n",
    "\n",
    "        # リネームする\n",
    "        self._rename()\n",
    "\n",
    "\n",
    "    def insert(self, prev_name, name=\"Middle\", **kwds):\n",
    "        \"\"\"\n",
    "        insertメソッドでは、前のレイヤーの名前を指定しそのレイヤーと結合するように\n",
    "        要素を追加します。\n",
    "        \"\"\"\n",
    "        # 'prev_name'が存在しなければエラー。\n",
    "        if not prev_name in self.__name_list:\n",
    "            raise KeyError(prev_name, \": No such key.\")\n",
    "        # 'prev'がキーワードに含まれている場合、\n",
    "        # 'prev_name'で指定されているレイヤーのユニット数と一致しなければエラー。\n",
    "        if \"prev\" in kwds:\n",
    "            if kwds[\"prev\"] \\\n",
    "                != self.__layer_list[self.index(prev_name)].n:\n",
    "                raise UnmatchUnitError(\n",
    "                    kwds[\"prev\"],\n",
    "                    self.__layer_list[self.index(prev_name)].n)\n",
    "        # 'n'がキーワードに含まれている場合、\n",
    "        if \"n\" in kwds:\n",
    "            # 'prev_name'が最後尾ではない場合は\n",
    "            if prev_name != self.__name_list[-1]:\n",
    "                # 次のレイヤーのユニット数と一致しなければエラー。\n",
    "                if kwds[\"n\"] != self.__layer_list[\n",
    "                        self.index(prev_name)+1].prev:\n",
    "                    raise UnmatchUnitError(\n",
    "                        kwds[\"n\"],\n",
    "                        self.__layer_list[self.index(prev_name)].prev)\n",
    "        # まだ何も要素がない場合は'append'メソッドを用いるようにエラーを出す。\n",
    "        if len(self) == 0:\n",
    "            raise RuntimeError(\n",
    "                \"You have to use 'append' method instead.\")\n",
    "\n",
    "        # 挿入場所のインデックスを取得\n",
    "        index = self.index(prev_name) + 1\n",
    "\n",
    "        # レイヤーの種類を読み取り、ネーミングルールに則った名前に変更する\n",
    "        name = self.name_rule(name)\n",
    "\n",
    "        # 要素を挿入する\n",
    "        for i, reg_name in enumerate(self.REGULATED_DIC):\n",
    "            if reg_name in name:\n",
    "                self.__layer_list.insert(index,\n",
    "                                         self.REGULATED_DIC[reg_name](name=name, **kwds))\n",
    "                self.__name_list.insert(index,\n",
    "                                        self.REGULATED_DIC[reg_name](name=name, **kwds))\n",
    "\n",
    "        # リネームする\n",
    "        self._rename()\n",
    "\n",
    "\n",
    "    def extend_insert(self, prev_name, lm):\n",
    "        \"\"\"\n",
    "        こちらはオリジナル関数です。\n",
    "        extendメソッドとinsertメソッドを組み合わせたような動作をします。\n",
    "        簡単に説明すると、別のレイヤーマネージャをinsertする感じです。\n",
    "        \"\"\"\n",
    "        if not isinstance(lm, LayerManager):\n",
    "            # 'lm'のインスタンスがLayerManagerでなければエラー。\n",
    "            raise TypeError(type(lm), \": Unexpected type.\")\n",
    "        # 'prev_name'が存在しなければエラー。\n",
    "        if not prev_name in self.__name_list:\n",
    "            raise KeyError(prev_name, \": No such key.\")\n",
    "        # 指定場所の前後のレイヤーとlmの最初・最後のレイヤーのユニット数が\n",
    "        # それぞれ一致しなければエラー。\n",
    "        if len(self) != 0:\n",
    "            if self.__layer_list[self.index(prev_name)].n \\\n",
    "                    != lm.layer_list[0].prev:\n",
    "                # 自分の指定場所のユニット数と'lm'の最初のユニット数が\n",
    "                # 一致しなければエラー。\n",
    "                raise UnmatchUnitError(\n",
    "                    self.__layer_list[self.index(prev_name)].n,\n",
    "                    lm.layer_list[0].prev)\n",
    "            if prev_name != self.__name_list[-1]:\n",
    "                # 'prev_name'が自分の最後尾のレイヤーでなく\n",
    "                if lm.layer_list[-1].n \\\n",
    "                    != self.__layer_list[self.index(prev_name)+1].prev:\n",
    "                    # 'lm'の最後尾のユニット数と自分の指定場所の次のレイヤーの\n",
    "                    # 'prev'ユニット数と一致しなければエラー。\n",
    "                    raise UnmatchUnitError(\n",
    "                        lm.layer_list[-1].n,\n",
    "                        self.__layer_list[self.index(prev_name)+1].prev)\n",
    "        else:\n",
    "            # 自分に何の要素もない場合は'extend'メソッドを使うようにエラーを出す。\n",
    "            raise RuntimeError(\n",
    "                \"You have to use 'extend' method instead.\")\n",
    "\n",
    "        # 挿入場所のインデックスを取得\n",
    "        index = self.index(prev_name) + 1\n",
    "\n",
    "        # 挿入場所以降の要素を'buf'に避難させてから一旦取り除き、\n",
    "        # extendメソッドを使って要素を追加\n",
    "        layer_buf = self.__layer_list[index:]\n",
    "        name_buf = self.__name_list[index:]\n",
    "        del self.__layer_list[index:]\n",
    "        del self.__name_list[index:]\n",
    "        self.extend(lm)\n",
    "\n",
    "        # 避難させていた要素を追加する\n",
    "        self.__layer_list.extend(layer_buf)\n",
    "        self.__name_list.extend(name_buf)\n",
    "\n",
    "        # リネームする\n",
    "        self._rename()\n",
    "\n",
    "\n",
    "    def remove(self, key):\n",
    "        \"\"\"\n",
    "        removeメソッドでは指定の名前の要素を削除します。\n",
    "        インデックスでの指定も許可します。\n",
    "        \"\"\"\n",
    "        # 既に実装している'del'文でOKです。\n",
    "        del self[key]\n",
    "\n",
    "\n",
    "    def index(self, target):\n",
    "        return self.__name_list.index(target)\n",
    "\n",
    "\n",
    "    def name(self, indices):\n",
    "        return self.__name_list[indices]\n",
    "\n",
    "\n",
    "    @property\n",
    "    def layer_list(self):\n",
    "        return self.__layer_list\n",
    "\n",
    "\n",
    "    @property\n",
    "    def name_list(self):\n",
    "        return self.__name_list\n",
    "\n",
    "\n",
    "    @property\n",
    "    def ntype(self):\n",
    "        return self.__ntype\n",
    "    \n",
    "    \n",
    "    def is_CNN(self, name=None):\n",
    "        if name is None:\n",
    "            if self.__ntype[self.CONV] > 0 \\\n",
    "            or self.__ntype[self.POOL] > 0:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            name = self.name_rule(name)\n",
    "            if self.reg_keys[self.CONV] in name \\\n",
    "            or self.reg_keys[self.POOL] in name:\n",
    "                return True\n",
    "            else:\n",
    "                return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験コード\n",
    "[目次へ戻る](#目次)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数近似編"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib nbagg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import tqdm\n",
    "\n",
    "\n",
    "# 学習対象設定\n",
    "def split_test(target, train_indices):\n",
    "    return (target[train_indices], target[~ train_indices])\n",
    "x = np.arange(0, 4, 5e-2)\n",
    "y = np.sin(x)\n",
    "x_left = 1\n",
    "x_right = 3\n",
    "y_top = np.max(y) + 1\n",
    "y_bottom = np.min(y) - 1\n",
    "indices = (x_left <= x) & (x <= x_right)\n",
    "x_train, x_test = split_test(x, indices)\n",
    "y_train, y_test = split_test(y, indices)\n",
    "\n",
    "# 初期設定\n",
    "n_in = 1\n",
    "n_out = 1\n",
    "epoch = 30000\n",
    "threshold = 1e-8\n",
    "n_batch = 8\n",
    "x_train = x_train.reshape(-1, n_in)\n",
    "x_test = x_test.reshape(-1, n_in)\n",
    "y_train = y_train.reshape(-1, n_in)\n",
    "y_test = y_test.reshape(-1, n_in)\n",
    "\n",
    "# ネットワーク構築\n",
    "lm = LayerManager((x_train, x_test), (y_train, y_test))\n",
    "lm.append(prev=n_in, n=30, act=\"tanhExp\")\n",
    "lm.append(n=30, act=\"tanhExp\")\n",
    "lm.append(n=n_out, name=\"o\", act=\"identity\")\n",
    "\n",
    "\n",
    "# アニメーションプロット用土台作成\n",
    "n_image = 100\n",
    "interval = 100\n",
    "fig, ax = lm.ready_anim(n_image, x, y, title=\"fitting animation\")\n",
    "ax.plot(np.full_like(np.arange(y_bottom, y_top+1), x_left),\n",
    "        np.arange(y_bottom, y_top+1),\n",
    "        color=\"g\")\n",
    "ax.plot(np.full_like(np.arange(y_bottom, y_top+1), x_right),\n",
    "        np.arange(y_bottom, y_top+1),\n",
    "        color=\"g\")\n",
    "\n",
    "# 学習開始\n",
    "lm.training(epoch, threshold=threshold, n_batch=n_batch)\n",
    "\n",
    "# フィッティングアニメーション作成\n",
    "anim = animation.ArtistAnimation(lm.anim_fig, lm.images,interval=interval, repeat_delay=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN実験編\n",
    "データ処理はいくつか種類がありますが、代表的な二つを紹介しておきます。\n",
    "\n",
    "[目次へ戻る](#目次)\n",
    "\n",
    "### 標準化\n",
    "標準化はデータを平均0、標準偏差1になるようにデータを縮尺する処理のことです。\n",
    "\\begin{align}\n",
    "  \\hat{x} = \\cfrac{x - \\mu}{\\sigma}\n",
    "\\end{align}\n",
    "ここでの$\\mu$は平均値、$\\sigma$は標準偏差です。\n",
    "\n",
    "### 正規化\n",
    "正規化はデータに何らかの処理を行いデータ値の大きさを0~1などに収める処理のことです。\n",
    "大抵は最大値と最小値を用いて\n",
    "\\begin{align}\n",
    "  \\hat{x} = \\cfrac{x - x_{min}}{x_{max} - x_{min}}\n",
    "\\end{align}\n",
    "とします。\n",
    "\n",
    "正規化は異常値の影響を大きく受けてしまうため一般には標準化を用いることが多いですが、画像データなどの異常値があり得ないデータの場合は正規化を行うことがあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KerasのMNISTデータ処理\n",
    "使いたい方を実行してください。\n",
    "KerasのMNISTデータセットは実行時間が非常に大きくなるため注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "\n",
    "\n",
    "# データセット取得\n",
    "n_class=10\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "C, B, I_h, I_w = 1, *x_train.shape\n",
    "B_test = x_test.shape[0]\n",
    "\n",
    "# 標準化\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train.reshape(B, -1)).reshape(B, C, I_h, I_w)\n",
    "x_test = sc.fit_transform(x_test.reshape(B_test, -1)).reshape(B_test, C, I_h, I_w)\n",
    "\n",
    "# one-hotラベルへの変換\n",
    "def to_one_hot(data, n_class):\n",
    "    vec = np.zeros((len(data), n_class))\n",
    "    for i in range(len(data)):\n",
    "        vec[i, data[i]] = 1.\n",
    "    return vec\n",
    "t_train = to_one_hot(y_train, n_class)\n",
    "t_test = to_one_hot(y_test, n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learnのMNISTデータ処理\n",
    "scikit-learnの方はデータ量がすごく削減されているため実行時間はかなり短くて済みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "\n",
    "\n",
    "# データセット取得\n",
    "n_class=10\n",
    "C, I_h, I_w = 1, 8, 8\n",
    "digits = datasets.load_digits()\n",
    "x = digits.data\n",
    "t = digits.target\n",
    "n_data = len(x)\n",
    "\n",
    "# 標準化\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x).reshape(n_data, I_h, I_w)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, t, test_size=0.2, shuffle=True)\n",
    "\n",
    "# one-hotラベルへの変換\n",
    "def to_one_hot(data, n_class):\n",
    "    vec = np.zeros((len(data), n_class))\n",
    "    for i in range(len(data)):\n",
    "        vec[i, data[i]] = 1.\n",
    "    return vec\n",
    "t_train = to_one_hot(y_train, n_class)\n",
    "t_test = to_one_hot(y_test, n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN実験コード本体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:05<00:00,  4.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset\n",
      "[0 9 7 9 5 6 2 5 3 4 4 1 6 1 9 2] [0 9 7 9 5 6 2 5 3 4 4 1 6 1 9 2]\n",
      "accuracy rate: 100.0 % (1437/1437)\n",
      "test dataset\n",
      "[2 5 1 6 0 9 6 2 4 0 1 6 2 5 2 1] [2 5 1 6 0 9 6 2 4 0 1 6 2 5 2 1]\n",
      "accuracy rate: 99.16666666666667 % (357/360)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 畳み込み層と出力層を作成\n",
    "M, F_h, F_w = 10, 3, 3\n",
    "lm = LayerManager((x_train, x_test), (t_train, t_test))\n",
    "lm.append(name=\"c\", I_shape=(C, I_h, I_w), F_shape=(M, F_h, F_w), pad=1,\n",
    "          wb_width=0.1, opt=\"AdaDelta\", opt_dic={\"eta\": 1e-2})\n",
    "lm.append(name=\"p\", I_shape=lm[-1].O_shape, pool=2)\n",
    "lm.append(name=\"m\", n=100, wb_width=0.1,\n",
    "          opt=\"AdaDelta\", opt_dic={\"eta\": 1e-2})\n",
    "lm.append(name=\"o\", n=n_class, act=\"softmax\", err_func=\"Cross\", wb_width=0.1,\n",
    "          opt=\"AdaDelta\", opt_dic={\"eta\": 1e-2})\n",
    "\n",
    "# 学習させる\n",
    "epoch = 50\n",
    "threshold = 1e-8\n",
    "n_batch = 128\n",
    "lm.training(epoch, threshold=threshold, n_batch=n_batch, show_train_error=True)\n",
    "\n",
    "# 予測する\n",
    "print(\"training dataset\")\n",
    "lm.predict(x=lm.x_train, y=lm.y_train)\n",
    "print(\"test dataset\")\n",
    "lm.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
