{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "test.ipynb のコピー",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVbbqCtyztT9"
      },
      "source": [
        "# 実行について\n",
        "上から順に実験コード前まで実行していきましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrKKXIPmztT_"
      },
      "source": [
        "# 目次\n",
        "\n",
        "- [誤差関数](#誤差関数)\n",
        "- [活性化関数](#活性化関数)\n",
        "- [最適化](#最適化)\n",
        "- [CNN util](#CNN-util)\n",
        "- [レイヤ](#レイヤ)\n",
        "- [レイヤマネージャ](#レイヤマネージャ)\n",
        "- [実験コード](#実験コード)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "512v1onNwulX"
      },
      "source": [
        "#cupyのインストールと確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkhGrw_9MN7A",
        "outputId": "e79310df-ff49-4c48-c17a-efb7ab7eae72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!curl https://colab.chainer.org/install | sh -"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1580  100  1580    0     0   6666      0 --:--:-- --:--:-- --:--:--  6666\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 11 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "\u001b[K     |████████████████████████████████| 348.0MB 51kB/s \n",
            "\u001b[?25h+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuCUMHjjtpxm",
        "outputId": "0fb12c1a-51fa-4465-928c-089c4dfb12f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!python -c 'import chainer; chainer.print_runtime_info()'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/chainer/_environment_check.py:91: UserWarning: \n",
            "--------------------------------------------------------------------------------\n",
            "Multiple installations of CuPy package has been detected.\n",
            "You should select only one package from from ['cupy-cuda102', 'cupy-cuda101', 'cupy-cuda100', 'cupy-cuda92', 'cupy-cuda91', 'cupy-cuda90', 'cupy-cuda80', 'cupy'].\n",
            "Follow these steps to resolve this issue:\n",
            "  1. `pip list` to list CuPy packages installed\n",
            "  2. `pip uninstall <package name>` to uninstall all CuPy packages\n",
            "  3. `pip install <package name>` to install the proper one\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  '''.format(name=name, pkgs=pkgs))\n",
            "Platform: Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Chainer: 7.4.0\n",
            "ChainerX: Not Available\n",
            "NumPy: 1.18.5\n",
            "CuPy:\n",
            "  CuPy Version          : 7.8.0\n",
            "  CUDA Root             : /usr/local/cuda\n",
            "  CUDA Build Version    : 10000\n",
            "  CUDA Driver Version   : 10010\n",
            "  CUDA Runtime Version  : 10000\n",
            "  cuBLAS Version        : 10000\n",
            "  cuFFT Version         : 10000\n",
            "  cuRAND Version        : 10000\n",
            "  cuSOLVER Version      : (10, 0, 0)\n",
            "  cuSPARSE Version      : 10000\n",
            "  NVRTC Version         : (10, 0)\n",
            "  cuDNN Build Version   : 7605\n",
            "  cuDNN Version         : 7605\n",
            "  NCCL Build Version    : 2604\n",
            "  NCCL Runtime Version  : 2604\n",
            "  CUB Version           : None\n",
            "  cuTENSOR Version      : None\n",
            "iDeep: 2.0.0.post3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0MHNFlmw1mS"
      },
      "source": [
        "#CPUの数を確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhDe3bx0OEFn",
        "outputId": "d987dc8e-a8fb-46be-e5cb-5846c853b098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.cpu_count()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85D8BjCnztT_"
      },
      "source": [
        "# 誤差関数\n",
        "[目次へ戻る](#目次)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1iUr5GgztUA"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Error():\n",
        "    def __init__(self, *args, **kwds):\n",
        "        self.error = 0\n",
        "    \n",
        "    \n",
        "    def forward(self, *args, **kwds):\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def backward(self, *args, **kwds):\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def total_error(self, *args, **kwds):\n",
        "        return np.sum(self.error)/self.error.size\n",
        "\n",
        "\n",
        "class SquareError(Error):\n",
        "    def forward(self, y, t, *args, **kwds):\n",
        "        self.error = 0.5 * (y - t)**2\n",
        "        return self.error\n",
        "    \n",
        "    \n",
        "    def backward(self, y, t, *args, **kwds):\n",
        "        return y - t\n",
        "\n",
        "\n",
        "class BinaryCrossEntropy(Error):\n",
        "    def forward(self, y, t, *args, eps=1e-8, **kwds):\n",
        "        self.error = - t*np.log(y+eps) - (1 - t)*np.log(1-y+eps)\n",
        "        return self.error\n",
        "    \n",
        "    \n",
        "    def backward(self, y, t, *args, eps=1e-8, **kwds):\n",
        "        return (y - t) / (y*(1 - y) + eps)\n",
        "    \n",
        "\n",
        "class CrossEntropy(Error):\n",
        "    def forward(self, y, t, *args, eps=1e-8, **kwds):\n",
        "        self.error = - t*np.log(y+eps)\n",
        "        return self.error\n",
        "    \n",
        "    \n",
        "    def backward(self, y, t, *args, eps=1e-8, **kwds):\n",
        "        return - t/(y+eps)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ce6PdGKztUE"
      },
      "source": [
        "_err_dic = {\"Square\": SquareError,\n",
        "            \"Binary\": BinaryCrossEntropy,\n",
        "            \"Cross\": CrossEntropy,\n",
        "           }\n",
        "\n",
        "\n",
        "def get_err(name, *args, **kwds):\n",
        "    if name in _err_dic.keys():\n",
        "        errfunc = _err_dic[name](*args, **kwds)\n",
        "    else:\n",
        "        raise ValueError(name + \": Unknown error function\")\n",
        "\n",
        "    return errfunc"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92vpQhCcztUH"
      },
      "source": [
        "# 活性化関数\n",
        "[目次へ戻る](#目次)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZBJH5ADztUH"
      },
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "\n",
        "class Activator():\n",
        "    def __init__(self, *args, mode=\"cpu\", **kwds):\n",
        "        self.mode = mode\n",
        "\n",
        "        if self.mode == \"cpu\":\n",
        "            self.forward = self.cpu_forward\n",
        "            self.backward = self.cpu_backward\n",
        "            self.update = self.cpu_update\n",
        "        elif self.mode == \"gpu\":\n",
        "            self.forward = self.gpu_forward\n",
        "            self.backward = self.gpu_backward\n",
        "            self.update = self.gpu_update\n",
        "    \n",
        "\n",
        "    def cpu_forward(self, *args, **kwds):\n",
        "        raise NotImplemented\n",
        "\n",
        "    def gpu_forward(self, *args, **kwds):\n",
        "        raise NotImplemented\n",
        "\n",
        "\n",
        "    def cpu_backward(self, *args, **kwds):\n",
        "        raise NotImplemented\n",
        "    \n",
        "    def gpu_backward(self, *args, **kwds):\n",
        "        raise NotImplemented\n",
        "\n",
        "\n",
        "    def cpu_update(self, *args, **kwds):\n",
        "        raise NotImplemented\n",
        "\n",
        "    def gpu_update(self, *args, **kwds):\n",
        "        raise NotImplemented\n",
        "\n",
        "\n",
        "class step(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return np.where(x > 0, 1, 0)\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return cp.where(x > 0, 1, 0)\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return np.zeros_like(x)\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.zeros_like(x)\n",
        "\n",
        "\n",
        "class identity(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return x\n",
        "    \n",
        "    gpu_forward = cpu_forward\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return np.ones_like(x)\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.ones_like(x)\n",
        "\n",
        "\n",
        "class bentIdentity(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return 0.5*(np.sqrt(x**2 + 1) - 1) + x\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return 0.5*(cp.sqrt(x**2 + 1) - 1) + x\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return 0.5*x/np.sqrt(x**2 + 1) + 1\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return 0.5*x/cp.sqrt(x**2 + 1) + 1\n",
        "\n",
        "\n",
        "class hardShrink(Activator):\n",
        "    def __init__(self, lambda_=0.5, *args, **kwds):\n",
        "        self.lambda_ = lambda_\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return np.where((-self.lambda_ <= x) & (x <= self.lambda_), 0, x)\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return cp.where((-self.lambda_ <= x) & (x <= self.lambda_), 0, x)\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return np.where((-self.lambda_ <= x) & (x <= self.lambda_), 0, 1)\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.where((-self.lambda_ <= x) & (x <= self.lambda_), 0, 1)\n",
        "\n",
        "\n",
        "class softShrink(Activator):\n",
        "    def __init__(self, lambda_=0.5, *args, **kwds):\n",
        "        self.lambda_ = lambda_\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return np.where(x < -self.lambda_, x + self.lambda_,\n",
        "                        np.where(x > self.lambda_, x - self.lambda_, 0))\n",
        "\n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.where(x < -self.lambda_, x + self.lambda_,\n",
        "                        cp.where(x > self.lambda_, x - self.lambda_, 0))\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return np.where((-self.lambda_ <= x) & (x <= self.lambda_), 0, 1)\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.where((-self.lambda_ <= x) & (x <= self.lambda_), 0, 1)\n",
        "\n",
        "\n",
        "class threshold(Activator):\n",
        "    def __init__(self, threshold, value, *args, **kwds):\n",
        "        self.threshold = threshold\n",
        "        self.value = value\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return np.where(x > self.threshold, x, self.value)\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return cp.where(x > self.threshold, x, self.value)\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return np.where(x > self.threshold, 1, 0)\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.where(x > self.threshold, 1, 0)\n",
        "\n",
        "\n",
        "class sigmoid(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return 1/(1 + np.exp(-x))\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return 1/(1 + cp.exp(-x))\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, y, *args, **kwds):\n",
        "        return y*(1 - y)\n",
        "    \n",
        "    gpu_backward = cpu_backward\n",
        "\n",
        "\n",
        "class hardSigmoid(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return np.clip(0.2*x + 0.5, 0, 1)\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return cp.clip(0.2*x + 0.5, 0, 1)\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return np.where((x > 2.5) | (x < -2.5), 0, 0.2)\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.where((x > 2.5) | (x < -2.5), 0, 0.2)\n",
        "    \n",
        "\n",
        "class logSigmoid(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return -np.log(1 + np.exp(-x))\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return -cp.log(1 + cp.exp(-x))\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return 1/(1 + np.exp(x))\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return 1/(1 + cp.exp(x))\n",
        "\n",
        "\n",
        "class act_tanh(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return np.tanh(x)\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return cp.tanh(x)\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return 1 - np.tanh(x)**2\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return 1 - cp.tanh(x)**2\n",
        "\n",
        "\n",
        "class hardtanh(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return np.clip(x, -1, 1)\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return cp.clip(x, -1, 1)\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return np.where((-1 <= x) & (x <= 1), 1, 0)\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.where((-1 <= x) & (x <= 1), 1, 0)\n",
        "\n",
        "\n",
        "class tanhShrink(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return x - np.tanh(x)\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return x - cp.tanh(x)\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return np.tanh(x)**2\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.tanh(x)**2\n",
        "\n",
        "\n",
        "class ReLU(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return np.maximum(0, x)\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return cp.maximum(0, x)\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return np.where(x > 0, 1, 0)\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.where(x > 0, 1, 0)\n",
        "\n",
        "\n",
        "class ReLU6(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return np.clip(x, 0, 6)\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return cp.clip(x, 0, 6)\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return np.where((0 < x) & (x < 6), 1, 0)\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.where((0 < x) & (x < 6), 1, 0)\n",
        "\n",
        "\n",
        "class leakyReLU(Activator):\n",
        "    def __init__(self, alpha=1e-2, *args, **kwds):\n",
        "        self.alpha = alpha\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return np.maximum(self.alpha*x, x)\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return cp.maximum(self.alpha*x, x)\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return np.where(x < 0, self.alpha, 1)\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.where(x < 0, self.alpha, 1)\n",
        "\n",
        "\n",
        "class ELU(Activator):\n",
        "    def __init__(self, alpha=1., *args, **kwds):\n",
        "        self.alpha = alpha\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return np.where(x >= 0, x, self.alpha*(np.expm1(x)))\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return cp.where(x >= 0, x, self.alpha*(cp.expm1(x)))\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return np.where(x >= 0, 1, self.alpha*np.exp(x))\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.where(x >= 0, 1, self.alpha*cp.exp(x))\n",
        "\n",
        "\n",
        "class SELU(Activator):\n",
        "    def __init__(self, lambda_=1.0507, alpha=1.67326, *args, **kwds):\n",
        "        self.lambda_ = lambda_\n",
        "        self.alpha = alpha\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return np.where(x >= 0, self.lambda_*x,\n",
        "                        self.lambda_*self.alpha*(np.expm1(x)))\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return cp.where(x >= 0, self.lambda_*x,\n",
        "                        self.lambda_*self.alpha*(cp.expm1(x)))\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return np.where(x >= 0, self.lambda_, self.lambda_*self.alpha*np.exp(x))\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.where(x >= 0, self.lambda_, self.lambda_*self.alpha*cp.exp(x))\n",
        "\n",
        "\n",
        "class CELU(Activator):\n",
        "    def __init__(self, alpha=1., *args, **kwds):\n",
        "        self.alpha = alpha\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return np.where(x >= 0, x, self.alpha*(np.expm1(x/self.alpha)))\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return cp.where(x >= 0, x, self.alpha*(cp.expm1(x/self.alpha)))\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return np.where(x >= 0, 1, np.exp(x/self.alpha))\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return cp.where(x >= 0, 1, cp.exp(x/self.alpha))\n",
        "\n",
        "\n",
        "class softmax(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        exp_x = np.exp(x-np.max(x, axis=1, keepdims=True))\n",
        "        return exp_x/np.sum(exp_x, axis=1, keepdims=True)\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        exp_x = cp.exp(x-cp.max(x, axis=1, keepdims=True))\n",
        "        return exp_x/cp.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, y, *args, **kwds):\n",
        "        return y*(1 - y)\n",
        "    \n",
        "    gpu_backward = cpu_backward\n",
        "\n",
        "\n",
        "class softmin(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        exp_mx = np.exp(-x)\n",
        "        return exp_mx/np.sum(exp_mx, axis=1, keepdims=True)\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        exp_mx = cp.exp(-x)\n",
        "        return exp_mx/cp.sum(exp_mx, axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, y, *args, **kwds):\n",
        "        return -y*(1 - y)\n",
        "    \n",
        "    gpu_backward = cpu_backward\n",
        "\n",
        "\n",
        "class logSoftmax(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        exp_x = np.exp(x)\n",
        "        return np.log(exp_x/np.sum(exp_x, axis=1, keepdims=True))\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        exp_x = cp.exp(x)\n",
        "        return cp.log(exp_x/cp.sum(exp_x, axis=1, keepdims=True))\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, y, *args, **kwds):\n",
        "        return -np.expm1(y)\n",
        "    \n",
        "    def gpu_backward(self, x, y, *args, **kwds):\n",
        "        return -cp.expm1(y)\n",
        "\n",
        "\n",
        "class softplus(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return np.logaddexp(x, 0)\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return cp.logaddexp(x, 0)\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return 1/(1 + np.exp(-x))\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return 1/(1 + cp.exp(-x))\n",
        "\n",
        "\n",
        "class softsign(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return x/(1 + np.abs(x))\n",
        "\n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return x/(1 + cp.abs(x))\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        return 1/(1 + np.abs(x))**2\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        return 1/(1 + cp.abs(x))**2\n",
        "\n",
        "\n",
        "class Swish(Activator):\n",
        "    def __init__(self, beta=1, *args, **kwds):\n",
        "        self.beta = beta\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return x/(1 + np.exp(-self.beta*x))\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return x/(1 + cp.exp(-self.beta*x))\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, y, *args, **kwds):\n",
        "        return self.beta*y + (1 - self.beta*y)/(1 + np.exp(-self.beta*x))\n",
        "    \n",
        "    def gpu_backward(self, x, y, *args, **kwds):\n",
        "        return self.beta*y + (1 - self.beta*y)/(1 + cp.exp(-self.beta*x))\n",
        "\n",
        "\n",
        "class Mish(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return x*np.tanh(np.logaddexp(x, 0))\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return x*cp.tanh(cp.logaddexp(x, 0))\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        omega = (4*(x + 1) + 4*np.exp(2*x)\n",
        "              + np.exp(3*x) + (4*x + 6)*np.exp(x))\n",
        "        delta = 2*np.exp(x) + np.exp(2*x) + 2\n",
        "        return np.exp(x)*omega/delta**2\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        omega = (4*(x + 1) + 4*cp.exp(2*x)\n",
        "              + cp.exp(3*x) + (4*x + 6)*cp.exp(x))\n",
        "        delta = 2*cp.exp(x) + cp.exp(2*x) + 2\n",
        "        return cp.exp(x)*omega/delta**2\n",
        "\n",
        "\n",
        "class tanhExp(Activator):\n",
        "    def cpu_forward(self, x, *args, **kwds):\n",
        "        return x*np.tanh(np.exp(x))\n",
        "    \n",
        "    def gpu_forward(self, x, *args, **kwds):\n",
        "        return c*np.tanh(cp.exp(x))\n",
        "\n",
        "\n",
        "    def cpu_backward(self, x, *args, **kwds):\n",
        "        tanh_exp_x = np.tanh(np.exp(x))\n",
        "        return tanh_exp_x - x*np.exp(x)*(tanh_exp_x**2 - 1)\n",
        "    \n",
        "    def gpu_backward(self, x, *args, **kwds):\n",
        "        tanh_exp_x = cp.tanh(cp.exp(x))\n",
        "        return tanh_exp_x - x*cp.exp(x)*(tanh_exp_x**2 - 1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqt7q-DNztUK"
      },
      "source": [
        "import string\n",
        "\n",
        "\n",
        "_act_dic = {\"step\": step,\n",
        "            \"identity\": identity,\n",
        "            \"bentidentity\": bentIdentity,\n",
        "            \"hardshrink\": hardShrink,\n",
        "            \"softshrink\": softShrink, \n",
        "            \"threshold\": threshold,\n",
        "            \"sigmoid\": sigmoid,\n",
        "            \"hardsigmoid\": hardSigmoid,\n",
        "            \"logsigmoid\": logSigmoid,\n",
        "            \"tanh\": act_tanh,\n",
        "            \"tanhshrink\": tanhShrink,\n",
        "            \"hardtanh\":hardtanh,\n",
        "            \"relu\": ReLU,\n",
        "            \"relu6\": ReLU6,\n",
        "            \"leakyrelu\": leakyReLU, \"lrelu\": leakyReLU,\n",
        "            \"elu\": ELU,\n",
        "            \"selu\": SELU,\n",
        "            \"celu\": CELU,\n",
        "            \"softmax\": softmax,\n",
        "            \"softmin\": softmin,\n",
        "            \"logsoftmax\": logSoftmax,\n",
        "            \"softplus\": softplus,\n",
        "            \"softsign\": softsign,\n",
        "            \"swish\": Swish,\n",
        "            \"mish\": Mish,\n",
        "            \"tanhexp\": tanhExp,\n",
        "           }\n",
        "\n",
        "\n",
        "def get_act(name, *args, **kwds):\n",
        "    name = name.lower().translate(str.maketrans( '', '',string.punctuation))\n",
        "    if name in _act_dic.keys():\n",
        "        activator = _act_dic[name](*args, **kwds)\n",
        "    else:\n",
        "        raise ValueError(name + \": Unknown activator\")\n",
        "\n",
        "    return activator"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb6rrrcAztUM"
      },
      "source": [
        "# 最適化\n",
        "[目次へ戻る](#目次)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkNHG7IlztUN"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Optimizer():\n",
        "    \"\"\"\n",
        "    最適化手法が継承するスーパークラス。\n",
        "    \"\"\"\n",
        "    def __init__(self, *args, mode=\"cpu\", **kwds):\n",
        "        self.mode = mode\n",
        "\n",
        "        if self.mode == \"cpu\":\n",
        "            self.update = self.cpu_update\n",
        "        elif self.mode == \"gpu\":\n",
        "            self.update = self.gpu_update\n",
        "\n",
        "\n",
        "    def cpu_update(self, *args, **kwds):\n",
        "        raise NotImplemented\n",
        "    \n",
        "    def gpu_update(self, *args, **kwds):\n",
        "        raise NotImplemented\n",
        "\n",
        "\n",
        "class SGD(Optimizer):\n",
        "    def __init__(self, eta=1e-2, *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.eta = eta\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, *args, **kwds):\n",
        "        dw = -self.eta*grad_w\n",
        "        db = -self.eta*grad_b\n",
        "        return dw, db\n",
        "    \n",
        "    gpu_update = cpu_update\n",
        "\n",
        "\n",
        "class MSGD(Optimizer):\n",
        "    def __init__(self, eta=1e-2, mu=0.9, *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.eta = eta\n",
        "        self.mu = mu\n",
        "\n",
        "        # 一つ前のステップの値を保持する\n",
        "        self.dw = 1e-8\n",
        "        self.db = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, *args, **kwds):\n",
        "        dw = self.mu*self.dw - (1-self.mu)*self.eta*grad_w\n",
        "        db = self.mu*self.db - (1-self.mu)*self.eta*grad_b\n",
        "        self.dw = dw\n",
        "        self.db = db\n",
        "        return dw, db\n",
        "    \n",
        "    gpu_update = cpu_update\n",
        "\n",
        "\n",
        "class NAG(Optimizer):\n",
        "    def __init__(self, eta=1e-2, mu=0.9, *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.eta = eta\n",
        "        self.mu = mu\n",
        "\n",
        "        # 一つ前のステップの値を保持\n",
        "        self.dw = 1e-8\n",
        "        self.db = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, w=0, b=0, dfw=None, dfb=None,\n",
        "               nargs=2, *args, **kwds):\n",
        "        if nargs == 1:\n",
        "            grad_w = dfw(w + self.mu*self.dw)\n",
        "            grad_b = 1e-8\n",
        "        elif nargs == 2:\n",
        "            grad_w = dfw(w + self.mu*self.dw, b + self.mu*self.db)\n",
        "            grad_b = dfb(w + self.mu*self.dw, b + self.mu*self.db)\n",
        "\n",
        "        dw = self.mu*self.dw - (1-self.mu)*self.eta*grad_w\n",
        "        db = self.mu*self.db - (1-self.mu)*self.eta*grad_b\n",
        "        self.dw = dw\n",
        "        self.db = db\n",
        "        return dw, db\n",
        "    \n",
        "    gpu_update = cpu_update\n",
        "\n",
        "\n",
        "class AdaGrad(Optimizer):\n",
        "    def __init__(self, eta=1e-3, *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.eta = eta\n",
        "\n",
        "        # 一つ前のステップの値を保持する\n",
        "        self.gw = 1e-8\n",
        "        self.gb = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, *args, **kwds):\n",
        "        self.gw += grad_w*grad_w\n",
        "        self.gb += grad_b*grad_b\n",
        "\n",
        "        dw = -self.eta*grad_w/np.sqrt(self.gw)\n",
        "        db = -self.eta*grad_b/np.sqrt(self.gb)\n",
        "        return dw, db\n",
        "    \n",
        "    def gpu_update(self, grad_w, grad_b, *args, **kwds):\n",
        "        self.gw += grad_w*grad_w\n",
        "        self.gb += grad_b*grad_b\n",
        "\n",
        "        dw = -self.eta*grad_w/cp.sqrt(self.gw)\n",
        "        db = -self.eta*grad_b/cp.sqrt(self.gb)\n",
        "        return dw, db\n",
        "\n",
        "\n",
        "class RMSprop(Optimizer):\n",
        "    def __init__(self, eta=1e-2, rho=0.99, eps=1e-8, *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.eta = eta\n",
        "        self.rho = rho\n",
        "        self.eps = eps\n",
        "\n",
        "        # 一つ前のステップの値を保持する\n",
        "        self.vw = 1e-8\n",
        "        self.vb = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, *args, **kwds):\n",
        "        self.vw += (1-self.rho)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.rho)*(grad_b**2 - self.vb)\n",
        "\n",
        "        dw = -self.eta*grad_w/np.sqrt(self.vw+self.eps)\n",
        "        db = -self.eta*grad_b/np.sqrt(self.vb+self.eps)\n",
        "        return dw, db\n",
        "    \n",
        "    def gpu_update(self, grad_w, grad_b, *args, **kwds):\n",
        "        self.vw += (1-self.rho)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.rho)*(grad_b**2 - self.vb)\n",
        "\n",
        "        dw = -self.eta*grad_w/cp.sqrt(self.vw+self.eps)\n",
        "        db = -self.eta*grad_b/cp.sqrt(self.vb+self.eps)\n",
        "        return dw, db\n",
        "\n",
        "\n",
        "class AdaDelta(Optimizer):\n",
        "    def __init__(self, rho=0.95, eps=1e-6, *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.rho = rho\n",
        "        self.eps = eps\n",
        "\n",
        "        # 一つ前のステップの値を保持する\n",
        "        self.vw = 1e-8\n",
        "        self.vb = 1e-8\n",
        "        self.uw = 1e-8\n",
        "        self.ub = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, *args, **kwds):\n",
        "        self.vw += (1-self.rho)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.rho)*(grad_b**2 - self.vb)\n",
        "\n",
        "        dw = -grad_w*np.sqrt(self.uw+self.eps)/np.sqrt(self.vw+self.eps)\n",
        "        db = -grad_b*np.sqrt(self.ub+self.eps)/np.sqrt(self.vb+self.eps)\n",
        "\n",
        "        self.uw += (1-self.rho)*(dw**2 - self.uw)\n",
        "        self.ub += (1-self.rho)*(db**2 - self.ub)\n",
        "\n",
        "        return dw, db\n",
        "    \n",
        "    def gpu_update(self, grad_w, grad_b, *args, **kwds):\n",
        "        self.vw += (1-self.rho)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.rho)*(grad_b**2 - self.vb)\n",
        "\n",
        "        dw = -grad_w*cp.sqrt(self.uw+self.eps)/cp.sqrt(self.vw+self.eps)\n",
        "        db = -grad_b*cp.sqrt(self.ub+self.eps)/cp.sqrt(self.vb+self.eps)\n",
        "\n",
        "        self.uw += (1-self.rho)*(dw**2 - self.uw)\n",
        "        self.ub += (1-self.rho)*(db**2 - self.ub)\n",
        "\n",
        "        return dw, db\n",
        "\n",
        "\n",
        "class Adam(Optimizer):\n",
        "    def __init__(self, alpha=1e-3, beta1=0.9, beta2=0.999, eps=1e-8,\n",
        "                 *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.alpha = alpha\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.eps = eps\n",
        "\n",
        "        # 一つ前のステップの値を保持する\n",
        "        self.mw = 1e-8\n",
        "        self.mb = 1e-8\n",
        "        self.vw = 1e-8\n",
        "        self.vb = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
        "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
        "\n",
        "        alpha_t = self.alpha*np.sqrt(1-self.beta2**t)/(1-self.beta1**t)\n",
        "        dw = -alpha_t*self.mw/(np.sqrt(self.vw+self.eps))\n",
        "        db = -alpha_t*self.mb/(np.sqrt(self.vb+self.eps))\n",
        "        return dw, db\n",
        "    \n",
        "    def gpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
        "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
        "\n",
        "        alpha_t = self.alpha*cp.sqrt(1-self.beta2**t)/(1-self.beta1**t)\n",
        "        dw = -alpha_t*self.mw/(cp.sqrt(self.vw+self.eps))\n",
        "        db = -alpha_t*self.mb/(cp.sqrt(self.vb+self.eps))\n",
        "        return dw, db\n",
        "\n",
        "\n",
        "class RMSpropGraves(Optimizer):\n",
        "    def __init__(self, eta=1e-4, rho=0.95, eps=1e-4, *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.eta = eta\n",
        "        self.rho = rho\n",
        "        self.eps = eps\n",
        "\n",
        "        # 一つ前のステップの値を保持する\n",
        "        self.mw = 1e-8\n",
        "        self.mb = 1e-8\n",
        "        self.vw = 1e-8\n",
        "        self.vb = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self,grad_w, grad_b, *args, **kwds):\n",
        "        self.mw += (1-self.rho)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.rho)*(grad_b - self.mb)\n",
        "        self.vw += (1-self.rho)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.rho)*(grad_b**2 - self.vb)\n",
        "\n",
        "        dw = -self.eta*grad_w/np.sqrt(self.vw - self.mw**2 + self.eps)\n",
        "        db = -self.eta*grad_b/np.sqrt(self.vb - self.mb**2 + self.eps)\n",
        "        return dw, db\n",
        "    \n",
        "    def gpu_update(self,grad_w, grad_b, *args, **kwds):\n",
        "        self.mw += (1-self.rho)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.rho)*(grad_b - self.mb)\n",
        "        self.vw += (1-self.rho)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.rho)*(grad_b**2 - self.vb)\n",
        "\n",
        "        dw = -self.eta*grad_w/cp.sqrt(self.vw - self.mw**2 + self.eps)\n",
        "        db = -self.eta*grad_b/cp.sqrt(self.vb - self.mb**2 + self.eps)\n",
        "        return dw, db\n",
        "\n",
        "\n",
        "class SMORMS3(Optimizer):\n",
        "    def __init__(self, eta=1e-3, eps=1e-8, *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.eta = eta\n",
        "        self.eps = eps\n",
        "\n",
        "        # 一つ前のステップの値を保持する\n",
        "        self.zetaw = 1e-8\n",
        "        self.zetab = 1e-8\n",
        "        self.sw = 1\n",
        "        self.sb = 1\n",
        "        self.mw = 1e-8\n",
        "        self.mb = 1e-8\n",
        "        self.vw = 1e-8\n",
        "        self.vb = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, *args, **kwds):\n",
        "        rhow = 1/(1+self.sw)\n",
        "        rhob = 1/(1+self.sb)\n",
        "\n",
        "        self.mw += (1-rhow)*(grad_w - self.mw)\n",
        "        self.mb += (1-rhob)*(grad_b - self.mb)\n",
        "        self.vw += (1-rhow)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-rhob)*(grad_b**2 - self.vb)\n",
        "\n",
        "        self.zetaw = self.mw**2 / (self.vw + self.eps)\n",
        "        self.zetaw = self.mb**2 / (self.vb + self.eps)\n",
        "\n",
        "        dw = -grad_w*(np.minimum(self.eta, self.zetaw)\n",
        "                      /np.sqrt(self.vw + self.eps))\n",
        "        db = -grad_b*(np.minimum(self.eta, self.zetab)\n",
        "                      /np.sqrt(self.vb + self.eps))\n",
        "\n",
        "        self.sw = 1 + (1 - self.zetaw)*self.sw\n",
        "        self.sb = 1 + (1 - self.zetab)*self.sb\n",
        "\n",
        "        return dw, db\n",
        "    \n",
        "    def gpu_update(self, grad_w, grad_b, *args, **kwds):\n",
        "        rhow = 1/(1+self.sw)\n",
        "        rhob = 1/(1+self.sb)\n",
        "\n",
        "        self.mw += (1-rhow)*(grad_w - self.mw)\n",
        "        self.mb += (1-rhob)*(grad_b - self.mb)\n",
        "        self.vw += (1-rhow)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-rhob)*(grad_b**2 - self.vb)\n",
        "\n",
        "        self.zetaw = self.mw**2 / (self.vw + self.eps)\n",
        "        self.zetaw = self.mb**2 / (self.vb + self.eps)\n",
        "\n",
        "        dw = -grad_w*(cp.minimum(self.eta, self.zetaw)\n",
        "                      /cp.sqrt(self.vw + self.eps))\n",
        "        db = -grad_b*(cp.minimum(self.eta, self.zetab)\n",
        "                      /cp.sqrt(self.vb + self.eps))\n",
        "\n",
        "        self.sw = 1 + (1 - self.zetaw)*self.sw\n",
        "        self.sb = 1 + (1 - self.zetab)*self.sb\n",
        "\n",
        "        return dw, db\n",
        "\n",
        "\n",
        "class AdaMax(Optimizer):\n",
        "    def __init__(self, alpha=2e-3, beta1=0.9, beta2=0.999,\n",
        "                 *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.alpha = alpha\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "\n",
        "        # 一つ前のステップの値を保持する\n",
        "        self.mw = 1e-8\n",
        "        self.mb = 1e-8\n",
        "        self.uw = 1e-8\n",
        "        self.ub = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
        "        self.uw = np.maximum(self.beta2*self.uw, np.abs(grad_w))\n",
        "        self.ub = np.maximum(self.beta2*self.ub, np.abs(grad_b))\n",
        "\n",
        "        alpha_t = self.alpha/(1 - self.beta1**t)\n",
        "        dw = -alpha_t*self.mw/self.uw\n",
        "        db = -alpha_t*self.mb/self.ub\n",
        "        return dw, db\n",
        "    \n",
        "    def gpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
        "        self.uw = cp.maximum(self.beta2*self.uw, cp.abs(grad_w))\n",
        "        self.ub = cp.maximum(self.beta2*self.ub, cp.abs(grad_b))\n",
        "\n",
        "        alpha_t = self.alpha/(1 - self.beta1**t)\n",
        "        dw = -alpha_t*self.mw/self.uw\n",
        "        db = -alpha_t*self.mb/self.ub\n",
        "        return dw, db\n",
        "\n",
        "\n",
        "class Nadam(Optimizer):\n",
        "    def __init__(self, alpha=2e-3, mu=0.975, nu=0.999, eps=1e-8,\n",
        "                 *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.alpha = alpha\n",
        "        self.mu = mu\n",
        "        self.nu = nu\n",
        "        self.eps = eps\n",
        "\n",
        "        # 一つ前のステップの値を保持する\n",
        "        self.mw = 1e-8\n",
        "        self.mb = 1e-8\n",
        "        self.vw = 1e-8\n",
        "        self.vb = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        self.mw += (1-self.mu)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.mu)*(grad_b - self.mb)\n",
        "        self.vw += (1-self.nu)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.nu)*(grad_b**2 - self.vb)\n",
        "\n",
        "        mhatw = (self.mu*self.mw/(1-self.mu**(t+1))\n",
        "                 + (1-self.mu)*grad_w/(1-self.mu**t))\n",
        "        mhatb = (self.mu*self.mb/(1-self.mu**(t+1))\n",
        "                 + (1-self.mu)*grad_b/(1-self.mu**t))\n",
        "        vhatw = self.nu*self.vw/(1-self.nu**t)\n",
        "        vhatb = self.nu*self.vb/(1-self.nu**t)\n",
        "\n",
        "        dw = -self.alpha*mhatw/np.sqrt(vhatw + self.eps)\n",
        "        db = -self.alpha*mhatb/np.sqrt(vhatb + self.eps)\n",
        "        return dw, db\n",
        "    \n",
        "    def gpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        self.mw += (1-self.mu)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.mu)*(grad_b - self.mb)\n",
        "        self.vw += (1-self.nu)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.nu)*(grad_b**2 - self.vb)\n",
        "\n",
        "        mhatw = (self.mu*self.mw/(1-self.mu**(t+1))\n",
        "                 + (1-self.mu)*grad_w/(1-self.mu**t))\n",
        "        mhatb = (self.mu*self.mb/(1-self.mu**(t+1))\n",
        "                 + (1-self.mu)*grad_b/(1-self.mu**t))\n",
        "        vhatw = self.nu*self.vw/(1-self.nu**t)\n",
        "        vhatb = self.nu*self.vb/(1-self.nu**t)\n",
        "\n",
        "        dw = -self.alpha*mhatw/cp.sqrt(vhatw + self.eps)\n",
        "        db = -self.alpha*mhatb/cp.sqrt(vhatb + self.eps)\n",
        "        return dw, db\n",
        "\n",
        "\n",
        "class Eve(Optimizer):\n",
        "    def __init__(self, alpha=1e-3, beta1=0.9, beta2=0.999, beta3=0.999,\n",
        "                 c=10, eps=1e-8, fstar=0, *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.alpha = alpha\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.beta3 = beta3\n",
        "        self.c = c\n",
        "        self.eps = eps\n",
        "\n",
        "        # 一つ前のステップの値を保持する\n",
        "        self.mw = 1e-8\n",
        "        self.mb = 1e-8\n",
        "        self.vw = 1e-8\n",
        "        self.vb = 1e-8\n",
        "        self.f = 0\n",
        "        self.fstar = fstar\n",
        "        self.dtilde_w = 1e-8\n",
        "        self.dtilde_b = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, t=1, f=1, *args, **kwds):\n",
        "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
        "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
        "\n",
        "        mhatw = self.mw/(1 - self.beta1**t)\n",
        "        mhatb = self.mb/(1 - self.beta1**t)\n",
        "        vhatw = self.vw/(1 - self.beta2**t)\n",
        "        vhatb = self.vb/(1 - self.beta2**t)\n",
        "\n",
        "        if t > 1:\n",
        "            d_w = (np.abs(f-self.fstar)\n",
        "                    /(np.minimum(f, self.f) - self.fstar))\n",
        "            d_b = (np.abs(f-self.fstar)\n",
        "                    /(np.minimum(f, self.f) - self.fstar))\n",
        "            dhat_w = np.clip(d_w, 1/self.c, self.c)\n",
        "            dhat_b = np.clip(d_b, 1/self.c, self.c)\n",
        "            self.dtilde_w += (1 - self.beta3)*(dhat_w - self.dtilde_w)\n",
        "            self.dtilde_b += (1 - self.beta3)*(dhat_b - self.dtilde_b)\n",
        "        else:\n",
        "            self.dtilde_w = 1\n",
        "            self.dtilde_b = 1\n",
        "\n",
        "        self.f = f\n",
        "\n",
        "        dw = -(self.alpha*mhatw\n",
        "               /(self.dtilde_w*(np.sqrt(vhatw) + self.eps)))\n",
        "        db = -(self.alpha*mhatb\n",
        "               /(self.dtilde_b*(np.sqrt(vhatb) + self.eps)))\n",
        "        return dw, db\n",
        "    \n",
        "    def gpu_update(self, grad_w, grad_b, t=1, f=1, *args, **kwds):\n",
        "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
        "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
        "\n",
        "        mhatw = self.mw/(1 - self.beta1**t)\n",
        "        mhatb = self.mb/(1 - self.beta1**t)\n",
        "        vhatw = self.vw/(1 - self.beta2**t)\n",
        "        vhatb = self.vb/(1 - self.beta2**t)\n",
        "\n",
        "        if t > 1:\n",
        "            d_w = (cp.abs(f-self.fstar)\n",
        "                    /(cp.minimum(f, self.f) - self.fstar))\n",
        "            d_b = (cp.abs(f-self.fstar)\n",
        "                    /(cp.minimum(f, self.f) - self.fstar))\n",
        "            dhat_w = cp.clip(d_w, 1/self.c, self.c)\n",
        "            dhat_b = cp.clip(d_b, 1/self.c, self.c)\n",
        "            self.dtilde_w += (1 - self.beta3)*(dhat_w - self.dtilde_w)\n",
        "            self.dtilde_b += (1 - self.beta3)*(dhat_b - self.dtilde_b)\n",
        "        else:\n",
        "            self.dtilde_w = 1\n",
        "            self.dtilde_b = 1\n",
        "\n",
        "        self.f = f\n",
        "\n",
        "        dw = -(self.alpha*mhatw\n",
        "               /(self.dtilde_w*(cp.sqrt(vhatw) + self.eps)))\n",
        "        db = -(self.alpha*mhatb\n",
        "               /(self.dtilde_b*(cp.sqrt(vhatb) + self.eps)))\n",
        "        return dw, db\n",
        "\n",
        "\n",
        "class SantaE(Optimizer):\n",
        "    def __init__(self, eta=1e-2, sigma=0.95, lambda_=1e-8,\n",
        "                 anne_func=lambda t, n: t**n, anne_rate=0.5,\n",
        "                 burnin=100, C=5, N=16,\n",
        "                 *args, **kwds):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            eta: Learning rate\n",
        "            sigma: Maybe in other cases;\n",
        "                    'rho' in RMSprop, AdaDelta, RMSpropGraves.\n",
        "                    'rhow' or 'rhob' in SMORMS3.\n",
        "                    'beta2' in Adam, Eve.\n",
        "                    'nu' in Nadam.\n",
        "                   To use calculation 'v'.\n",
        "            lambda_: Named 'eps'(ε) in other cases.\n",
        "            anne_func: Annealing function.\n",
        "                       To use calculation 'beta' at each timestep.\n",
        "                       Default is 'timestep'**'annealing rate'.\n",
        "                       The calculated value should be towards infinity\n",
        "                       as 't' increases.\n",
        "            anne_rate: Annealing rate.\n",
        "                       To use calculation 'beta' at each timestep.\n",
        "                       The second Argument of 'anne_func'.\n",
        "            burnin: Swith exploration and refinement.\n",
        "                    This should be specified by users.\n",
        "            C: To calculate first 'alpha'.\n",
        "            N: Number of minibatch.\n",
        "        \"\"\"\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.eta = eta\n",
        "        self.sigma = sigma\n",
        "        self.lambda_ = lambda_\n",
        "        self.anne_func = anne_func\n",
        "        self.anne_rate = anne_rate\n",
        "        self.burnin = burnin\n",
        "        self.N = N\n",
        "\n",
        "        # Keep one step before and Initialize.\n",
        "        self.alpha_w = np.sqrt(eta)*C\n",
        "        self.alpha_b = np.sqrt(eta)*C\n",
        "        self.vw = 1e-8\n",
        "        self.vb = 1e-8\n",
        "        self.gw = 1e-8\n",
        "        self.gb = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        try:\n",
        "            shape_w = grad_w.shape\n",
        "        except:\n",
        "            shape_w = (1, )\n",
        "        try:\n",
        "            shape_b = grad_b.shape\n",
        "        except:\n",
        "            shape_b = (1, )\n",
        "\n",
        "        if t == 1:\n",
        "            # Initialize uw, ub.\n",
        "            self.uw = np.sqrt(self.eta)*np.random.randn(*shape_w)\n",
        "            self.ub = np.sqrt(self.eta)*np.random.randn(*shape_b)\n",
        "\n",
        "        self.vw = (self.sigma*self.vw\n",
        "                   + grad_w*grad_w * (1 - self.sigma) / self.N**2)\n",
        "        self.vb = (self.sigma*self.vb\n",
        "                   + grad_b*grad_b * (1 - self.sigma) / self.N**2)\n",
        "\n",
        "        gw = 1/np.sqrt(self.lambda_ + np.sqrt(self.vw))\n",
        "        gb = 1/np.sqrt(self.lambda_ + np.sqrt(self.vb))\n",
        "\n",
        "        beta = self.anne_func(t, self.anne_rate)\n",
        "        if t < self.burnin:\n",
        "            # Exploration.\n",
        "            self.alpha_w += self.uw*self.uw - self.eta/beta\n",
        "            self.alpha_b += self.ub*self.ub - self.eta/beta\n",
        "\n",
        "            uw = (self.eta/beta * (1 - self.gw/gw)/self.uw\n",
        "                  + np.sqrt(2*self.eta/beta * self.gw)\n",
        "                  * np.random.randn(*shape_w))\n",
        "            ub = (self.eta/beta * (1 - self.gb/gb)/self.ub\n",
        "                  + np.sqrt(2*self.eta/beta * self.gb)\n",
        "                  * np.random.randn(*shape_b))\n",
        "        else:\n",
        "            # Refinement.\n",
        "            uw = 0\n",
        "            ub = 0\n",
        "\n",
        "        uw += (1 - self.alpha_w)*self.uw - self.eta*gw*grad_w\n",
        "        ub += (1 - self.alpha_b)*self.ub - self.eta*gb*grad_b\n",
        "\n",
        "        # Update values.\n",
        "        self.uw = uw\n",
        "        self.ub = ub\n",
        "        self.gw = gw\n",
        "        self.gb = gb\n",
        "\n",
        "        dw = gw*uw\n",
        "        db = gb*ub\n",
        "        return dw, db\n",
        "    \n",
        "    def gpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        try:\n",
        "            shape_w = grad_w.shape\n",
        "        except:\n",
        "            shape_w = (1, )\n",
        "        try:\n",
        "            shape_b = grad_b.shape\n",
        "        except:\n",
        "            shape_b = (1, )\n",
        "\n",
        "        if t == 1:\n",
        "            # Initialize uw, ub.\n",
        "            self.uw = cp.sqrt(self.eta)*cp.random.randn(*shape_w)\n",
        "            self.ub = cp.sqrt(self.eta)*cp.random.randn(*shape_b)\n",
        "\n",
        "        self.vw = (self.sigma*self.vw\n",
        "                   + grad_w*grad_w * (1 - self.sigma) / self.N**2)\n",
        "        self.vb = (self.sigma*self.vb\n",
        "                   + grad_b*grad_b * (1 - self.sigma) / self.N**2)\n",
        "\n",
        "        gw = 1/cp.sqrt(self.lambda_ + cp.sqrt(self.vw))\n",
        "        gb = 1/cp.sqrt(self.lambda_ + cp.sqrt(self.vb))\n",
        "\n",
        "        beta = self.anne_func(t, self.anne_rate)\n",
        "        if t < self.burnin:\n",
        "            # Exploration.\n",
        "            self.alpha_w += self.uw*self.uw - self.eta/beta\n",
        "            self.alpha_b += self.ub*self.ub - self.eta/beta\n",
        "\n",
        "            uw = (self.eta/beta * (1 - self.gw/gw)/self.uw\n",
        "                  + cp.sqrt(2*self.eta/beta * self.gw)\n",
        "                  * cp.random.randn(*shape_w))\n",
        "            ub = (self.eta/beta * (1 - self.gb/gb)/self.ub\n",
        "                  + cp.sqrt(2*self.eta/beta * self.gb)\n",
        "                  * cp.random.randn(*shape_b))\n",
        "        else:\n",
        "            # Refinement.\n",
        "            uw = 0\n",
        "            ub = 0\n",
        "\n",
        "        uw += (1 - self.alpha_w)*self.uw - self.eta*gw*grad_w\n",
        "        ub += (1 - self.alpha_b)*self.ub - self.eta*gb*grad_b\n",
        "\n",
        "        # Update values.\n",
        "        self.uw = uw\n",
        "        self.ub = ub\n",
        "        self.gw = gw\n",
        "        self.gb = gb\n",
        "\n",
        "        dw = gw*uw\n",
        "        db = gb*ub\n",
        "        return dw, db\n",
        "\n",
        "\n",
        "class SantaSSS(Optimizer):\n",
        "    def __init__(self, eta=1e-2, sigma=0.95, lambda_=1e-8,\n",
        "                 anne_func=lambda t, n: t**n, anne_rate=0.5,\n",
        "                 burnin=100, C=5, N=16,\n",
        "                 *args, **kwds):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            eta: Learning rate\n",
        "            sigma: Maybe in other cases;\n",
        "                    'rho' in RMSprop, AdaDelta, RMSpropGraves.\n",
        "                    'rhow' or 'rhob' in SMORMS3.\n",
        "                    'beta2' in Adam, Eve.\n",
        "                    'nu' in Nadam.\n",
        "                   To use calculation 'v'.\n",
        "            lambda_: Named 'eps'(ε) in other cases.\n",
        "            anne_func: Annealing function.\n",
        "                       To use calculation 'beta' at each timestep.\n",
        "                       Default is 'timestep'**'annealing rate'.\n",
        "                       The calculated value should be towards infinity\n",
        "                       as 't' increases.\n",
        "            anne_rate: Annealing rate.\n",
        "                       To use calculation 'beta' at each timestep.\n",
        "                       The second Argument of 'anne_func'.\n",
        "            burnin: Swith exploration and refinement.\n",
        "                    This should be specified by users.\n",
        "            C: To calculate first 'alpha'.\n",
        "            N: Number of minibatch.\n",
        "        \"\"\"\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.eta = eta\n",
        "        self.sigma = sigma\n",
        "        self.lambda_ = lambda_\n",
        "        self.anne_func = anne_func\n",
        "        self.anne_rate = anne_rate\n",
        "        self.burnin = burnin\n",
        "        self.N = N\n",
        "\n",
        "        # Keep one step before and Initialize.\n",
        "        self.alpha_w = np.sqrt(eta)*C\n",
        "        self.alpha_b = np.sqrt(eta)*C\n",
        "        self.vw = 1e-8\n",
        "        self.vb = 1e-8\n",
        "        self.gw = 1e-8\n",
        "        self.gb = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        try:\n",
        "            shape_w = grad_w.shape\n",
        "        except:\n",
        "            shape_w = (1, )\n",
        "        try:\n",
        "            shape_b = grad_b.shape\n",
        "        except:\n",
        "            shape_b = (1, )\n",
        "\n",
        "        if t == 1:\n",
        "            # Initialize uw, ub.\n",
        "            self.uw = np.sqrt(self.eta)*np.random.randn(*shape_w)\n",
        "            self.ub = np.sqrt(self.eta)*np.random.randn(*shape_b)\n",
        "\n",
        "        self.vw = (self.sigma*self.vw\n",
        "                   + grad_w*grad_w * (1 - self.sigma) / self.N**2)\n",
        "        self.vb = (self.sigma*self.vb\n",
        "                   + grad_b*grad_b * (1 - self.sigma) / self.N**2)\n",
        "\n",
        "        gw = 1/np.sqrt(self.lambda_ + np.sqrt(self.vw))\n",
        "        gb = 1/np.sqrt(self.lambda_ + np.sqrt(self.vb))\n",
        "\n",
        "        dw = 0.5*gw*self.uw\n",
        "        db = 0.5*gb*self.ub\n",
        "\n",
        "        beta = self.anne_func(t, self.anne_rate)\n",
        "        if t < self.burnin:\n",
        "            # Exploration.\n",
        "            self.alpha_w += (self.uw*self.uw - self.eta/beta)*0.5\n",
        "            self.alpha_b += (self.ub*self.ub - self.eta/beta)*0.5\n",
        "\n",
        "            uw = np.exp(-0.5*self.alpha_w)*self.uw\n",
        "            ub = np.exp(-0.5*self.alpha_b)*self.ub\n",
        "            uw += (-gw*grad_w*self.eta\n",
        "                        + np.sqrt(2*self.gw*self.eta/beta)\n",
        "                        * np.random.randn(*shape_w)\n",
        "                        + self.eta/beta*(1-self.gw/gw)/self.uw)\n",
        "            ub += (-gb*grad_b*self.eta\n",
        "                        + np.sqrt(2*self.gb*self.eta/beta)\n",
        "                        * np.random.randn(*shape_b)\n",
        "                        + self.eta/beta*(1-self.gb/gb)/self.ub)\n",
        "            uw *= np.exp(-0.5*self.alpha_w)\n",
        "            ub *= np.exp(-0.5*self.alpha_b)\n",
        "\n",
        "            self.alpha_w += (uw*uw - self.eta/beta)*0.5\n",
        "            self.alpha_b += (ub*ub - self.eta/beta)*0.5\n",
        "        else:\n",
        "            # Refinement.\n",
        "            uw = np.exp(-0.5*self.alpha_w)*self.uw\n",
        "            ub = np.exp(-0.5*self.alpha_b)*self.ub\n",
        "\n",
        "            uw -= gw*grad_w*self.eta\n",
        "            ub -= gb*grad_b*self.eta\n",
        "\n",
        "            uw *= np.exp(-0.5*self.alpha_w)\n",
        "            ub *= np.exp(-0.5*self.alpha_b)\n",
        "\n",
        "        # Update values.\n",
        "        self.uw = uw\n",
        "        self.ub = ub\n",
        "        self.gw = gw\n",
        "        self.gb = gb\n",
        "\n",
        "        dw = gw*uw*0.5\n",
        "        db = gb*ub*0.5\n",
        "        return dw, db\n",
        "    \n",
        "    def gpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        try:\n",
        "            shape_w = grad_w.shape\n",
        "        except:\n",
        "            shape_w = (1, )\n",
        "        try:\n",
        "            shape_b = grad_b.shape\n",
        "        except:\n",
        "            shape_b = (1, )\n",
        "\n",
        "        if t == 1:\n",
        "            # Initialize uw, ub.\n",
        "            self.uw = cp.sqrt(self.eta)*cp.random.randn(*shape_w)\n",
        "            self.ub = cp.sqrt(self.eta)*cp.random.randn(*shape_b)\n",
        "\n",
        "        self.vw = (self.sigma*self.vw\n",
        "                   + grad_w*grad_w * (1 - self.sigma) / self.N**2)\n",
        "        self.vb = (self.sigma*self.vb\n",
        "                   + grad_b*grad_b * (1 - self.sigma) / self.N**2)\n",
        "\n",
        "        gw = 1/cp.sqrt(self.lambda_ + cp.sqrt(self.vw))\n",
        "        gb = 1/cp.sqrt(self.lambda_ + cp.sqrt(self.vb))\n",
        "\n",
        "        dw = 0.5*gw*self.uw\n",
        "        db = 0.5*gb*self.ub\n",
        "\n",
        "        beta = self.anne_func(t, self.anne_rate)\n",
        "        if t < self.burnin:\n",
        "            # Exploration.\n",
        "            self.alpha_w += (self.uw*self.uw - self.eta/beta)*0.5\n",
        "            self.alpha_b += (self.ub*self.ub - self.eta/beta)*0.5\n",
        "\n",
        "            uw = cp.exp(-0.5*self.alpha_w)*self.uw\n",
        "            ub = cp.exp(-0.5*self.alpha_b)*self.ub\n",
        "            uw += (-gw*grad_w*self.eta\n",
        "                        + cp.sqrt(2*self.gw*self.eta/beta)\n",
        "                        * cp.random.randn(*shape_w)\n",
        "                        + self.eta/beta*(1-self.gw/gw)/self.uw)\n",
        "            ub += (-gb*grad_b*self.eta\n",
        "                        + cp.sqrt(2*self.gb*self.eta/beta)\n",
        "                        * cp.random.randn(*shape_b)\n",
        "                        + self.eta/beta*(1-self.gb/gb)/self.ub)\n",
        "            uw *= cp.exp(-0.5*self.alpha_w)\n",
        "            ub *= cp.exp(-0.5*self.alpha_b)\n",
        "\n",
        "            self.alpha_w += (uw*uw - self.eta/beta)*0.5\n",
        "            self.alpha_b += (ub*ub - self.eta/beta)*0.5\n",
        "        else:\n",
        "            # Refinement.\n",
        "            uw = cp.exp(-0.5*self.alpha_w)*self.uw\n",
        "            ub = cp.exp(-0.5*self.alpha_b)*self.ub\n",
        "\n",
        "            uw -= gw*grad_w*self.eta\n",
        "            ub -= gb*grad_b*self.eta\n",
        "\n",
        "            uw *= cp.exp(-0.5*self.alpha_w)\n",
        "            ub *= cp.exp(-0.5*self.alpha_b)\n",
        "\n",
        "        # Update values.\n",
        "        self.uw = uw\n",
        "        self.ub = ub\n",
        "        self.gw = gw\n",
        "        self.gb = gb\n",
        "\n",
        "        dw = gw*uw*0.5\n",
        "        db = gb*ub*0.5\n",
        "        return dw, db\n",
        "\n",
        "\n",
        "class AMSGrad(Optimizer):\n",
        "    def __init__(self, alpha=1e-3, beta1=0.9, beta2=0.999, eps=1e-8,\n",
        "                 *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.alpha = alpha\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.eps = eps\n",
        "\n",
        "        # 一つ前のステップの値を保持する\n",
        "        self.mw = 1e-8\n",
        "        self.mb = 1e-8\n",
        "        self.vw = 1e-8\n",
        "        self.vb = 1e-8\n",
        "        self.vhatw = 1e-8\n",
        "        self.vhatb = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
        "\n",
        "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
        "\n",
        "        self.vhatw = np.maximum(self.vhatw, self.vw)\n",
        "        self.vhatb = np.maximum(self.vhatb, self.vb)\n",
        "\n",
        "        alpha_t = self.alpha / np.sqrt(t)\n",
        "        dw = - alpha_t * self.mw/np.sqrt(self.vhatw + self.eps)\n",
        "        db = - alpha_t * self.mb/np.sqrt(self.vhatb + self.eps)\n",
        "        return dw, db\n",
        "    \n",
        "    def gpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
        "\n",
        "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
        "\n",
        "        self.vhatw = cp.maximum(self.vhatw, self.vw)\n",
        "        self.vhatb = cp.maximum(self.vhatb, self.vb)\n",
        "\n",
        "        alpha_t = self.alpha / cp.sqrt(t)\n",
        "        dw = - alpha_t * self.mw/cp.sqrt(self.vhatw + self.eps)\n",
        "        db = - alpha_t * self.mb/cp.sqrt(self.vhatb + self.eps)\n",
        "        return dw, db\n",
        "\n",
        "\n",
        "class AdaBound(Optimizer):\n",
        "    def __init__(self, alpha=1e-3, eta=1e-1, beta1=0.9, beta2=0.999,\n",
        "                 eps=1e-8, *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.alpha = alpha\n",
        "        self.eta = eta\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.eps = eps\n",
        "\n",
        "        # 一つ前のステップの値を保持する\n",
        "        self.mw = 1e-8\n",
        "        self.mb = 1e-8\n",
        "        self.vw = 1e-8\n",
        "        self.vb = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
        "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
        "\n",
        "        etal = self.eta*(1 - 1/((1-self.beta2)*t + 1))\n",
        "        etau = self.eta*(1 + 1/((1-self.beta2)*t + self.eps))\n",
        "        etahatw_t = np.clip(self.alpha/np.sqrt(self.vw), etal, etau)\n",
        "        etahatb_t = np.clip(self.alpha/np.sqrt(self.vb), etal, etau)\n",
        "        etaw_t = etahatw_t/np.sqrt(t)\n",
        "        etab_t = etahatb_t/np.sqrt(t)\n",
        "\n",
        "        dw = - etaw_t*self.mw\n",
        "        db = - etab_t*self.mb\n",
        "        return dw, db\n",
        "    \n",
        "    def gpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
        "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
        "\n",
        "        etal = self.eta*(1 - 1/((1-self.beta2)*t + 1))\n",
        "        etau = self.eta*(1 + 1/((1-self.beta2)*t + self.eps))\n",
        "        etahatw_t = cp.clip(self.alpha/cp.sqrt(self.vw), etal, etau)\n",
        "        etahatb_t = cp.clip(self.alpha/cp.sqrt(self.vb), etal, etau)\n",
        "        etaw_t = etahatw_t/cp.sqrt(t)\n",
        "        etab_t = etahatb_t/cp.sqrt(t)\n",
        "\n",
        "        dw = - etaw_t*self.mw\n",
        "        db = - etab_t*self.mb\n",
        "        return dw, db\n",
        "\n",
        "\n",
        "class AMSBound(Optimizer):\n",
        "    def __init__(self, alpha=1e-3, eta=1e-1, beta1=0.9, beta2=0.999,\n",
        "                 eps=1e-8, *args, **kwds):\n",
        "        super().__init__(*args, **kwds)\n",
        "\n",
        "        # ハイパーパラメータ\n",
        "        self.alpha = alpha\n",
        "        self.eta = eta\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.eps = eps\n",
        "\n",
        "        # 一つ前のステップの値を保持する\n",
        "        self.mw = 1e-8\n",
        "        self.mb = 1e-8\n",
        "        self.vw = 1e-8\n",
        "        self.vb = 1e-8\n",
        "        self.vhatw = 1e-8\n",
        "        self.vhatb = 1e-8\n",
        "\n",
        "\n",
        "    def cpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
        "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
        "        self.vhatw = np.maximum(self.vhatw, self.vw)\n",
        "        self.vhatb = np.maximum(self.vhatb, self.vb)\n",
        "\n",
        "        etal = self.eta*(1 - 1/((1-self.beta2)*t + 1))\n",
        "        etau = self.eta*(1 + 1/((1-self.beta2)*t + self.eps))\n",
        "        etahatw_t = np.clip(self.alpha/np.sqrt(self.vhatw), etal, etau)\n",
        "        etahatb_t = np.clip(self.alpha/np.sqrt(self.vhatb), etal, etau)\n",
        "        etaw_t = etahatw_t/np.sqrt(t)\n",
        "        etab_t = etahatb_t/np.sqrt(t)\n",
        "\n",
        "        dw = - etaw_t*self.mw\n",
        "        db = - etab_t*self.mb\n",
        "        return dw, db\n",
        "    \n",
        "    def gpu_update(self, grad_w, grad_b, t=1, *args, **kwds):\n",
        "        self.mw += (1-self.beta1)*(grad_w - self.mw)\n",
        "        self.mb += (1-self.beta1)*(grad_b - self.mb)\n",
        "        self.vw += (1-self.beta2)*(grad_w**2 - self.vw)\n",
        "        self.vb += (1-self.beta2)*(grad_b**2 - self.vb)\n",
        "        self.vhatw = cp.maximum(self.vhatw, self.vw)\n",
        "        self.vhatb = cp.maximum(self.vhatb, self.vb)\n",
        "\n",
        "        etal = self.eta*(1 - 1/((1-self.beta2)*t + 1))\n",
        "        etau = self.eta*(1 + 1/((1-self.beta2)*t + self.eps))\n",
        "        etahatw_t = cp.clip(self.alpha/cp.sqrt(self.vhatw), etal, etau)\n",
        "        etahatb_t = cp.clip(self.alpha/cp.sqrt(self.vhatb), etal, etau)\n",
        "        etaw_t = etahatw_t/cp.sqrt(t)\n",
        "        etab_t = etahatb_t/cp.sqrt(t)\n",
        "\n",
        "        dw = - etaw_t*self.mw\n",
        "        db = - etab_t*self.mb\n",
        "        return dw, db"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfZR1GnpztUP"
      },
      "source": [
        "import string\n",
        "\n",
        "\n",
        "_opt_dic = {\n",
        "    \"sgd\": SGD,\n",
        "    \"msgd\": MSGD, \"momentum\": MSGD,\n",
        "    \"nag\": NAG,\n",
        "    \"adagrad\": AdaGrad,\n",
        "    \"rmsprop\": RMSprop,\n",
        "    \"adadelta\": AdaDelta,\n",
        "    \"adam\": Adam,\n",
        "    \"rmspropgraves\": RMSpropGraves,\n",
        "    \"smorms3\": SMORMS3,\n",
        "    \"adamax\": AdaMax,\n",
        "    \"nadam\": Nadam,\n",
        "    \"eve\": Eve,\n",
        "    \"santae\": SantaE,\n",
        "    \"santasss\": SantaSSS,\n",
        "    \"amsgrad\": AMSGrad,\n",
        "    \"adabound\": AdaBound,\n",
        "    \"amsbound\": AMSBound,\n",
        "}\n",
        "\n",
        "\n",
        "def get_opt(name, *args, **kwds):\n",
        "    name = name.lower().translate(str.maketrans( '', '',string.punctuation))\n",
        "    if name in _opt_dic.keys():\n",
        "        optimizer = _opt_dic[name](*args, **kwds)\n",
        "    else:\n",
        "        raise ValueError(name + \": Unknown optimizer\")\n",
        "\n",
        "    return optimizer"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDJ8iwlLztUS"
      },
      "source": [
        "# CNN util\n",
        "[目次へ戻る](#目次)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khGZQOT9ztUT"
      },
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "\n",
        "def cpu_im2col(images, filters, stride=1, pad=0):\n",
        "    if images.ndim == 2:\n",
        "        images = images.reshape(1, 1, *images.shape)\n",
        "    elif images.ndim == 3:\n",
        "        B, I_h, I_w = images.shape\n",
        "        images = images.reshape(B, 1, I_h, I_w)\n",
        "    B, C, I_h, I_w = images.shape\n",
        "    if isinstance(filters, tuple):\n",
        "        if len(filters) == 2:\n",
        "            filters = (1, 1, *filters)\n",
        "        elif len(filters) == 3:\n",
        "            M, F_h, F_w = filters\n",
        "            filters = (M, 1, F_h, F_w)\n",
        "        _, _, F_h, F_w = filters\n",
        "    else:\n",
        "        if filters.ndim == 2:\n",
        "            filters = filters.reshape(1, 1, *filters.shape)\n",
        "        elif filters.ndim == 3:\n",
        "            M, F_h, F_w = filters.shape\n",
        "            filters = filters.reshape(M, 1, F_h, F_w)\n",
        "        _, _, F_h, F_w = filters.shape\n",
        "    \n",
        "    if isinstance(stride, tuple):\n",
        "        stride_ud, stride_lr = stride\n",
        "    else:\n",
        "        stride_ud = stride\n",
        "        stride_lr = stride\n",
        "    if isinstance(pad, tuple):\n",
        "        pad_ud, pad_lr = pad\n",
        "    elif isinstance(pad, int):\n",
        "        pad_ud = pad\n",
        "        pad_lr = pad\n",
        "    elif pad == \"same\":\n",
        "        pad_ud = 0.5*((I_h - 1)*stride_ud - I_h + F_h)\n",
        "        pad_lr = 0.5*((I_w - 1)*stride_lr - I_w + F_w)\n",
        "    pad_zero = (0, 0)\n",
        "    \n",
        "    def get_O_shape(i, f, s, p):\n",
        "        return int((i - f + 2*p)//s + 1)\n",
        "    \n",
        "    O_h = get_O_shape(I_h, F_h, stride_ud, pad_ud)\n",
        "    O_w = get_O_shape(I_w, F_w, stride_lr, pad_lr)\n",
        "    \n",
        "    result_pad = (pad_ud, pad_lr)\n",
        "    pad_ud = int(np.ceil(pad_ud))\n",
        "    pad_lr = int(np.ceil(pad_lr))\n",
        "    pad_ud = (pad_ud, pad_ud)\n",
        "    pad_lr = (pad_lr, pad_lr)\n",
        "    images = np.pad(images, [pad_zero, pad_zero, pad_ud, pad_lr], \\\n",
        "                    \"constant\")\n",
        "    \n",
        "    cols = np.empty((B, C, F_h, F_w, O_h, O_w))\n",
        "    for h in range(F_h):\n",
        "        h_lim = h + stride_ud*O_h\n",
        "        for w in range(F_w):\n",
        "            w_lim = w + stride_lr*O_w\n",
        "            cols[:, :, h, w, :, :] \\\n",
        "                = images[:, :, h:h_lim:stride_ud, w:w_lim:stride_lr]\n",
        "    \n",
        "    results = []\n",
        "    results.append(cols.transpose(1, 2, 3, 0, 4, 5).reshape(C*F_h*F_w, B*O_h*O_w))\n",
        "    results.append((O_h, O_w))\n",
        "    results.append(result_pad)\n",
        "    return results\n",
        "\n",
        "\n",
        "def gpu_im2col(images, filters, stride=1, pad=0):\n",
        "    if images.ndim == 2:\n",
        "        images = images.reshape(1, 1, *images.shape)\n",
        "    elif images.ndim == 3:\n",
        "        B, I_h, I_w = images.shape\n",
        "        images = images.reshape(B, 1, I_h, I_w)\n",
        "    B, C, I_h, I_w = images.shape\n",
        "    if isinstance(filters, tuple):\n",
        "        if len(filters) == 2:\n",
        "            filters = (1, 1, *filters)\n",
        "        elif len(filters) == 3:\n",
        "            M, F_h, F_w = filters\n",
        "            filters = (M, 1, F_h, F_w)\n",
        "        _, _, F_h, F_w = filters\n",
        "    else:\n",
        "        if filters.ndim == 2:\n",
        "            filters = filters.reshape(1, 1, *filters.shape)\n",
        "        elif filters.ndim == 3:\n",
        "            M, F_h, F_w = filters.shape\n",
        "            filters = filters.reshape(M, 1, F_h, F_w)\n",
        "        _, _, F_h, F_w = filters.shape\n",
        "    \n",
        "    if isinstance(stride, tuple):\n",
        "        stride_ud, stride_lr = stride\n",
        "    else:\n",
        "        stride_ud = stride\n",
        "        stride_lr = stride\n",
        "    if isinstance(pad, tuple):\n",
        "        pad_ud, pad_lr = pad\n",
        "    elif isinstance(pad, int):\n",
        "        pad_ud = pad\n",
        "        pad_lr = pad\n",
        "    elif pad == \"same\":\n",
        "        pad_ud = 0.5*((I_h - 1)*stride_ud - I_h + F_h)\n",
        "        pad_lr = 0.5*((I_w - 1)*stride_lr - I_w + F_w)\n",
        "    pad_zero = (0, 0)\n",
        "    \n",
        "    def get_O_shape(i, f, s, p):\n",
        "        return int((i - f + 2*p)//s + 1)\n",
        "    \n",
        "    O_h = get_O_shape(I_h, F_h, stride_ud, pad_ud)\n",
        "    O_w = get_O_shape(I_w, F_w, stride_lr, pad_lr)\n",
        "    \n",
        "    result_pad = (pad_ud, pad_lr)\n",
        "    pad_ud = int(np.ceil(pad_ud))\n",
        "    pad_lr = int(np.ceil(pad_lr))\n",
        "    pad_ud = (pad_ud, pad_ud)\n",
        "    pad_lr = (pad_lr, pad_lr)\n",
        "    images = cp.pad(images, [pad_zero, pad_zero, pad_ud, pad_lr], \\\n",
        "                    \"constant\")\n",
        "    \n",
        "    cols = cp.empty((B, C, F_h, F_w, O_h, O_w))\n",
        "    for h in range(F_h):\n",
        "        h_lim = h + stride_ud*O_h\n",
        "        for w in range(F_w):\n",
        "            w_lim = w + stride_lr*O_w\n",
        "            cols[:, :, h, w, :, :] \\\n",
        "                = images[:, :, h:h_lim:stride_ud, w:w_lim:stride_lr]\n",
        "    \n",
        "    results = []\n",
        "    results.append(cols.transpose(1, 2, 3, 0, 4, 5).reshape(C*F_h*F_w, B*O_h*O_w))\n",
        "    results.append((O_h, O_w))\n",
        "    results.append(result_pad)\n",
        "    return results"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IjMMN5sztUV"
      },
      "source": [
        "import numpy as np\n",
        "import cupy as np\n",
        "\n",
        "\n",
        "def cpu_col2im(cols, I_shape, O_shape, stride=1, pad=0):\n",
        "    if len(I_shape) == 2:\n",
        "        B, C, I_h, I_w = 1, 1, *I_shape\n",
        "    elif len(I_shape) == 3:\n",
        "        C, B, I_h, I_w = 1, *I_shape\n",
        "    else:\n",
        "        B, C, I_h, I_w = I_shape\n",
        "    M, O_h, O_w = O_shape\n",
        "    \n",
        "    if isinstance(stride, tuple):\n",
        "        stride_ud, stride_lr = stride\n",
        "    else:\n",
        "        stride_ud = stride\n",
        "        stride_lr = stride\n",
        "    if isinstance(pad, tuple):\n",
        "        pad_ud, pad_lr = pad\n",
        "    elif isinstance(pad, int):\n",
        "        pad_ud = pad\n",
        "        pad_lr = pad\n",
        "    \n",
        "    def get_f_shape(i, o, s, p):\n",
        "        return int(i + 2*p - (o - 1)*s)\n",
        "    \n",
        "    F_h = get_f_shape(I_h, O_h, stride_ud, pad_ud)\n",
        "    F_w = get_f_shape(I_w, O_w, stride_lr, pad_lr)\n",
        "    pad_ud = int(np.ceil(pad_ud))\n",
        "    pad_lr = int(np.ceil(pad_lr))\n",
        "    cols = cols.reshape(C, F_h, F_w, B, O_h, O_w).transpose(3, 0, 1, 2, 4, 5)\n",
        "    images = np.zeros((B, C, I_h+2*pad_ud+stride_ud-1, I_w+2*pad_lr+stride_lr-1))\n",
        "    \n",
        "    for h in range(F_h):\n",
        "        h_lim = h + stride_ud*O_h\n",
        "        for w in range(F_w):\n",
        "            w_lim = w + stride_lr*O_w\n",
        "            images[:, :, h:h_lim:stride_ud, w:w_lim:stride_lr] += cols[:, :, h, w, :, :]\n",
        "    \n",
        "    return images[:, :, pad_ud : I_h+pad_ud, pad_lr : I_w+pad_lr]\n",
        "\n",
        "\n",
        "def gpu_col2im(cols, I_shape, O_shape, stride=1, pad=0):\n",
        "    if len(I_shape) == 2:\n",
        "        B, C, I_h, I_w = 1, 1, *I_shape\n",
        "    elif len(I_shape) == 3:\n",
        "        C, B, I_h, I_w = 1, *I_shape\n",
        "    else:\n",
        "        B, C, I_h, I_w = I_shape\n",
        "    M, O_h, O_w = O_shape\n",
        "    \n",
        "    if isinstance(stride, tuple):\n",
        "        stride_ud, stride_lr = stride\n",
        "    else:\n",
        "        stride_ud = stride\n",
        "        stride_lr = stride\n",
        "    if isinstance(pad, tuple):\n",
        "        pad_ud, pad_lr = pad\n",
        "    elif isinstance(pad, int):\n",
        "        pad_ud = pad\n",
        "        pad_lr = pad\n",
        "    \n",
        "    def get_f_shape(i, o, s, p):\n",
        "        return int(i + 2*p - (o - 1)*s)\n",
        "    \n",
        "    F_h = get_f_shape(I_h, O_h, stride_ud, pad_ud)\n",
        "    F_w = get_f_shape(I_w, O_w, stride_lr, pad_lr)\n",
        "    pad_ud = int(np.ceil(pad_ud))\n",
        "    pad_lr = int(np.ceil(pad_lr))\n",
        "    cols = cols.reshape(C, F_h, F_w, B, O_h, O_w).transpose(3, 0, 1, 2, 4, 5)\n",
        "\n",
        "    images = cp.zeros((B, C, I_h+2*pad_ud+stride_ud-1,\n",
        "                             I_w+2*pad_lr+stride_lr-1))\n",
        "    for h in range(F_h):\n",
        "        h_lim = h + stride_ud*O_h\n",
        "        for w in range(F_w):\n",
        "            w_lim = w + stride_lr*O_w\n",
        "            images[:, :, h:h_lim:stride_ud, w:w_lim:stride_lr] \\\n",
        "                += cols[:, :, h, w, :, :]\n",
        "    \n",
        "    return images[:, :, pad_ud : I_h+pad_ud, pad_lr : I_w+pad_lr]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8pleeAhztUY"
      },
      "source": [
        "# レイヤ\n",
        "[目次へ戻る](#目次)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTGzyMb5ztUY"
      },
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "\n",
        "class BaseLayer():\n",
        "    \"\"\"\n",
        "    全ての元となるレイヤークラス\n",
        "    中間層と出力層で共通する処理を記述する。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *, mode=\"cpu\",\n",
        "                 prev=1, n=1,\n",
        "                 name=\"\", wb_width=5e-2,\n",
        "                 act=\"ReLU\", opt=\"Adam\",\n",
        "                 act_dic=None, opt_dic=None, **kwds):\n",
        "        if act_dic is None:\n",
        "            act_dic = {}\n",
        "        if opt_dic is None:\n",
        "            opt_dic = {}\n",
        "        \n",
        "        # GPU利用かどうか\n",
        "        self.mode = mode\n",
        "        \n",
        "        self.prev = prev  # 一つ前の層の出力数 = この層への入力数\n",
        "        self.n = n        # この層の出力数 = 次の層への入力数\n",
        "        self.name = name  # この層の名前\n",
        "\n",
        "        # 重みとバイアスを設定\n",
        "        if mode == \"cpu\":\n",
        "            self.w = wb_width*np.random.randn(prev, n)\n",
        "            self.b = wb_width*np.random.randn(n)\n",
        "        elif mode == \"gpu\":\n",
        "            self.w = wb_width*cp.random.randn(prev, n)\n",
        "            self.b = wb_width*cp.random.randn(n)\n",
        "\n",
        "        # 活性化関数(クラス)を取得\n",
        "        self.act = get_act(act, mode=mode, **act_dic)\n",
        "\n",
        "        # 最適化子(クラス)を取得\n",
        "        self.opt = get_opt(opt, mode=mode, **opt_dic)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        順伝播の実装\n",
        "        \"\"\"\n",
        "        # 入力を記憶しておく\n",
        "        self.x = x\n",
        "\n",
        "        # 順伝播\n",
        "        self.u = x@self.w + self.b\n",
        "        self.y = self.act.forward(self.u)\n",
        "        \n",
        "        return self.y\n",
        "\n",
        "\n",
        "    def backward(self, grad):\n",
        "        \"\"\"\n",
        "        逆伝播の実装\n",
        "        \"\"\"\n",
        "        dact = grad*self.act.backward(self.u, self.y)\n",
        "        self.grad_w = self.x.T@dact\n",
        "        if self.mode == \"cpu\":\n",
        "            self.grad_b = np.sum(dact, axis=0)\n",
        "        elif self.mode == \"gpu\":\n",
        "            self.grad_b = cp.sum(dact, axis=0)\n",
        "        self.grad_x = dact@self.w.T\n",
        "\n",
        "        return self.grad_x\n",
        "\n",
        "\n",
        "    def update(self, **kwds):\n",
        "        \"\"\"\n",
        "        パラメータ学習の実装\n",
        "        \"\"\"\n",
        "        dw, db = self.opt.update(self.grad_w, self.grad_b, **kwds)\n",
        "\n",
        "        self.w += dw\n",
        "        self.b += db"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8gUFD65ztUa"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class MiddleLayer(BaseLayer):\n",
        "    \"\"\"\n",
        "    中間層クラス\n",
        "    入力層も実装上は中間層の一つとして取り扱います。\n",
        "    \"\"\"\n",
        "    pass"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNHDn5SgztUd"
      },
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "\n",
        "softmax = type(get_act(\"softmax\"))\n",
        "sigmoid = type(get_act(\"sigmoid\"))\n",
        "cross = type(get_err(\"Cross\"))\n",
        "binary = type(get_err(\"Binary\"))\n",
        "\n",
        "\n",
        "class OutputLayer(BaseLayer):\n",
        "    \"\"\"\n",
        "    出力層クラス\n",
        "    \"\"\"\n",
        "    def __init__(self, *, err_func=\"Square\", **kwds):\n",
        "        # 損失関数(クラス)を取得\n",
        "        self.errfunc = get_err(err_func)\n",
        "\n",
        "        super().__init__(**kwds)\n",
        "    \n",
        "\n",
        "    def backward(self, t):\n",
        "        \"\"\"\n",
        "        逆伝播の実装\n",
        "        \"\"\"\n",
        "        # 出力層の活性化関数がsoftmax関数で損失関数が交差エントロピー誤差の場合\n",
        "        # 誤差の伝播を場合分けしておく\n",
        "        if isinstance(self.act, softmax) \\\n",
        "        and isinstance(self.errfunc, cross):\n",
        "            dact = self.y - t\n",
        "            self.grad_w = self.x.T@dact\n",
        "            if self.mode == \"cpu\":\n",
        "                self.grad_b = np.sum(dact, axis=0)\n",
        "            elif self.mode == \"gpu\":\n",
        "                self.grad_b = cp.sum(dact, axis=0)\n",
        "            self.grad_x = dact@self.w.T\n",
        "\n",
        "            return self.grad_x\n",
        "        elif isinstance(self.act, sigmoid) \\\n",
        "         and isinstance(self.errfunc, binary):\n",
        "            dact = self.y - t\n",
        "            self.grad_w = self.x.T@dact\n",
        "            if self.mode == \"cpu\":\n",
        "                self.grad_b = np.sum(dact, axis=0)\n",
        "            elif self.mode == \"gpu\":\n",
        "                self.grad_b = cp.sum(dact, axis=0)\n",
        "            self.grad_x = dact@self.w.T\n",
        "\n",
        "            return self.grad_x\n",
        "        else:\n",
        "            grad = self.errfunc.backward(self.y, t)\n",
        "            return super().backward(grad)\n",
        "\n",
        "\n",
        "    def get_error(self, t):\n",
        "        self.error = self.errfunc.forward(self.y, t) / t.shape[0]\n",
        "        return self.errfunc.total_error()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM5fr0hJztUf"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class ConvLayer(BaseLayer):\n",
        "    def __init__(self, *, mode=\"cpu\",\n",
        "                 I_shape=None, F_shape=None,\n",
        "                 stride=1, pad=\"same\",\n",
        "                 name=\"\", wb_width=5e-2,\n",
        "                 act=\"ReLU\", opt=\"Adam\",\n",
        "                 act_dic={}, opt_dic={}, **kwds):\n",
        "        # GPU利用かどうか\n",
        "        self.mode = mode\n",
        "\n",
        "        self.name = name\n",
        "        \n",
        "        if I_shape is None:\n",
        "            raise KeyError(\"Input shape is None.\")\n",
        "        if F_shape is None:\n",
        "            raise KeyError(\"Filter shape is None.\")\n",
        "        \n",
        "        if len(I_shape) == 2:\n",
        "            C, I_h, I_w = 1, *I_shape\n",
        "        else:\n",
        "            C, I_h, I_w = I_shape\n",
        "        self.I_shape = (C, I_h, I_w)\n",
        "        \n",
        "        if len(F_shape) == 2:\n",
        "            M, F_h, F_w = 1, *F_shape\n",
        "        else:\n",
        "            M, F_h, F_w = F_shape\n",
        "        self.F_shape = (M, C, F_h, F_w)\n",
        "        \n",
        "        # im2col関数とcol2im関数を保持\n",
        "        if self.mode == \"cpu\":\n",
        "            self.im2col = cpu_im2col\n",
        "            self.col2im = cpu_col2im\n",
        "        elif self.mode == \"gpu\":\n",
        "            self.im2col = gpu_im2col\n",
        "            self.col2im = gpu_col2im\n",
        "        \n",
        "        if self.mode == \"cpu\":\n",
        "            _, O_shape, self.pad_state = self.im2col(\n",
        "                np.zeros((1, *self.I_shape)),\n",
        "                self.F_shape,\n",
        "                stride=stride, pad=pad)\n",
        "        elif self.mode == \"gpu\":\n",
        "            _, O_shape, self.pad_state = self.im2col(\n",
        "                cp.zeros((1, *self.I_shape)),\n",
        "                self.F_shape,\n",
        "                stride=stride, pad=pad)\n",
        "        self.O_shape = (M, *O_shape)\n",
        "        self.stride = stride\n",
        "        \n",
        "        self.n = np.prod(self.O_shape)\n",
        "        \n",
        "        # フィルタとバイアスを設定\n",
        "        if self.mode == \"cpu\":\n",
        "            self.w = wb_width*np.random.randn(*self.F_shape).reshape(M, -1).T\n",
        "            self.b = wb_width*np.random.randn(M)\n",
        "        elif self.mode == \"gpu\":\n",
        "            self.w = wb_width*cp.random.randn(*self.F_shape).reshape(M, -1).T\n",
        "            self.b = wb_width*cp.random.randn(M)\n",
        "        \n",
        "        # 活性化関数(クラス)を取得\n",
        "        self.act = get_act(act, mode=mode, **act_dic)\n",
        "\n",
        "        # 最適化子(クラス)を取得\n",
        "        self.opt = get_opt(opt, mode=mode, **opt_dic)\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        B = x.shape[0]\n",
        "        M, O_h, O_w = self.O_shape\n",
        "        \n",
        "        x, _, self.pad_state = self.im2col(x, self.F_shape,\n",
        "                                           stride=self.stride,\n",
        "                                           pad=self.pad_state)\n",
        "        super().forward(x.T)\n",
        "\n",
        "        return self.y.reshape(B, O_h, O_w, M).transpose(0, 3, 1, 2)\n",
        "    \n",
        "    \n",
        "    def backward(self, grad):\n",
        "        B = grad.shape[0]\n",
        "        I_shape = B, *self.I_shape\n",
        "        M, O_h, O_w = self.O_shape\n",
        "        \n",
        "        grad = grad.transpose(0, 2, 3, 1).reshape(-1, M)\n",
        "        super().backward(grad)\n",
        "        self.grad_x = self.col2im(self.grad_x.T, I_shape, self.O_shape,\n",
        "                                  stride=self.stride, pad=self.pad_state)\n",
        "        return self.grad_x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyN5e7_MztUh"
      },
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "\n",
        "class PoolingLayer(BaseLayer):\n",
        "    def __init__(self, *, mode=\"cpu\",\n",
        "                 I_shape=None, pool=1, pad=0,\n",
        "                 name=\"\", **kwds):\n",
        "        self.mode = mode\n",
        "\n",
        "        self.name = name\n",
        "        \n",
        "        if I_shape is None:\n",
        "            raise KeyError(\"Input shape is None.\")\n",
        "        \n",
        "        if len(I_shape) == 2:\n",
        "            C, I_h, I_w = 1, *I_shape\n",
        "        else:\n",
        "            C, I_h, I_w = I_shape\n",
        "        self.I_shape = (C, I_h, I_w)\n",
        "\n",
        "        # im2col関数とcol2im関数を保持\n",
        "        if self.mode == \"cpu\":\n",
        "            self.im2col = cpu_im2col\n",
        "            self.col2im = cpu_col2im\n",
        "        elif self.mode == \"gpu\":\n",
        "            self.im2col = gpu_im2col\n",
        "            self.col2im = gpu_col2im\n",
        "        \n",
        "        if self.mode == \"cpu\":\n",
        "            _, O_shape, self.pad_state = self.im2col(\n",
        "                np.zeros((1, *self.I_shape)),\n",
        "                (pool, pool),\n",
        "                stride=pool, pad=pad)\n",
        "        elif self.mode == \"gpu\":\n",
        "            _, O_shape, self.pad_state = self.im2col(\n",
        "                cp.zeros((1, *self.I_shape)),\n",
        "                (pool, pool),\n",
        "                stride=pool, pad=pad)\n",
        "        self.O_shape = (C, *O_shape)\n",
        "        \n",
        "        self.n = np.prod(self.O_shape)\n",
        "        \n",
        "        self.pool = pool\n",
        "        self.F_shape = (pool, pool)\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        B = x.shape[0]\n",
        "        C, O_h, O_w = self.O_shape\n",
        "        \n",
        "        self.x, _, self.pad_state = self.im2col(x, self.F_shape,\n",
        "                                                stride=self.pool,\n",
        "                                                pad=self.pad_state)\n",
        "        self.x = self.x.T.reshape(B*O_h*O_w*C, -1)\n",
        "\n",
        "        if self.mode == \"cpu\":\n",
        "            self.max_index = np.argmax(self.x, axis=1)\n",
        "            self.y = np.max(self.x, axis=1).reshape(B, O_h, O_w, C).transpose(0, 3, 1, 2)\n",
        "        elif self.mode == \"gpu\":\n",
        "            self.max_index = cp.argmax(self.x, axis=1)\n",
        "            self.y = cp.max(self.x, axis=1).reshape(B, O_h, O_w, C).transpose(0, 3, 1, 2)\n",
        "        \n",
        "        return self.y\n",
        "    \n",
        "    \n",
        "    def backward(self, grad):\n",
        "        B = grad.shape[0]\n",
        "        I_shape = B, *self.I_shape\n",
        "        C, O_h, O_w = self.O_shape\n",
        "        \n",
        "        grad = grad.transpose(0, 2, 3, 1).reshape(-1, 1)\n",
        "        if self.mode == \"cpu\":\n",
        "            self.grad_x = np.zeros((grad.size, self.pool*self.pool))\n",
        "        elif self.mode == \"gpu\":\n",
        "            self.grad_x = cp.zeros((grad.size, self.pool*self.pool))\n",
        "        self.grad_x[:, self.max_index] = grad\n",
        "        self.grad_x = self.grad_x.reshape(B*O_h*O_w, C*self.pool*self.pool).T\n",
        "        self.grad_x = self.col2im(self.grad_x, I_shape, self.O_shape,\n",
        "                                  stride=self.pool, pad=self.pad_state)\n",
        "        \n",
        "        return self.grad_x\n",
        "    \n",
        "    \n",
        "    def update(self, **kwds):\n",
        "        pass"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uuolbd5ztUj"
      },
      "source": [
        "# レイヤマネージャ\n",
        "[目次へ戻る](#目次)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6fEiQilztUk"
      },
      "source": [
        "class LayerManagerError(Exception):\n",
        "    \"\"\"レイヤーモジュールにおけるユーザ定義エラーのベースクラス\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class AssignError(LayerManagerError):\n",
        "    def __init__(self, value=None):\n",
        "        if not value is None:\n",
        "            self.value = value\n",
        "            self.message = (str(value)\n",
        "                         + \": Assigning that value is prohibited.\")\n",
        "        else:\n",
        "            self.value = None\n",
        "            self.message = \"Assigning that value is prohibited.\"\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.message\n",
        "\n",
        "\n",
        "class UnmatchUnitError(LayerManagerError):\n",
        "    def __init__(self, prev, n):\n",
        "        self.prev = prev\n",
        "        self.n = n\n",
        "\n",
        "        self.message = \"Unmatch units: <{}> and <{}>.\".format(prev, n)\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.message\n",
        "\n",
        "\n",
        "class UndefinedLayerError(LayerManagerError):\n",
        "    def __init__(self, type_name):\n",
        "        self.type = type_name\n",
        "        self.message = \"<{}>: Undefined layer type.\".format(str(type_name))\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.message"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j7Aemr8ztUq"
      },
      "source": [
        "class _TypeManager():\n",
        "    \"\"\"\n",
        "    層の種類に関するマネージャクラス\n",
        "    \"\"\"\n",
        "    N_TYPE = 4  # 層の種類数\n",
        "\n",
        "    BASE = -1\n",
        "    MIDDLE = 0  # 中間層のナンバリング\n",
        "    OUTPUT = 1  # 出力層のナンバリング\n",
        "    CONV = 2    #畳み込み層のナンバリング\n",
        "    POOL = 3    #プーリング層のナンバリング\n",
        "    \n",
        "    REGULATED_DIC = {\"Middle\": MiddleLayer,\n",
        "                     \"Output\": OutputLayer,\n",
        "                     \"Conv\": ConvLayer,\n",
        "                     \"Pool\": PoolingLayer,\n",
        "                     \"BaseLayer\": None}\n",
        "    \n",
        "    \n",
        "    @property\n",
        "    def reg_keys(self):\n",
        "        return list(self.REGULATED_DIC.keys())\n",
        "    \n",
        "    \n",
        "    def name_rule(self, name):\n",
        "        name = name.lower()\n",
        "        if \"middle\" in name or name == \"mid\" or name == \"m\":\n",
        "            name = self.reg_keys[self.MIDDLE]\n",
        "        elif \"output\" in name or name == \"out\" or name == \"o\":\n",
        "            name = self.reg_keys[self.OUTPUT]\n",
        "        elif \"conv\" in name or name == \"c\":\n",
        "            name = self.reg_keys[self.CONV]\n",
        "        elif \"pool\" in name or name == \"p\":\n",
        "            name = self.reg_keys[self.POOL]\n",
        "        else:\n",
        "            raise UndefinedLayerError(name)\n",
        "        \n",
        "        return name"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o2vYURKztUs"
      },
      "source": [
        "import time\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "\n",
        "softmax = type(get_act(\"softmax\"))\n",
        "sigmoid = type(get_act(\"sigmoid\"))\n",
        "\n",
        "\n",
        "class Trainer():\n",
        "    def __init__(self, x, y):\n",
        "        self.x_train, self.x_test = x\n",
        "        self.y_train, self.y_test = y\n",
        "        if self.mode == \"gpu\":\n",
        "            self.x_train = cp.asarray(self.x_train)\n",
        "            self.x_test = cp.asarray(self.x_test)\n",
        "            self.y_train = cp.asarray(self.y_train)\n",
        "            self.y_test = cp.asarray(self.y_test)\n",
        "        \n",
        "        self.make_anim = False\n",
        "    \n",
        "\n",
        "    def forward(self, x, lim_memory=10):\n",
        "        def propagate(x):\n",
        "            x_in = x\n",
        "            n_batch = x.shape[0]\n",
        "            switch = True\n",
        "            for ll in self.layer_list:\n",
        "                if switch and not self.is_CNN(ll.name):\n",
        "                    x_in = x_in.reshape(n_batch, -1)\n",
        "                    switch = False\n",
        "                x_in = ll.forward(x_in)\n",
        "        \n",
        "        # 順伝播メソッドは誤差計算や未知データの予測にも使用するため\n",
        "        # メモリ容量が大きくなる可能性がある\n",
        "        if np.prod(x.shape)*8/2**20 >= 10:\n",
        "            # 倍精度浮動小数点数(8byte)で10MB(=30*2**20)以上の\n",
        "            # メモリを利用する場合は5MB以下ずつに分割して実行する\n",
        "            n_batch = int(5*2**20/(8*np.prod(x.shape[1:])))\n",
        "            if self.mode == \"cpu\":\n",
        "                y = np.zeros((x.shape[0], lm[-1].n))\n",
        "            elif self.mode == \"gpu\":\n",
        "                y = cp.zeros((x.shape[0], lm[-1].n))\n",
        "            n_loop = int(np.ceil(x.shape[0]/n_batch))\n",
        "            for i in range(n_loop):\n",
        "                propagate(x[i*n_batch : (i+1)*n_batch])\n",
        "                y[i*n_batch : (i+1)*n_batch] = lm[-1].y.copy()\n",
        "            lm[-1].y = y\n",
        "        else:\n",
        "            # そうでなければ普通に実行する\n",
        "            propagate(x)\n",
        "\n",
        "    \n",
        "    def backward(self, t):\n",
        "        y_in = t\n",
        "        n_batch = t.shape[0]\n",
        "        switch = True\n",
        "        for ll in self.layer_list[::-1]:\n",
        "            if switch and self.is_CNN(ll.name):\n",
        "                y_in = y_in.reshape(n_batch, *ll.O_shape)\n",
        "                switch = False\n",
        "            y_in = ll.backward(y_in)\n",
        "    \n",
        "    \n",
        "    def update(self, **kwds):\n",
        "        for ll in self.layer_list:\n",
        "            ll.update(**kwds)\n",
        "    \n",
        "    \n",
        "    def training(self, epoch, n_batch=16, threshold=1e-8,\n",
        "                 show_error=True, show_train_error=False, **kwds):\n",
        "        if show_error:\n",
        "            self.error_list = []\n",
        "        if show_train_error:\n",
        "            self.train_error_list = []\n",
        "        if self.make_anim:\n",
        "            self.images = []\n",
        "        self.n_batch = n_batch\n",
        "        \n",
        "        n_train = self.x_train.shape[0]//n_batch\n",
        "        n_test = self.x_test.shape[0]\n",
        "        \n",
        "        # 学習開始\n",
        "        if self.mode == \"gpu\":\n",
        "            cp.cuda.Stream.null.synchronize()\n",
        "        start_time = time.time()\n",
        "        lap_time = -1\n",
        "        error = 0\n",
        "        error_prev = 0\n",
        "        rand_index = np.arange(self.x_train.shape[0])\n",
        "        for t in range(1, epoch+1):\n",
        "            #シーン作成\n",
        "            if self.make_anim:\n",
        "                self.make_scene(t, epoch)\n",
        "            \n",
        "            # 訓練誤差計算\n",
        "            if show_train_error:\n",
        "                self.forward(self.x_train)\n",
        "                error = lm[-1].get_error(self.y_train)\n",
        "                self.train_error_list.append(error)\n",
        "            \n",
        "            # 誤差計算\n",
        "            self.forward(self.x_test)\n",
        "            error = lm[-1].get_error(self.y_test)\n",
        "            if show_error:\n",
        "                self.error_list.append(error)\n",
        "\n",
        "            # 収束判定\n",
        "            if np.isnan(error):\n",
        "                print(\"fail training...\")\n",
        "                break\n",
        "            if abs(error - error_prev) < threshold:\n",
        "                print(\"end learning...\")\n",
        "                break\n",
        "            else:\n",
        "                error_prev = error\n",
        "\n",
        "            t_percent = int(50*t/epoch)\n",
        "            np.random.shuffle(rand_index)\n",
        "            for i in range(n_train):\n",
        "                i_percent = int(50*(i+1)/n_train)\n",
        "                if i_percent <= t_percent:\n",
        "                    time_stamp = (\"progress:[\" + \"X\"*i_percent\n",
        "                                               + \"\\\\\"*(t_percent-i_percent)\n",
        "                                               + \" \"*(50-t_percent) + \"]\")\n",
        "                else:\n",
        "                    time_stamp = (\"progress:[\" + \"X\"*t_percent\n",
        "                                               + \"/\"*(i_percent-t_percent)\n",
        "                                               + \" \"*(50-i_percent) + \"]\")\n",
        "                if self.mode == \"gpu\":\n",
        "                    cp.cuda.Stream.null.synchronize()\n",
        "                elapsed_time = time.time() - start_time\n",
        "                print(\"\\r\" + time_stamp\n",
        "                      + \"{}s/{}s\".format(\n",
        "                          int(elapsed_time),\n",
        "                          int(lap_time*epoch) if lap_time > 0 else \"?\"),\n",
        "                      end=\"\")\n",
        "\n",
        "                rand = rand_index[i*n_batch : (i+1)*n_batch]\n",
        "                self.forward(self.x_train[rand])\n",
        "                self.backward(self.y_train[rand])\n",
        "                self.update(**kwds)\n",
        "            if lap_time < 0:\n",
        "                if self.mode == \"gpu\":\n",
        "                    cp.cuda.Stream.null.synchronize()\n",
        "                lap_time = time.time() - start_time\n",
        "        print()\n",
        "\n",
        "        if show_error:\n",
        "            # 誤差遷移表示\n",
        "            self.show_errors(show_train_error, **kwds)\n",
        "    \n",
        "    \n",
        "    def pred_func(self, y, threshold=0.5):\n",
        "        if isinstance(self[-1].act, softmax):\n",
        "            return np.argmax(y, axis=1)\n",
        "        elif isinstance(self[-1].act, sigmoid):\n",
        "            return np.where(y > threshold, 1, 0)\n",
        "        else:\n",
        "            raise NotImplemented\n",
        "    \n",
        "    \n",
        "    def predict(self, x=None, y=None, threshold=0.5):\n",
        "        if x is None:\n",
        "            x = self.x_test\n",
        "        if y is None:\n",
        "            y = self.y_test\n",
        "        \n",
        "        self.forward(x)\n",
        "        self.y_pred = self.pred_func(self[-1].y, threshold=threshold)\n",
        "        y = self.pred_func(y, threshold=threshold)\n",
        "        print(\"correct:\", y[:min(16, int(y.shape[0]*0.1))])\n",
        "        print(\"predict:\", self.y_pred[:min(16, int(y.shape[0]*0.1))])\n",
        "        print(\"accuracy rate:\", np.sum(self.y_pred == y, dtype=int)/y.shape[0]*100, \"%\",\n",
        "              \"({}/{})\".format(np.sum(self.y_pred == y, dtype=int), y.shape[0]))\n",
        "        \n",
        "        return self.y_pred\n",
        "    \n",
        "    \n",
        "    def show_errors(self, show_train_error=False, title=\"error transition\",\n",
        "                    xlabel=\"epoch\", ylabel=\"error\", fname=\"error_transition.png\",\n",
        "                    log_scale=True, **kwds):\n",
        "        fig, ax = plt.subplots(1)\n",
        "        fig.suptitle(title)\n",
        "        if log_scale:\n",
        "            ax.set_yscale(\"log\")\n",
        "        ax.set_xlabel(xlabel)\n",
        "        ax.set_ylabel(ylabel)\n",
        "        ax.grid()\n",
        "        if show_train_error:\n",
        "            ax.plot(self.train_error_list, label=\"train error\")\n",
        "        ax.plot(self.error_list, label=\"test error\")\n",
        "        ax.legend(loc=\"best\")\n",
        "        #fig.show()\n",
        "        if len(fname) != 0:\n",
        "            fig.savefig(fname)\n",
        "    \n",
        "    \n",
        "    def ready_anim(self, n_image, x, y, title=\"animation\",\n",
        "                   xlabel=\"x\", ylabel=\"y\", ex_color=\"r\", color=\"b\",\n",
        "                   x_left=0, x_right=0, y_down = 1, y_up = 1):\n",
        "        self.n_image = n_image\n",
        "        self.x = x\n",
        "        self.color = color\n",
        "        self.make_anim = True\n",
        "        \n",
        "        self.anim_fig, self.anim_ax = plt.subplots(1)\n",
        "        self.anim_fig.suptitle(title)\n",
        "        self.anim_ax.set_xlabel(xlabel)\n",
        "        self.anim_ax.set_ylabel(ylabel)\n",
        "        self.anim_ax.set_xlim(np.min(x) - x_left, np.max(x) + x_right)\n",
        "        self.anim_ax.set_ylim(np.min(y) - y_down, np.max(y) + y_up)\n",
        "        self.anim_ax.grid()\n",
        "        self.anim_ax.plot(x, y, color=ex_color)\n",
        "        \n",
        "        return self.anim_fig, self.anim_ax\n",
        "    \n",
        "    \n",
        "    def make_scene(self, t, epoch):\n",
        "        # シーン作成\n",
        "        if t % (epoch/self.n_image) == 1:\n",
        "            x_in = self.x.reshape(-1, 1)\n",
        "            for ll in self.layer_list:\n",
        "                x_in = ll.forward(x_in)\n",
        "            im, = self.anim_ax.plot(self.x, ll.y, color=self.color)\n",
        "            self.images.append([im])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDe16V5SztUv"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class LayerManager(_TypeManager, Trainer):\n",
        "    \"\"\"\n",
        "    層を管理するためのマネージャクラス\n",
        "    \"\"\"\n",
        "    def __init__(self, x, y, mode=\"cpu\"):\n",
        "        # gpu利用可能かどうか\n",
        "        if not mode in [\"cpu\", \"gpu\"]:\n",
        "            raise KeyError(\"'mode' must select in {}\".format([\"cpu\", \"gpu\"])\n",
        "                         + \"but you specify '{}'.\".format(mode))\n",
        "        self.mode = mode.lower()\n",
        "        \n",
        "        super().__init__(x, y)\n",
        "        \n",
        "        self.__layer_list = []  # レイヤーのリスト\n",
        "        self.__name_list = []   # 各レイヤーの名前リスト\n",
        "        self.__ntype = np.zeros(self.N_TYPE, dtype=int)  # 種類別レイヤーの数\n",
        "        \n",
        "\n",
        "    def __repr__(self):\n",
        "        layerRepr= \"layer_list: \" + repr(self.__layer_list)\n",
        "        nameRepr = \"name_list: \" + repr(self.__name_list)\n",
        "        ntypeRepr = \"ntype: \" + repr(self.__ntype)\n",
        "        return (layerRepr + \"\\n\"\n",
        "                + nameRepr + \"\\n\"\n",
        "                + ntypeRepr)\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        layerStr = \"layer_list: \" + str(self.__layer_list)\n",
        "        nameStr = \"name_list: \" + str(self.__name_list)\n",
        "        ntypeStr = \"ntype: \" + str(self.__ntype)\n",
        "        return (layerStr + \"\\n\"\n",
        "                + nameStr + \"\\n\"\n",
        "                + ntypeStr)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Pythonのビルドイン関数`len`から呼ばれたときの動作を記述。\n",
        "        種類別レイヤーの数の総和を返します。\n",
        "        \"\"\"\n",
        "        return int(np.sum(self.__ntype))\n",
        "\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        \"\"\"\n",
        "        例えば\n",
        "        lm = LayerManager()\n",
        "\n",
        "        +----------------+\n",
        "        | (lmに要素を追加) |\n",
        "        +----------------+\n",
        "\n",
        "        x = lm[3].~~\n",
        "        のように、リストや配列の要素にアクセスされたときに呼ばれるので、\n",
        "        そのときの動作を記述。\n",
        "        sliceやstr, intでのアクセスのみ許可します。\n",
        "        \"\"\"\n",
        "        if isinstance(key, slice):\n",
        "            # keyがスライスならレイヤーのリストをsliceで参照する。\n",
        "            # 異常な値(Index out of rangeなど)が入力されたら\n",
        "            # Pythonがエラーを出してくれます。\n",
        "            return self.__layer_list[key]\n",
        "        elif isinstance(key, str):\n",
        "            # keyが文字列なら各レイヤーの名前リストからインデックスを取得して、\n",
        "            # 該当するレイヤーのリストの要素を返す。\n",
        "            if key in self.__name_list:\n",
        "                index = self.__name_list.index(key)\n",
        "                return self.__layer_list[index]\n",
        "            else:\n",
        "                # keyが存在しない場合はKeyErrorを出す。\n",
        "                raise KeyError(\"{}: No such item\".format(key))\n",
        "        elif isinstance(key, int):\n",
        "            # keyが整数ならレイヤーのリストの該当要素を返す。\n",
        "            # 異常な値(Index out of rangeなど)が入力されたら\n",
        "            # Pythonがエラーを出してくれます。\n",
        "            return self.__layer_list[key]\n",
        "        else:\n",
        "            raise KeyError(key, \": Undefined such key type.\")\n",
        "\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        \"\"\"\n",
        "        例えば\n",
        "        lm = LayerManager()\n",
        "\n",
        "        +----------------+\n",
        "        | (lmに要素を追加) |\n",
        "        +----------------+\n",
        "\n",
        "        lm[1] = x\n",
        "        のように、リストや配列の要素にアクセスされたときに呼ばれるので、\n",
        "        そのときの動作を記述。\n",
        "        要素の上書きのみ認め、新規要素の追加などは禁止します。\n",
        "        \"\"\"\n",
        "        value_type = \"\"\n",
        "        if isinstance(value, list):\n",
        "            # 右辺で指定された'value'が'list'なら\n",
        "            # 全ての要素が'BaseLayer'クラスかそれを継承していなければエラー。\n",
        "            if not np.all(\n",
        "                np.where(isinstance(value, BaseLayer), True, False)):\n",
        "                self.AssignError()\n",
        "            value_type = \"list\"\n",
        "        elif isinstance(value, BaseLayer):\n",
        "            # 右辺で指定された'value'が'BaseLayer'クラスか\n",
        "            # それを継承していない場合はエラー。\n",
        "            self.AssignError(type(value))\n",
        "        if value_type == \"\":\n",
        "            value_type = self.reg_keys[self.BASE]\n",
        "\n",
        "        if isinstance(key, slice):\n",
        "            # keyがスライスならレイヤーのリストの要素を上書きする。\n",
        "            # ただし'value_type'が'list'でなければエラー。\n",
        "            # 異常な値(Index out of rangeなど)が入力されたら\n",
        "            # Pythonがエラーを出してくれます。\n",
        "            if value_type != \"list\":\n",
        "                self.AssignError(value_type)\n",
        "            self.__layer_list[key] = value\n",
        "        elif isinstance(key, str):\n",
        "            # keyが文字列なら各レイヤーの名前リストからインデックスを取得して、\n",
        "            # 該当するレイヤーのリストの要素を上書きする。\n",
        "            # ただし'value_type'が'BaseLayer'でなければエラー。\n",
        "            if value_type != self.reg_keys[self.BASE]:\n",
        "                raise AssignError(value_type)\n",
        "            if key in self.__name_list:\n",
        "                index = self.__name_list.index(key)\n",
        "                self.__layer_list[index] = value\n",
        "            else:\n",
        "                # keyが存在しない場合はKeyErrorを出す。\n",
        "                raise KeyError(\"{}: No such item\".format(key))\n",
        "        elif isinstance(key, int):\n",
        "            # keyが整数ならレイヤーのリストの該当要素を上書きする。\n",
        "            # ただし'value_type'が'BaseLayer'でなければエラー。\n",
        "            # また、異常な値(Index out of rangeなど)が入力されたら\n",
        "            # Pythonがエラーを出してくれます。\n",
        "            if value_type != self.reg_keys[self.BASE]:\n",
        "                raise AssignError(value_type)\n",
        "            self.__layer_list[key] = value\n",
        "        else:\n",
        "            raise KeyError(key, \": Undefined such key type.\")\n",
        "\n",
        "\n",
        "    def __delitem__(self, key):\n",
        "        \"\"\"\n",
        "        例えば\n",
        "        lm = LayerManager()\n",
        "\n",
        "        +----------------+\n",
        "        | (lmに要素を追加) |\n",
        "        +----------------+\n",
        "\n",
        "        del lm[2]\n",
        "        のように、del文でリストや配列の要素にアクセスされたときに呼ばれるので、\n",
        "        そのときの動作を記述。\n",
        "        指定要素が存在すれば削除、さらにリネームを行います。\n",
        "        \"\"\"\n",
        "        if isinstance(key, slice):\n",
        "            # keyがスライスならそのまま指定の要素を削除\n",
        "            # 異常な値(Index out of rangeなど)が入力されたら\n",
        "            # Pythonがエラーを出してくれます。\n",
        "            del self.__layer_list[slice]\n",
        "            del self.__name_list[slice]\n",
        "        elif isinstance(key, str):\n",
        "            # keyが文字列なら各レイヤーの名前リストからインデックスを取得して、\n",
        "            # 該当する要素を削除する。\n",
        "            if key in self.__name_list:\n",
        "                del self.__layer_list[index]\n",
        "                del self.__name_list[index]\n",
        "            else:\n",
        "                # keyが存在しない場合はKeyErrorを出す。\n",
        "                raise KeyError(\"{}: No such item\".format(key))\n",
        "        elif isinstance(key, int):\n",
        "            # keyが整数ならレイヤーのリストの該当要素を削除する。\n",
        "            # 異常な値(Index out of rangeなど)が入力されたら\n",
        "            # Pythonがエラーを出してくれます。\n",
        "            del self.__layer_list[key]\n",
        "        else:\n",
        "            raise KeyError(key, \": Undefined such key type.\")\n",
        "\n",
        "        # リネームする\n",
        "        self._rename()\n",
        "\n",
        "\n",
        "    def _rename(self):\n",
        "        \"\"\"\n",
        "        リスト操作によってネームリストのネーミングがルールに反するものになった場合に\n",
        "        改めてルールを満たすようにネーミングリストおよび各レイヤーの名前を変更する。\n",
        "\n",
        "        ネーミングルールは[レイヤーの種類][何番目か]とします。\n",
        "        レイヤーの種類はMiddleLayerならMiddle\n",
        "                     OutputLayerならOutput\n",
        "        のように略します。\n",
        "        何番目かというのは種類別でカウントします。\n",
        "\n",
        "        また、ここで改めて__ntypeのカウントを行います。\n",
        "        \"\"\"\n",
        "        # 種類別レイヤーの数を初期化\n",
        "        self.__ntype = np.zeros(self.N_TYPE)\n",
        "\n",
        "        # 再カウントと各レイヤーのリネーム\n",
        "        for i in range(len(self)):\n",
        "            for j, reg_name in enumerate(self.REGULATED_DIC):\n",
        "                if reg_name in self.__name_list[i]:\n",
        "                    self.__ntype[j] += 1\n",
        "                    self.__name_list[i] = (self.reg_keys[j]\n",
        "                                        + str(self.__ntype[j]))\n",
        "                    self.__layer_list[i].name = (self.reg_keys[j]\n",
        "                                              + str(self.__ntype[j]))\n",
        "                    break\n",
        "            else:\n",
        "                raise UndefinedLayerType(self.__name_list[i])\n",
        "    \n",
        "\n",
        "    def append(self, *, name=\"Middle\", **kwds):\n",
        "        \"\"\"\n",
        "        リストに要素を追加するメソッドでお馴染みのappendメソッドの実装。\n",
        "        \"\"\"\n",
        "        if \"prev\" in kwds:\n",
        "            # 'prev'がキーワードに含まれている場合、\n",
        "            # 一つ前の層の要素数を指定していることになります。\n",
        "            # 基本的に最初のレイヤーを挿入する時を想定していますので、\n",
        "            # それ以外は基本的に自動で決定するため指定しません。\n",
        "            if len(self) != 0:\n",
        "                if kwds[\"prev\"] != self.__layer_list[-1].n:\n",
        "                    # 最後尾のユニット数と一致しなければエラー。\n",
        "                    raise UnmatchUnitError(self.__layer_list[-1].n,\n",
        "                                           kwds[\"prev\"])\n",
        "        elif not self.is_CNN(name):\n",
        "            if len(self) == 0:\n",
        "                # 最初のDNNレイヤは必ず入力ユニットの数を指定する必要があります。\n",
        "                raise UnmatchUnitError(\"Input units\", \"Unspecified\")\n",
        "            else:\n",
        "                # 最後尾のレイヤのユニット数を'kwds'に追加\n",
        "                kwds[\"prev\"] = self.__layer_list[-1].n\n",
        "\n",
        "        # レイヤーの種類を読み取り、ネーミングルールに則った名前に変更する\n",
        "        name = self.name_rule(name)\n",
        "\n",
        "        # レイヤーを追加する。\n",
        "        for i, reg_name in enumerate(self.REGULATED_DIC):\n",
        "            if name in reg_name:\n",
        "                # 種類別レイヤーをインクリメントして\n",
        "                self.__ntype[i] += 1\n",
        "                # 名前に追加し\n",
        "                name += str(self.__ntype[i])\n",
        "                # ネームリストに追加し\n",
        "                self.__name_list.append(name)\n",
        "                # 最後にレイヤーを生成してリストに追加します。\n",
        "                self.__layer_list.append(\n",
        "                    self.REGULATED_DIC[reg_name](name=name,\n",
        "                                                 mode=self.mode,\n",
        "                                                 **kwds))\n",
        "\n",
        "\n",
        "    def extend(self, lm):\n",
        "        \"\"\"\n",
        "        extendメソッドでは既にある別のレイヤーマネージャ'lm'の要素を\n",
        "        全て追加します。\n",
        "        \"\"\"\n",
        "        if not isinstance(lm, LayerManager):\n",
        "            # 'lm'のインスタンスがLayerManagerでなければエラー。\n",
        "            raise TypeError(type(lm), \": Unexpected type.\")\n",
        "        if len(self) != 0:\n",
        "            if self.__layer_list[-1].n != lm[0].prev:\n",
        "                # 自分の最後尾のレイヤーのユニット数と\n",
        "                # 'lm'の最初のレイヤーの入力数が一致しない場合はエラー。\n",
        "                raise UnmatchUnitError(self.__layer_list[-1].n,\n",
        "                                       lm[0].prev)\n",
        "        if lm.mode != self.mode:\n",
        "            # 'lm'と'self'の'mode'が一致していなければエラー\n",
        "            # 対応する気になったらするかも...\n",
        "            raise TypeError(\"Your 'mode'<{}>\".format(lm.mode) +\n",
        "                            \"is not equal to my 'mode'<{}>.\".format(self.mode))\n",
        "\n",
        "        # それぞれ'extend'メソッドで追加\n",
        "        self.__layer_list.extend(lm.layer_list)\n",
        "        self.__name_list.extend(lm.name_list)\n",
        "\n",
        "        # リネームする\n",
        "        self._rename()\n",
        "\n",
        "\n",
        "    def insert(self, prev_name, name=\"Middle\", **kwds):\n",
        "        \"\"\"\n",
        "        insertメソッドでは、前のレイヤーの名前を指定しそのレイヤーと結合するように\n",
        "        要素を追加します。\n",
        "        \"\"\"\n",
        "        # 'prev_name'が存在しなければエラー。\n",
        "        if not prev_name in self.__name_list:\n",
        "            raise KeyError(prev_name, \": No such key.\")\n",
        "        # 'prev'がキーワードに含まれている場合、\n",
        "        # 'prev_name'で指定されているレイヤーのユニット数と一致しなければエラー。\n",
        "        if \"prev\" in kwds:\n",
        "            if kwds[\"prev\"] \\\n",
        "                != self.__layer_list[self.index(prev_name)].n:\n",
        "                raise UnmatchUnitError(\n",
        "                    kwds[\"prev\"],\n",
        "                    self.__layer_list[self.index(prev_name)].n)\n",
        "        # 'n'がキーワードに含まれている場合、\n",
        "        if \"n\" in kwds:\n",
        "            # 'prev_name'が最後尾ではない場合は\n",
        "            if prev_name != self.__name_list[-1]:\n",
        "                # 次のレイヤーのユニット数と一致しなければエラー。\n",
        "                if kwds[\"n\"] != self.__layer_list[\n",
        "                        self.index(prev_name)+1].prev:\n",
        "                    raise UnmatchUnitError(\n",
        "                        kwds[\"n\"],\n",
        "                        self.__layer_list[self.index(prev_name)].prev)\n",
        "        # まだ何も要素がない場合は'append'メソッドを用いるようにエラーを出す。\n",
        "        if len(self) == 0:\n",
        "            raise RuntimeError(\n",
        "                \"You have to use 'append' method instead.\")\n",
        "\n",
        "        # 挿入場所のインデックスを取得\n",
        "        index = self.index(prev_name) + 1\n",
        "\n",
        "        # レイヤーの種類を読み取り、ネーミングルールに則った名前に変更する\n",
        "        name = self.name_rule(name)\n",
        "\n",
        "        # 要素を挿入する\n",
        "        for i, reg_name in enumerate(self.REGULATED_DIC):\n",
        "            if reg_name in name:\n",
        "                self.__layer_list.insert(\n",
        "                    index, self.REGULATED_DIC[reg_name](name=name,\n",
        "                                                        mode=self.mode,\n",
        "                                                        **kwds))\n",
        "                self.__name_list.insert(\n",
        "                    index, self.REGULATED_DIC[reg_name](name=name,\n",
        "                                                        mode=self.mode,\n",
        "                                                        **kwds))\n",
        "\n",
        "        # リネームする\n",
        "        self._rename()\n",
        "\n",
        "\n",
        "    def extend_insert(self, prev_name, lm):\n",
        "        \"\"\"\n",
        "        こちらはオリジナル関数です。\n",
        "        extendメソッドとinsertメソッドを組み合わせたような動作をします。\n",
        "        簡単に説明すると、別のレイヤーマネージャをinsertする感じです。\n",
        "        \"\"\"\n",
        "        if not isinstance(lm, LayerManager):\n",
        "            # 'lm'のインスタンスがLayerManagerでなければエラー。\n",
        "            raise TypeError(type(lm), \": Unexpected type.\")\n",
        "        # 'prev_name'が存在しなければエラー。\n",
        "        if not prev_name in self.__name_list:\n",
        "            raise KeyError(prev_name, \": No such key.\")\n",
        "        # 指定場所の前後のレイヤーとlmの最初・最後のレイヤーのユニット数が\n",
        "        # それぞれ一致しなければエラー。\n",
        "        if len(self) != 0:\n",
        "            if self.__layer_list[self.index(prev_name)].n \\\n",
        "                    != lm.layer_list[0].prev:\n",
        "                # 自分の指定場所のユニット数と'lm'の最初のユニット数が\n",
        "                # 一致しなければエラー。\n",
        "                raise UnmatchUnitError(\n",
        "                    self.__layer_list[self.index(prev_name)].n,\n",
        "                    lm.layer_list[0].prev)\n",
        "            if prev_name != self.__name_list[-1]:\n",
        "                # 'prev_name'が自分の最後尾のレイヤーでなく\n",
        "                if lm.layer_list[-1].n \\\n",
        "                    != self.__layer_list[self.index(prev_name)+1].prev:\n",
        "                    # 'lm'の最後尾のユニット数と自分の指定場所の次のレイヤーの\n",
        "                    # 'prev'ユニット数と一致しなければエラー。\n",
        "                    raise UnmatchUnitError(\n",
        "                        lm.layer_list[-1].n,\n",
        "                        self.__layer_list[self.index(prev_name)+1].prev)\n",
        "        else:\n",
        "            # 自分に何の要素もない場合は'extend'メソッドを使うようにエラーを出す。\n",
        "            raise RuntimeError(\n",
        "                \"You have to use 'extend' method instead.\")\n",
        "        if lm.mode != self.mode:\n",
        "            # 'lm'と'self'の'mode'が一致していなければエラー\n",
        "            # 対応する気になったらするかも...\n",
        "            raise TypeError(\"Your 'mode'<{}>\".format(lm.mode) +\n",
        "                            \"is not equal to my 'mode'<{}>.\".format(self.mode))\n",
        "\n",
        "        # 挿入場所のインデックスを取得\n",
        "        index = self.index(prev_name) + 1\n",
        "\n",
        "        # 挿入場所以降の要素を'buf'に避難させてから一旦取り除き、\n",
        "        # extendメソッドを使って要素を追加\n",
        "        layer_buf = self.__layer_list[index:]\n",
        "        name_buf = self.__name_list[index:]\n",
        "        del self.__layer_list[index:]\n",
        "        del self.__name_list[index:]\n",
        "        self.extend(lm)\n",
        "\n",
        "        # 避難させていた要素を追加する\n",
        "        self.__layer_list.extend(layer_buf)\n",
        "        self.__name_list.extend(name_buf)\n",
        "\n",
        "        # リネームする\n",
        "        self._rename()\n",
        "\n",
        "\n",
        "    def remove(self, key):\n",
        "        \"\"\"\n",
        "        removeメソッドでは指定の名前の要素を削除します。\n",
        "        インデックスでの指定も許可します。\n",
        "        \"\"\"\n",
        "        # 既に実装している'del'文でOKです。\n",
        "        del self[key]\n",
        "\n",
        "\n",
        "    def index(self, target):\n",
        "        return self.__name_list.index(target)\n",
        "\n",
        "\n",
        "    def name(self, indices):\n",
        "        return self.__name_list[indices]\n",
        "\n",
        "\n",
        "    @property\n",
        "    def layer_list(self):\n",
        "        return self.__layer_list\n",
        "\n",
        "\n",
        "    @property\n",
        "    def name_list(self):\n",
        "        return self.__name_list\n",
        "\n",
        "\n",
        "    @property\n",
        "    def ntype(self):\n",
        "        return self.__ntype\n",
        "    \n",
        "    \n",
        "    def is_CNN(self, name=None):\n",
        "        if name is None:\n",
        "            if self.__ntype[self.CONV] > 0 \\\n",
        "            or self.__ntype[self.POOL] > 0:\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "        else:\n",
        "            name = self.name_rule(name)\n",
        "            if self.reg_keys[self.CONV] in name \\\n",
        "            or self.reg_keys[self.POOL] in name:\n",
        "                return True\n",
        "            else:\n",
        "                return False"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P118WfBztUx"
      },
      "source": [
        "# 実験コード\n",
        "[目次へ戻る](#目次)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr1R9RP5ztUx"
      },
      "source": [
        "## 関数近似編"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "4c5L-6uKztUx",
        "outputId": "e9350de2-6939-4626-93db-f3db5f2f94ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "%matplotlib nbagg\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import tqdm\n",
        "\n",
        "\n",
        "# 学習対象設定\n",
        "def split_test(target, train_indices):\n",
        "    return (target[train_indices], target[~ train_indices])\n",
        "x = np.arange(0, 4, 5e-2)\n",
        "y = np.sin(x)\n",
        "x_left = 1\n",
        "x_right = 3\n",
        "y_top = np.max(y) + 1\n",
        "y_bottom = np.min(y) - 1\n",
        "indices = (x_left <= x) & (x <= x_right)\n",
        "x_train, x_test = split_test(x, indices)\n",
        "y_train, y_test = split_test(y, indices)\n",
        "\n",
        "# 初期設定\n",
        "n_in = 1\n",
        "n_out = 1\n",
        "epoch = 30000\n",
        "threshold = 1e-8\n",
        "n_batch = 8\n",
        "x_train = x_train.reshape(-1, n_in)\n",
        "x_test = x_test.reshape(-1, n_in)\n",
        "y_train = y_train.reshape(-1, n_in)\n",
        "y_test = y_test.reshape(-1, n_in)\n",
        "\n",
        "# ネットワーク構築\n",
        "lm = LayerManager((x_train, x_test), (y_train, y_test))\n",
        "lm.append(prev=n_in, n=30, act=\"tanhExp\")\n",
        "lm.append(n=30, act=\"tanhExp\")\n",
        "lm.append(n=n_out, name=\"o\", act=\"identity\")\n",
        "\n",
        "\n",
        "# アニメーションプロット用土台作成\n",
        "n_image = 100\n",
        "interval = 100\n",
        "fig, ax = lm.ready_anim(n_image, x, y, title=\"fitting animation\")\n",
        "ax.plot(np.full_like(np.arange(y_bottom, y_top+1), x_left),\n",
        "        np.arange(y_bottom, y_top+1),\n",
        "        color=\"g\")\n",
        "ax.plot(np.full_like(np.arange(y_bottom, y_top+1), x_right),\n",
        "        np.arange(y_bottom, y_top+1),\n",
        "        color=\"g\")\n",
        "\n",
        "# 学習開始\n",
        "lm.training(epoch, threshold=threshold, n_batch=n_batch)\n",
        "\n",
        "# フィッティングアニメーション作成\n",
        "anim = animation.ArtistAnimation(lm.anim_fig, lm.images,interval=interval,\n",
        "                                 repeat_delay=3000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "/* Put everything inside the global mpl namespace */\n",
              "window.mpl = {};\n",
              "\n",
              "\n",
              "mpl.get_websocket_type = function() {\n",
              "    if (typeof(WebSocket) !== 'undefined') {\n",
              "        return WebSocket;\n",
              "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
              "        return MozWebSocket;\n",
              "    } else {\n",
              "        alert('Your browser does not have WebSocket support. ' +\n",
              "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
              "              'Firefox 4 and 5 are also supported but you ' +\n",
              "              'have to enable WebSockets in about:config.');\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
              "    this.id = figure_id;\n",
              "\n",
              "    this.ws = websocket;\n",
              "\n",
              "    this.supports_binary = (this.ws.binaryType != undefined);\n",
              "\n",
              "    if (!this.supports_binary) {\n",
              "        var warnings = document.getElementById(\"mpl-warnings\");\n",
              "        if (warnings) {\n",
              "            warnings.style.display = 'block';\n",
              "            warnings.textContent = (\n",
              "                \"This browser does not support binary websocket messages. \" +\n",
              "                    \"Performance may be slow.\");\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.imageObj = new Image();\n",
              "\n",
              "    this.context = undefined;\n",
              "    this.message = undefined;\n",
              "    this.canvas = undefined;\n",
              "    this.rubberband_canvas = undefined;\n",
              "    this.rubberband_context = undefined;\n",
              "    this.format_dropdown = undefined;\n",
              "\n",
              "    this.image_mode = 'full';\n",
              "\n",
              "    this.root = $('<div/>');\n",
              "    this._root_extra_style(this.root)\n",
              "    this.root.attr('style', 'display: inline-block');\n",
              "\n",
              "    $(parent_element).append(this.root);\n",
              "\n",
              "    this._init_header(this);\n",
              "    this._init_canvas(this);\n",
              "    this._init_toolbar(this);\n",
              "\n",
              "    var fig = this;\n",
              "\n",
              "    this.waiting = false;\n",
              "\n",
              "    this.ws.onopen =  function () {\n",
              "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
              "            fig.send_message(\"send_image_mode\", {});\n",
              "            if (mpl.ratio != 1) {\n",
              "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
              "            }\n",
              "            fig.send_message(\"refresh\", {});\n",
              "        }\n",
              "\n",
              "    this.imageObj.onload = function() {\n",
              "            if (fig.image_mode == 'full') {\n",
              "                // Full images could contain transparency (where diff images\n",
              "                // almost always do), so we need to clear the canvas so that\n",
              "                // there is no ghosting.\n",
              "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
              "            }\n",
              "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
              "        };\n",
              "\n",
              "    this.imageObj.onunload = function() {\n",
              "        fig.ws.close();\n",
              "    }\n",
              "\n",
              "    this.ws.onmessage = this._make_on_message_function(this);\n",
              "\n",
              "    this.ondownload = ondownload;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_header = function() {\n",
              "    var titlebar = $(\n",
              "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
              "        'ui-helper-clearfix\"/>');\n",
              "    var titletext = $(\n",
              "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
              "        'text-align: center; padding: 3px;\"/>');\n",
              "    titlebar.append(titletext)\n",
              "    this.root.append(titlebar);\n",
              "    this.header = titletext[0];\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_canvas = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var canvas_div = $('<div/>');\n",
              "\n",
              "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
              "\n",
              "    function canvas_keyboard_event(event) {\n",
              "        return fig.key_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
              "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
              "    this.canvas_div = canvas_div\n",
              "    this._canvas_extra_style(canvas_div)\n",
              "    this.root.append(canvas_div);\n",
              "\n",
              "    var canvas = $('<canvas/>');\n",
              "    canvas.addClass('mpl-canvas');\n",
              "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
              "\n",
              "    this.canvas = canvas[0];\n",
              "    this.context = canvas[0].getContext(\"2d\");\n",
              "\n",
              "    var backingStore = this.context.backingStorePixelRatio ||\n",
              "\tthis.context.webkitBackingStorePixelRatio ||\n",
              "\tthis.context.mozBackingStorePixelRatio ||\n",
              "\tthis.context.msBackingStorePixelRatio ||\n",
              "\tthis.context.oBackingStorePixelRatio ||\n",
              "\tthis.context.backingStorePixelRatio || 1;\n",
              "\n",
              "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
              "\n",
              "    var rubberband = $('<canvas/>');\n",
              "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
              "\n",
              "    var pass_mouse_events = true;\n",
              "\n",
              "    canvas_div.resizable({\n",
              "        start: function(event, ui) {\n",
              "            pass_mouse_events = false;\n",
              "        },\n",
              "        resize: function(event, ui) {\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "        stop: function(event, ui) {\n",
              "            pass_mouse_events = true;\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "    });\n",
              "\n",
              "    function mouse_event_fn(event) {\n",
              "        if (pass_mouse_events)\n",
              "            return fig.mouse_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    rubberband.mousedown('button_press', mouse_event_fn);\n",
              "    rubberband.mouseup('button_release', mouse_event_fn);\n",
              "    // Throttle sequential mouse events to 1 every 20ms.\n",
              "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
              "\n",
              "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
              "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
              "\n",
              "    canvas_div.on(\"wheel\", function (event) {\n",
              "        event = event.originalEvent;\n",
              "        event['data'] = 'scroll'\n",
              "        if (event.deltaY < 0) {\n",
              "            event.step = 1;\n",
              "        } else {\n",
              "            event.step = -1;\n",
              "        }\n",
              "        mouse_event_fn(event);\n",
              "    });\n",
              "\n",
              "    canvas_div.append(canvas);\n",
              "    canvas_div.append(rubberband);\n",
              "\n",
              "    this.rubberband = rubberband;\n",
              "    this.rubberband_canvas = rubberband[0];\n",
              "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
              "    this.rubberband_context.strokeStyle = \"#000000\";\n",
              "\n",
              "    this._resize_canvas = function(width, height) {\n",
              "        // Keep the size of the canvas, canvas container, and rubber band\n",
              "        // canvas in synch.\n",
              "        canvas_div.css('width', width)\n",
              "        canvas_div.css('height', height)\n",
              "\n",
              "        canvas.attr('width', width * mpl.ratio);\n",
              "        canvas.attr('height', height * mpl.ratio);\n",
              "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
              "\n",
              "        rubberband.attr('width', width);\n",
              "        rubberband.attr('height', height);\n",
              "    }\n",
              "\n",
              "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
              "    // upon first draw.\n",
              "    this._resize_canvas(600, 600);\n",
              "\n",
              "    // Disable right mouse context menu.\n",
              "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
              "        return false;\n",
              "    });\n",
              "\n",
              "    function set_focus () {\n",
              "        canvas.focus();\n",
              "        canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    window.setTimeout(set_focus, 100);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            // put a spacer in here.\n",
              "            continue;\n",
              "        }\n",
              "        var button = $('<button/>');\n",
              "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
              "                        'ui-button-icon-only');\n",
              "        button.attr('role', 'button');\n",
              "        button.attr('aria-disabled', 'false');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "\n",
              "        var icon_img = $('<span/>');\n",
              "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
              "        icon_img.addClass(image);\n",
              "        icon_img.addClass('ui-corner-all');\n",
              "\n",
              "        var tooltip_span = $('<span/>');\n",
              "        tooltip_span.addClass('ui-button-text');\n",
              "        tooltip_span.html(tooltip);\n",
              "\n",
              "        button.append(icon_img);\n",
              "        button.append(tooltip_span);\n",
              "\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    var fmt_picker_span = $('<span/>');\n",
              "\n",
              "    var fmt_picker = $('<select/>');\n",
              "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
              "    fmt_picker_span.append(fmt_picker);\n",
              "    nav_element.append(fmt_picker_span);\n",
              "    this.format_dropdown = fmt_picker[0];\n",
              "\n",
              "    for (var ind in mpl.extensions) {\n",
              "        var fmt = mpl.extensions[ind];\n",
              "        var option = $(\n",
              "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
              "        fmt_picker.append(option);\n",
              "    }\n",
              "\n",
              "    // Add hover states to the ui-buttons\n",
              "    $( \".ui-button\" ).hover(\n",
              "        function() { $(this).addClass(\"ui-state-hover\");},\n",
              "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
              "    );\n",
              "\n",
              "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
              "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
              "    // which will in turn request a refresh of the image.\n",
              "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_message = function(type, properties) {\n",
              "    properties['type'] = type;\n",
              "    properties['figure_id'] = this.id;\n",
              "    this.ws.send(JSON.stringify(properties));\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_draw_message = function() {\n",
              "    if (!this.waiting) {\n",
              "        this.waiting = true;\n",
              "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
              "    }\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    var format_dropdown = fig.format_dropdown;\n",
              "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
              "    fig.ondownload(fig, format);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
              "    var size = msg['size'];\n",
              "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
              "        fig._resize_canvas(size[0], size[1]);\n",
              "        fig.send_message(\"refresh\", {});\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
              "    var x0 = msg['x0'] / mpl.ratio;\n",
              "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
              "    var x1 = msg['x1'] / mpl.ratio;\n",
              "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
              "    x0 = Math.floor(x0) + 0.5;\n",
              "    y0 = Math.floor(y0) + 0.5;\n",
              "    x1 = Math.floor(x1) + 0.5;\n",
              "    y1 = Math.floor(y1) + 0.5;\n",
              "    var min_x = Math.min(x0, x1);\n",
              "    var min_y = Math.min(y0, y1);\n",
              "    var width = Math.abs(x1 - x0);\n",
              "    var height = Math.abs(y1 - y0);\n",
              "\n",
              "    fig.rubberband_context.clearRect(\n",
              "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
              "\n",
              "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
              "    // Updates the figure title.\n",
              "    fig.header.textContent = msg['label'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
              "    var cursor = msg['cursor'];\n",
              "    switch(cursor)\n",
              "    {\n",
              "    case 0:\n",
              "        cursor = 'pointer';\n",
              "        break;\n",
              "    case 1:\n",
              "        cursor = 'default';\n",
              "        break;\n",
              "    case 2:\n",
              "        cursor = 'crosshair';\n",
              "        break;\n",
              "    case 3:\n",
              "        cursor = 'move';\n",
              "        break;\n",
              "    }\n",
              "    fig.rubberband_canvas.style.cursor = cursor;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
              "    fig.message.textContent = msg['message'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
              "    // Request the server to send over a new figure.\n",
              "    fig.send_draw_message();\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
              "    fig.image_mode = msg['mode'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Called whenever the canvas gets updated.\n",
              "    this.send_message(\"ack\", {});\n",
              "}\n",
              "\n",
              "// A function to construct a web socket function for onmessage handling.\n",
              "// Called in the figure constructor.\n",
              "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
              "    return function socket_on_message(evt) {\n",
              "        if (evt.data instanceof Blob) {\n",
              "            /* FIXME: We get \"Resource interpreted as Image but\n",
              "             * transferred with MIME type text/plain:\" errors on\n",
              "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
              "             * to be part of the websocket stream */\n",
              "            evt.data.type = \"image/png\";\n",
              "\n",
              "            /* Free the memory for the previous frames */\n",
              "            if (fig.imageObj.src) {\n",
              "                (window.URL || window.webkitURL).revokeObjectURL(\n",
              "                    fig.imageObj.src);\n",
              "            }\n",
              "\n",
              "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
              "                evt.data);\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
              "            fig.imageObj.src = evt.data;\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        var msg = JSON.parse(evt.data);\n",
              "        var msg_type = msg['type'];\n",
              "\n",
              "        // Call the  \"handle_{type}\" callback, which takes\n",
              "        // the figure and JSON message as its only arguments.\n",
              "        try {\n",
              "            var callback = fig[\"handle_\" + msg_type];\n",
              "        } catch (e) {\n",
              "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        if (callback) {\n",
              "            try {\n",
              "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
              "                callback(fig, msg);\n",
              "            } catch (e) {\n",
              "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
              "            }\n",
              "        }\n",
              "    };\n",
              "}\n",
              "\n",
              "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
              "mpl.findpos = function(e) {\n",
              "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
              "    var targ;\n",
              "    if (!e)\n",
              "        e = window.event;\n",
              "    if (e.target)\n",
              "        targ = e.target;\n",
              "    else if (e.srcElement)\n",
              "        targ = e.srcElement;\n",
              "    if (targ.nodeType == 3) // defeat Safari bug\n",
              "        targ = targ.parentNode;\n",
              "\n",
              "    // jQuery normalizes the pageX and pageY\n",
              "    // pageX,Y are the mouse positions relative to the document\n",
              "    // offset() returns the position of the element relative to the document\n",
              "    var x = e.pageX - $(targ).offset().left;\n",
              "    var y = e.pageY - $(targ).offset().top;\n",
              "\n",
              "    return {\"x\": x, \"y\": y};\n",
              "};\n",
              "\n",
              "/*\n",
              " * return a copy of an object with only non-object keys\n",
              " * we need this to avoid circular references\n",
              " * http://stackoverflow.com/a/24161582/3208463\n",
              " */\n",
              "function simpleKeys (original) {\n",
              "  return Object.keys(original).reduce(function (obj, key) {\n",
              "    if (typeof original[key] !== 'object')\n",
              "        obj[key] = original[key]\n",
              "    return obj;\n",
              "  }, {});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.mouse_event = function(event, name) {\n",
              "    var canvas_pos = mpl.findpos(event)\n",
              "\n",
              "    if (name === 'button_press')\n",
              "    {\n",
              "        this.canvas.focus();\n",
              "        this.canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    var x = canvas_pos.x * mpl.ratio;\n",
              "    var y = canvas_pos.y * mpl.ratio;\n",
              "\n",
              "    this.send_message(name, {x: x, y: y, button: event.button,\n",
              "                             step: event.step,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "\n",
              "    /* This prevents the web browser from automatically changing to\n",
              "     * the text insertion cursor when the button is pressed.  We want\n",
              "     * to control all of the cursor setting manually through the\n",
              "     * 'cursor' event from matplotlib */\n",
              "    event.preventDefault();\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    // Handle any extra behaviour associated with a key event\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.key_event = function(event, name) {\n",
              "\n",
              "    // Prevent repeat events\n",
              "    if (name == 'key_press')\n",
              "    {\n",
              "        if (event.which === this._key)\n",
              "            return;\n",
              "        else\n",
              "            this._key = event.which;\n",
              "    }\n",
              "    if (name == 'key_release')\n",
              "        this._key = null;\n",
              "\n",
              "    var value = '';\n",
              "    if (event.ctrlKey && event.which != 17)\n",
              "        value += \"ctrl+\";\n",
              "    if (event.altKey && event.which != 18)\n",
              "        value += \"alt+\";\n",
              "    if (event.shiftKey && event.which != 16)\n",
              "        value += \"shift+\";\n",
              "\n",
              "    value += 'k';\n",
              "    value += event.which.toString();\n",
              "\n",
              "    this._key_event_extra(event, name);\n",
              "\n",
              "    this.send_message(name, {key: value,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
              "    if (name == 'download') {\n",
              "        this.handle_save(this, null);\n",
              "    } else {\n",
              "        this.send_message(\"toolbar_button\", {name: name});\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
              "    this.message.textContent = tooltip;\n",
              "};\n",
              "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
              "\n",
              "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
              "\n",
              "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
              "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
              "    // object with the appropriate methods. Currently this is a non binary\n",
              "    // socket, so there is still some room for performance tuning.\n",
              "    var ws = {};\n",
              "\n",
              "    ws.close = function() {\n",
              "        comm.close()\n",
              "    };\n",
              "    ws.send = function(m) {\n",
              "        //console.log('sending', m);\n",
              "        comm.send(m);\n",
              "    };\n",
              "    // Register the callback with on_msg.\n",
              "    comm.on_msg(function(msg) {\n",
              "        //console.log('receiving', msg['content']['data'], msg);\n",
              "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
              "        ws.onmessage(msg['content']['data'])\n",
              "    });\n",
              "    return ws;\n",
              "}\n",
              "\n",
              "mpl.mpl_figure_comm = function(comm, msg) {\n",
              "    // This is the function which gets called when the mpl process\n",
              "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
              "\n",
              "    var id = msg.content.data.id;\n",
              "    // Get hold of the div created by the display call when the Comm\n",
              "    // socket was opened in Python.\n",
              "    var element = $(\"#\" + id);\n",
              "    var ws_proxy = comm_websocket_adapter(comm)\n",
              "\n",
              "    function ondownload(figure, format) {\n",
              "        window.open(figure.imageObj.src);\n",
              "    }\n",
              "\n",
              "    var fig = new mpl.figure(id, ws_proxy,\n",
              "                           ondownload,\n",
              "                           element.get(0));\n",
              "\n",
              "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
              "    // web socket which is closed, not our websocket->open comm proxy.\n",
              "    ws_proxy.onopen();\n",
              "\n",
              "    fig.parent_element = element.get(0);\n",
              "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
              "    if (!fig.cell_info) {\n",
              "        console.error(\"Failed to find cell for figure\", id, fig);\n",
              "        return;\n",
              "    }\n",
              "\n",
              "    var output_index = fig.cell_info[2]\n",
              "    var cell = fig.cell_info[0];\n",
              "\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
              "    var width = fig.canvas.width/mpl.ratio\n",
              "    fig.root.unbind('remove')\n",
              "\n",
              "    // Update the output cell to use the data from the current canvas.\n",
              "    fig.push_to_output();\n",
              "    var dataURL = fig.canvas.toDataURL();\n",
              "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
              "    // the notebook keyboard shortcuts fail.\n",
              "    IPython.keyboard_manager.enable()\n",
              "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
              "    fig.close_ws(fig, msg);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.close_ws = function(fig, msg){\n",
              "    fig.send_message('closing', msg);\n",
              "    // fig.ws.close()\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
              "    // Turn the data on the canvas into data in the output cell.\n",
              "    var width = this.canvas.width/mpl.ratio\n",
              "    var dataURL = this.canvas.toDataURL();\n",
              "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Tell IPython that the notebook contents must change.\n",
              "    IPython.notebook.set_dirty(true);\n",
              "    this.send_message(\"ack\", {});\n",
              "    var fig = this;\n",
              "    // Wait a second, then push the new image to the DOM so\n",
              "    // that it is saved nicely (might be nice to debounce this).\n",
              "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items){\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) { continue; };\n",
              "\n",
              "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    // Add the status bar.\n",
              "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "\n",
              "    // Add the close button to the window.\n",
              "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
              "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
              "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
              "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
              "    buttongrp.append(button);\n",
              "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
              "    titlebar.prepend(buttongrp);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(el){\n",
              "    var fig = this\n",
              "    el.on(\"remove\", function(){\n",
              "\tfig.close_ws(fig, {});\n",
              "    });\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(el){\n",
              "    // this is important to make the div 'focusable\n",
              "    el.attr('tabindex', 0)\n",
              "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
              "    // off when our div gets focus\n",
              "\n",
              "    // location in version 3\n",
              "    if (IPython.notebook.keyboard_manager) {\n",
              "        IPython.notebook.keyboard_manager.register_events(el);\n",
              "    }\n",
              "    else {\n",
              "        // location in version 2\n",
              "        IPython.keyboard_manager.register_events(el);\n",
              "    }\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    var manager = IPython.notebook.keyboard_manager;\n",
              "    if (!manager)\n",
              "        manager = IPython.keyboard_manager;\n",
              "\n",
              "    // Check for shift+enter\n",
              "    if (event.shiftKey && event.which == 13) {\n",
              "        this.canvas_div.blur();\n",
              "        // select the cell after this one\n",
              "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
              "        IPython.notebook.select(index + 1);\n",
              "    }\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    fig.ondownload(fig, null);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.find_output_cell = function(html_output) {\n",
              "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
              "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
              "    // IPython event is triggered only after the cells have been serialised, which for\n",
              "    // our purposes (turning an active figure into a static one), is too late.\n",
              "    var cells = IPython.notebook.get_cells();\n",
              "    var ncells = cells.length;\n",
              "    for (var i=0; i<ncells; i++) {\n",
              "        var cell = cells[i];\n",
              "        if (cell.cell_type === 'code'){\n",
              "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
              "                var data = cell.output_area.outputs[j];\n",
              "                if (data.data) {\n",
              "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
              "                    data = data.data;\n",
              "                }\n",
              "                if (data['text/html'] == html_output) {\n",
              "                    return [cell, data, j];\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "}\n",
              "\n",
              "// Register the function which deals with the matplotlib target/channel.\n",
              "// The kernel may be null if the page has been refreshed.\n",
              "if (IPython.notebook.kernel != null) {\n",
              "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
              "}\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id='5a6197ed-3ed5-42fa-99b8-34a4bcd0ef24'></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "progress:[XXXXXXX///                                        ]28s/255s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-907e56d5e212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# 学習開始\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# フィッティングアニメーション作成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-a6d225b53bc8>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self, epoch, n_batch, threshold, show_error, show_train_error, **kwds)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mrand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_batch\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlap_time\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-a6d225b53bc8>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0my_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mO_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mswitch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0my_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-a9b794471b35>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gpu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdact\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMW8q4N9ztU2"
      },
      "source": [
        "## CNN実験編\n",
        "データ処理はいくつか種類がありますが、代表的な二つを紹介しておきます。\n",
        "\n",
        "[目次へ戻る](#目次)\n",
        "\n",
        "### 標準化\n",
        "標準化はデータを平均0、標準偏差1になるようにデータを縮尺する処理のことです。\n",
        "\\begin{align}\n",
        "  \\hat{x} = \\cfrac{x - \\mu}{\\sigma}\n",
        "\\end{align}\n",
        "ここでの$\\mu$は平均値、$\\sigma$は標準偏差です。\n",
        "\n",
        "### 正規化\n",
        "正規化はデータに何らかの処理を行いデータ値の大きさを0~1などに収める処理のことです。\n",
        "大抵は最大値と最小値を用いて\n",
        "\\begin{align}\n",
        "  \\hat{x} = \\cfrac{x - x_{min}}{x_{max} - x_{min}}\n",
        "\\end{align}\n",
        "とします。\n",
        "\n",
        "正規化は異常値の影響を大きく受けてしまうため一般には標準化を用いることが多いですが、画像データなどの異常値があり得ないデータの場合は正規化を行うことがあります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5JhdRBcztU3"
      },
      "source": [
        "### KerasのMNISTデータ処理\n",
        "使いたい方を実行してください。\n",
        "KerasのMNISTデータセットは実行時間が非常に大きくなるため注意してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgPfkLaAztU3",
        "outputId": "40b312e9-28b7-47cf-a08c-ef8a4b7abf73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "#from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tqdm\n",
        "\n",
        "\n",
        "# データセット取得\n",
        "n_class=10\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "C, B, I_h, I_w = 1, *x_train.shape\n",
        "B_test = x_test.shape[0]\n",
        "\n",
        "# 標準化\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train.reshape(B, -1)).reshape(B, C, I_h, I_w)\n",
        "x_test = sc.fit_transform(x_test.reshape(B_test, -1)).reshape(B_test, C, I_h, I_w)\n",
        "\n",
        "# one-hotラベルへの変換\n",
        "def to_one_hot(data, n_class):\n",
        "    vec = np.zeros((len(data), n_class))\n",
        "    for i in range(len(data)):\n",
        "        vec[i, data[i]] = 1.\n",
        "    return vec\n",
        "t_train = to_one_hot(y_train, n_class)\n",
        "t_test = to_one_hot(y_test, n_class)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6COy6gwztU6"
      },
      "source": [
        "### scikit-learnのMNISTデータ処理\n",
        "scikit-learnの方はデータ量がすごく削減されているため実行時間はかなり短くて済みます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AqHoYbaztU6"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tqdm\n",
        "\n",
        "\n",
        "# データセット取得\n",
        "n_class=10\n",
        "C, I_h, I_w = 1, 8, 8\n",
        "digits = datasets.load_digits()\n",
        "x = digits.data\n",
        "t = digits.target\n",
        "n_data = len(x)\n",
        "\n",
        "# 標準化\n",
        "sc = StandardScaler()\n",
        "x = sc.fit_transform(x).reshape(n_data, I_h, I_w)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, t, test_size=0.2, shuffle=True)\n",
        "\n",
        "# one-hotラベルへの変換\n",
        "def to_one_hot(data, n_class):\n",
        "    vec = np.zeros((len(data), n_class))\n",
        "    for i in range(len(data)):\n",
        "        vec[i, data[i]] = 1.\n",
        "    return vec\n",
        "t_train = to_one_hot(y_train, n_class)\n",
        "t_test = to_one_hot(y_test, n_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbJB97dpztU8"
      },
      "source": [
        "### CNN実験コード本体"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmDlAcJ6EfF5",
        "outputId": "5260d507-e9b9-4b79-e644-d705e5de740d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "!free -h\n",
        "!nvidia-smi\n",
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            12G        1.5G        6.1G        972K        5.1G         11G\n",
            "Swap:            0B          0B          0B\n",
            "Sun Sep 27 23:57:00 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "zncp7_nVztU9",
        "outputId": "376304e0-2e7f-43ac-d893-b8e053030364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "%matplotlib inline\n",
        "# 畳み込み層と出力層を作成\n",
        "M, F_h, F_w = 10, 3, 3\n",
        "lm = LayerManager((x_train, x_test), (t_train, t_test), mode=\"gpu\")\n",
        "#lm.append(name=\"c\", I_shape=(C, I_h, I_w), F_shape=(M, F_h, F_w), pad=1,\n",
        "#          wb_width=0.1, opt=\"AdaDelta\", opt_dic={\"eta\": 1e-2})\n",
        "lm.append(name=\"c\", I_shape=(C, I_h, I_w), F_shape=(M, F_h, F_w), pad=1)\n",
        "lm.append(name=\"p\", I_shape=lm[-1].O_shape, pool=2)\n",
        "#lm.append(name=\"m\", n=100, wb_width=0.1,\n",
        "#          opt=\"AdaDelta\", opt_dic={\"eta\": 1e-2})\n",
        "lm.append(name=\"m\", n=100)\n",
        "#lm.append(name=\"o\", n=n_class, act=\"softmax\", err_func=\"Cross\", wb_width=0.1,\n",
        "#          opt=\"AdaDelta\", opt_dic={\"eta\": 1e-2})\n",
        "lm.append(name=\"o\", n=n_class, act=\"softmax\", err_func=\"Cross\")\n",
        "\n",
        "# 学習させる\n",
        "epoch = 5\n",
        "threshold = 1e-8\n",
        "n_batch = 8\n",
        "lm.training(epoch, threshold=threshold, n_batch=n_batch, show_train_error=True)\n",
        "\n",
        "# 予測する\n",
        "print(\"training dataset\")\n",
        "_ = lm.predict(x=lm.x_train, y=lm.y_train)\n",
        "print(\"test dataset\")\n",
        "if lm.mode == \"cpu\":\n",
        "    y_pred = lm.predict()\n",
        "elif lm.mode == \"gpu\":\n",
        "    y_pred = lm.predict().get()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "progress:[XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX]483s/514s\n",
            "training dataset\n",
            "correct: [5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7]\n",
            "predict: [5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7]\n",
            "accuracy rate: 98.58 % (59148/60000)\n",
            "test dataset\n",
            "correct: [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5]\n",
            "predict: [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5]\n",
            "accuracy rate: 97.58 % (9758/10000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEjCAYAAAAsbUY2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU9d3+8fdnJvtCQsIawo4gW9jdQAVRAQH3rVbFamvtZu3veWy1WrVWa1tbW3F91GJrtWLdBbSiQMQFVPYdAUG2AJF9C2T5/v6YCUxCMkxCkpNM7td1zcXMOWfO3Dk6ufM958wZc84hIiJSGZ/XAUREpH5TUYiISFgqChERCUtFISIiYakoREQkLBWFiIiEpaIQaQDM7Gkz+02Y+b82s+fqMpM0HqbPUYhExszWAd93zn3ocY6hwIvOuWwvc0jjoRGFRB0ziyn32Mws4v/Xq7p8Za8rEi1UFNIgmFmWmb1uZvlmttbMbg2Zd5+ZvWZmL5rZHuAGM8s1swfN7FPgANDJzM4wsy/NbHfw3zNC1nHM8uVe/19AO2CSme0zs1+aWQczc2Z2k5mtB6YHl33VzLYEX2emmfUMWc8/zOwJM5tiZnvN7HMz6xycZ2b2VzPbZmZ7zGyxmfUKed4DZpYMvAdkBXPsC26b+8zsxZDXudDMlprZruDP1j1k3joz+18zWxTM+IqZJdTcfy2JNioKqfeCf91PAhYCbYDhwG1mNiJksYuA14B04KXgtOuAm4FUYC8wBRgPZAKPAFPMLDNkHaHLfxOawTl3HbAeGOucS3HO/Slk9tlAd6A0z3vASUALYF5InlJXA78FmgKrgQeD088HzgK6AmnAlcD2cjn2A6OAzcEcKc65zeW2V1fgZeA2oDnwLoGCiwtZ7EpgJNARyAFuQKQSKgppCAYBzZ1z9zvnDjvnvgaeJfALt9Qs59xbzrkS59zB4LR/OOeWOueKCPwSXuWc+5dzrsg59zKwAhgbso4jyzvnCquQ7z7n3P7S13XOTXDO7XXOHQLuA/qYWVrI8m86574I5noJ6BucXkigpE4mcPxwuXMurwo5Sl0FTHHOfRD8Of4MJAJnhCwz3jm32Tm3g0AJ961gPSKAikIahvYEdrXsKr0BvwZahiyzoYLnhU7LotwoIfi4zXHWEYkjzzMzv5n9wczWBHeDrQvOahay/JaQ+weAFADn3HTgceAJYJuZPWNmTaqRp8zP6pwrCWYM/VkrzCBSERWFNAQbgLXOufSQW6pz7oKQZSo6fS902mYChROqHbDpOOuobH2VTb+GwG6wcwnsPuoQnG7HWXdgRc6Nd84NAHoQ2AV1exVylCrzs5qZAW0p+7OKRExFIQ3BF8BeM/uVmSUG/2rvZWaDqrCOd4GuZnaNmcWY2VUEfhlPrsI6tlLuIHcFUoFDBI4tJAG/j3TlZjbIzE41s1hgP1AAlFSSI7Pc7qxQ/wFGm9nw4Lr+J5jps0iziIRSUUi955wrBsYQ2I++FvgWeI7AX+yRrmN7cB3/Q+CX+C+BMc65b6sQ5SHg7uDur/+tZJkXCOz22QQsA2ZXYf1NCBx72Rlcx3bg4fILOedWEDhY/XUwS1a5+SuBa4HHCGyrsQQOwh+uQhaRI/SBOxERCUsjChERCUtFISIiYakoREQkLBWFiIiEpaIQEZGwVBQiIhKWikJERMJSUYiISFgqChERCUtFISIiYakoREQkLBWFiIiEpaIQEZGwVBQiIhKWikJERMJSUYiISFgqChERCSvG6wC1oVmzZq5Dhw7Veu7+/ftJTk6u2UA1QLmqRrmqRrmqJhpzzZ0791vnXPMKZzrnou42YMAAV10zZsyo9nNrk3JVjXJVjXJVTTTmAua4Sn6nateTiIiEpaIQEZGwVBQiIhJWVB7MFpHoYGasXbuWgoICr6OUkZaWxvLly72OcYxIciUkJJCdnU1sbGzE61VRiEi9lZycTGpqKh06dMDMvI5zxN69e0lNTfU6xjGOl8s5x/bt29m4cSMdO3aMeL3a9SQi9Zbf7yczM7NelURDZmZkZmZWeYSmohCRek0lUbOqsz1VFEHFxcXMevMJdqye7XUUEZF6RUUR5DNoueQZBm58nqLDh7yOIyL1wK5du3jyySer9dwLLriAXbt21XAib6gogsznZ89pv6IdW1gw+Smv44hIPRCuKIqKisI+99133yU9Pb1G85R/zeNlqOpyldFZTyH6DL+aZZ/9mbaLH6No9A+JiU/0OpKIeOiOO+5gzZo19O3bl/POO4/Ro0fzm9/8htTUVFavXs1XX33FxRdfzIYNGygoKODnP/85N998MwAdOnRgzpw57Nu3j1GjRjFkyBA+++wz2rRpw9tvv01iYtnfL/n5+dxyyy2sX78egL/97W8MHjyY++67jzVr1vD111/Trl07unXrVubxQw89xI033si3335LRkYGL7zwAu3ateOGG24gISGB+fPnM3jwYB555JFqbwcVRQjz+VjW9rtcvv5+FrzzKH2vuMPrSCIS9NtJS1m2eU+NrrNHVhPuHduz0vl/+MMfWLJkCQsWLAAgNzeXefPmMXv2bHr37g3AhAkTyMjI4ODBgwwaNIjLLruMzMzMMutZtWoVL7/8Ms8++yxXXnklr7/+Otdee22ZZX7+85/zi1/8giFDhrB+/XpGjBhx5DMRy5Yt45NPPiExMZH77ruvzOOxY8cybtw4xo0bx5NPPsmtt97KW2+9BcDGjRv57LPP8Pv9J7SdVBTlZHbox8LNvWm39EmKxvyEmMT6d660iHjnlFNOIfTq1OPHj+fNN98EYMOGDaxateqYoujYsSN9+/YFYMCAAaxbt+6Y9X744YcsW7bsyOM9e/awb98+AC688MIyI5DQx7NmzeKNN94A4Oqrr+aee+45stwVV1xxwiUBKopjmM9HwZm/JmPGd1j89p/pffVvvY4kIhD2L/+6FHoZ79zcXD788ENmzZpFUlISQ4cOrfAzCvHx8Ufu+/1+Dh48eMwyJSUlzJ49m4SEhLCvWdHjSLKeCB3MrsApZ43ii5iBtF/xHEX7d3odR0Q8kpqayt69eyudv3v3bpo2bUpSUhIrVqxg9uzqn15//vnn89hjjx15XLq763jOOOMMJk6cCMB//vMfzjzzzGpnqIyKogJmRuHZd9GEfax6+w9exxERj2RmZjJ48GB69erF7bfffsz8kSNHUlRURPfu3bnjjjs47bTTqv1a48ePZ86cOeTk5NCjRw+efvrpiJ732GOP8fzzz5OTk8PEiRN59NFHq52hUpV9UUVDvAFjgWe6dOlS7S/vKP3ij+LiEjfzgVFu/70tXOHurdVeX02Jxi9KqU3KVTX1Nde8efO8jlChPXv2eB2hQpHmWrZs2THTaCxfXOScm+ScuzktLe2E1+XzGQy7i3h3iLVvP1gD6UREGqaoKoqaNvi0M5geN4x2a/5N0a5NXscREfGEiiIMn8+IG34nPlfM+rfu9zqOiIgnVBTHceYpg3g//nzarnuN4h3rvI4jIlLnVBTH4fMZSefeQYkzNr55r9dxRETqnIoiAkMH9mFKwgVkb3iH4m0rvY4jIlKnVBQR8PmMtHN/SYGLZcvb9xz/CSISFU7kMuMQuLDfgQMHajCRN1QUERo2oCdvJ1xEm03/pXjzQq/jiEgd8LooqntZ8eLi4mq/ZkVUFBHy+Yxm5/8vu10S+RpViDQKoZcZL/1k9sMPP8zZZ59NTk4O994bOG65f/9+Ro8eTZ8+fejVqxevvPIK48ePZ/PmzQwbNoxhw4Yds+65c+dy9tlnM2DAAEaMGEFeXh4AQ4cO5bbbbmPgwIE8+uijxzyeNm0a/fr1o3fv3tx4440cOhT4orUOHTpwzz330L9/f1599dUa3Q66KGAVnNuvK/+cehnf2/ovitd/gb/dKV5HEmk83rsDtiyu2XW26g2jKr9MT/nLjE+dOpVVq1aRm5tLSkoKF154ITNnziQ/P5+srCymTJkCBK4BlZaWxiOPPMKMGTNo1qxZmfUWFhbys5/9jLfffpvmzZvzyiuvcNdddzFhwgQADh8+zJw5cwCYNGnSkccFBQWcdNJJTJs2ja5du3L99dfz1FNPcdtttwGQkZHBvHnzanYboRFFlfh8RusRt5HvmrDjnbu9jiMidWzq1KlMnTqVIUOG0L9/f1asWMGqVavo3bs3H3zwAb/61a/4+OOPOd7VIVauXMmSJUs477zz6Nu3Lw888AAbN248Mv+qq64qs3zp45UrV9KxY0e6du0KwLhx45g5c+aR5S699NKa+lHL0Iiiis7v25n/m3oFP/r27xSvycXfeajXkUQahzB/+dcV5xx33nkn11xzDampZb+rZt68ebz77rvcfffdDB8+vMz3QlS0np49ezJr1qwK53t9WfHyNKKoIp/PaD/iZ2x2GeyefA8ELkYoIlGo/GXGR4wYwYQJE458odCmTZvYtm0bmzdvJikpiWuvvZbbb7/9yO6fyi5T3q1bN/Lz848URWFhIUuXLj1unm7durFu3TpWr14NwL/+9S/OPvvsE/45j0cjimoY2acDj75/Nb/Y+STFK/+L/+RRXkcSkVoQepnxUaNG8fDDD7N8+XLOPfdcfD4fKSkpvPjii6xevZrbb78dn89HbGwsTz31FAA333wzI0eOJCsrixkzZhxZb1xcHK+99hq33noru3fvpqioiNtuu42ePcN/OVNCQgLPP/88V1xxBUVFRQwaNIhbbrmlVrcBEF2XGS+9DRgwIKJL7VYk0sstT56/zq39zUlu1yOnOFdcXO3Xi1R9vQy0clWNclWNLjNeNbrMeD0zKqcdE5OuIW33CkqWvuV1HBGRWqOiqCafz+g58ia+KmnDgffvh+LIPggjItLQqChOwAU52fw7+TpS9q2lZOFEr+OIRCWnE0ZqVHW2p4riBPh9Rv8R17OopCMFH/4eig57HUkkqhQXF7N9+3aVRQ1xzrF9+3YSEhKq9Dyd9XSCRudkcffU63nowG8pmfcCvlO+73Ukkaixf/9+9u7dS35+vtdRyigoKKjyL9u6EEmuhIQEsrOzq7ReFcUJ8vuM0867ki/enEjO9D+S0O+7EJvodSyRqOCco2PHjl7HOEZubi79+vXzOsYxaiuXdj3VgDF92vDv5HEkFGyj5ItnvY4jIlKjVBQ1wO8zho24mJnFvSn86BE4dOwnMUVEGioVRQ0Zk5PFxNTriT+8k5JZ1b9+vYhIfaOiqCF+nzHi/NFMLR5A8Sfj4cAOryOJiNQIFUUNGpOTxSup1+Mv2o/7dLzXcUREaoSKogb5fcbY885jUvHpFM9+GvZu9TqSiMgJU1HUsLF9sngt9Tqs+BDu4794HUdE5ISpKGqY32dcet5ZvFp0Fm7OBNi1wetIIiInREVRC8bmZPFWk2spKnG4j/7kdRwRkROioqgFMX4fV513Oi8VDccteAm2r/E6kohItdX7ojCzTmb2dzN7zessVTE2J4tJTb7DYReDm/GQ13FERKqtVovCzCaY2TYzW1Ju+kgzW2lmq83sjnDrcM597Zy7qTZz1oYYv49rzx3E80Xnw5LXYOsyryOJiFRLbY8o/gGMDJ1gZn7gCWAU0AP4jpn1MLPeZja53K1FLeerVRf2yeLdJldygETcjAe8jiMiUi1W29d5N7MOwGTnXK/g49OB+5xzI4KP7wRwzoXdP2NmrznnLg8z/2bgZoCWLVsOmDixel8ktG/fPlJSUqr13Ip8uqmQxGUT+X+xrzG3/5/Z2+SkepGrpihX1ShX1ShX1ZxIrmHDhs11zg2scGZlX6ZdUzegA7Ak5PHlwHMhj68DHg/z/EzgaWANcGckrzlgwICIvmC8IjX9JfOFRcVu1B8nu133ZbuSFy6u9npqOldNUa6qUa6qUa6qOZFcwBxXye/Uen8w2zm33Tl3i3OuszvOqKM+ivH7uHF4Hx4/PAZbMx3Wfep1JBGRKvGiKDYBbUMeZwenRa2L+2aRm3YR2y0DN/13oK91FJEGxIui+BI4ycw6mlkccDXwjgc56kyM38cPh/fir4cvwtbPgjXTvI4kIhKx2j499mVgFtDNzDaa2U3OuSLgp8D7wHLgP865pbWZoz64uG8Ws9IuYIuvJW76AxpViEiDUatF4Zz7jnOutXMu1jmX7Zz7e3D6u865rsHjDg/W1OuZ2Vgze2b37t01tcoaE+P3ccs53fnzoYuxzfNhxWSvI4mIRKTeH8yuCufcJOfczWlpaV5HqdAl/dowL+18NviycdMfhJJiryOJiBxXVBVFfRcYVXTjjwWXYPnLYcnrXkcSETkuFUUdu6RfGxanDeNrf0fcjN9DcaHXkUREwlJR1LFYv4+fnNOVBw9eiu1cCwte8jqSiEhYKgoPXNK/DV+lDWZFTLfA91UUFngdSUSkUlFVFPX5rKdQsX4fPzunK/cfuAzbswnmPu91JBGRSkVVUdT3s55CXdK/DRvSB7EoNifw3dqH93sdSUSkQlFVFA1JrN/HT4d14b59l2L78+Hzp72OJCJSIRWFhy7tn8229D58GTsI9+mjcHCX15FERI6hovBQ6aji3n2XYAW7YdbjXkcSETmGisJjl/bPZk96dz6JG4Kb/RTs/9brSCIiZagoPBYX4+Mnw7pw796LoPAAfPJXryOJiJQRVUXRUE6PLe+y/tkUpHVhetw5uC+ehT2bvY4kInJEVBVFQzo9NlRcjI+fntOFe/eMwbkSmPlnryOJiBwRVUXRkF3WPxuX1p73487Hzfsn7FzndSQREUBFUW8cOVax6wJKzA+5f/Q6kogIoKKoVy4fkE1sehaT4kbjFk2E/JVeRxIRUVHUJ3ExPn48rDO/3Xk+xf5EmPF7ryOJiKgo6psrBrQlMa0Fb8RdCMvegryFXkcSkUZORVHPBEYVXXhgxzkUxjaB6TX2leIiItUSVUXRUD9HUd4VA7NJScvklbhLYNX7sOELryOJSCMWVUXRUD9HUV58jJ8fD+vCg9vP5nBCJky73+tIItKIRVVRRJMrBmaTnpbOi7GXw7qPSd+pYxUi4g0VRT1VOqr4Y/7pHEpqRaevXwTnvI4lIo2QiqIeu3JgNhlpTZjgv5Ime7+Cr/7rdSQRaYRUFPVYfIyfHw/tzF/yB7I7rhVMfwBKSryOJSKNjIqinrtyUFuaNUnhSXc5bF0Cy970OpKINDIqinoucKyiM8/uPY39aScFPq1dXOR1LBFpRFQUDcCVA9uSFu/nSbsKtq+GRRO9jiQijUhUFUW0fOCuvIRYP6M7xfLElu7szegduLJs0SGvY4lIIxFVRREtH7iryFnZMbRsksB4dxXsXg/zXvA6kog0ElFVFNEszm/8eGgXns3ryO4Wg2Dmw3D4gNexRKQRUFE0IFcNakvLJgn8pegq2LcVvnzO60gi0gioKBqQhFg/Pzq7My9szmJn1pnwyV+hYI/XsUQkyqkoGpirT2lHi9R4/njoCji4A2Y/5XUkEYlyKooGJiHWz4+GdmbipmZsb3s+zHocDuzwOpaIRDEVRQP0neCo4vcHL4VDe+HTR72OJCJRTEXRAJWOKl7f2IT8jhfC5/8He7d6HUtEopSKooH6zintaJ4az+/2XQTFh+Hjv3gdSUSi1HGLwgLa1kUYiVzpGVDvbEhga+fLYe7zsGuD17FEJAodtyiccw54tw6ySBVdc2pgVHH/ntGBCR/90dtAIhKVIt31NM/MBtVqkhoQrdd6qkxCrJ9bzu7MlPUx5J10DSz4N2xf43UsEYkykRbFqcAsM1tjZovMbLGZLarNYNURzdd6qsx3g6OK3+4cCTHxgcuQi4jUoEiLYgTQGTgHGAuMCf4rHisdVfz3mxI2d7selrwOW5d6HUtEokhEReGc+wZIJ1AOY4H04DSpB757ajuapcRz7/bhEJ8K0x/0OpKIRJGIisLMfg68BLQI3l40s5/VZjCJXGBU0YkP1hayoftNsHIKbJzrdSwRiRKR7nq6CTjVOXePc+4e4DTgB7UXS6rqu6e2D4wqtp4FSZkw/XdeRxKRKBFpURhQHPK4ODhN6onEuMCoYvrag6zv8UP4egas+8TrWCISBSItiueBz83sPjO7D5gN/L3WUkm1BEYVcdyTdxqktoZpvwPnvI4lIg1cJJ/M9hEohu8BO4K37znn/lbL2aSKEuP8/PCszuSu2ce6nj+GDbNh9TSvY4lIAxfJJ7NLgCecc/Occ+ODt/l1kE2q4buntaNZShz3bugP6e0Cxyo0qhCRExDprqdpZnaZmem4RD2XFBfDD8/qzEdrdrO2162QtwCWT/I6log0YJEWxQ+BV4FDZrbHzPaamb6Ds5767mntyEyO4951PaFZV5jxIJQUH/+JIiIViPQYxUjnnM85F+eca+KcS3XONamDfFINSXEx/PDsTsxcvZM1vW6F/BWw+DWvY4lIAxXpMYrH6yCL1KBrT2tPZnIcv13dBVr1htzfQ3Gh17FEpAHSMYoolRQXw81ndWLm6h2s6nUb7FwH81/0OpaINEBVOUbxH+r5MYrGdpnx47nu9PZkJMdx/4psyB4EMx+GwgKvY4lIAxNpUaQBNwAPBI9N9ATOq61Q1dUYLzMeTumo4uPV2/mq5y9gzyaYM8HrWCLSwERaFE8QuL7Td4KP96LjFg3CdacFRhUPLG8OHc8KfLf2oX1exxKRBiTiLy5yzv0EKABwzu0E4motldSY5PjgsYqv8lnR8zY48C18/rTXsUSkAYm0KArNzA84ADNrDpTUWiqpUaWjiocWpULXkfDZeDi4y+tYItJARFoU44E3gRZm9iDwCaDv3GwgkuNj+MGZnfjoq3yWd/8ZFOyGzx7zOpaINBCRfsPdS8AvgYeAPOBi59yrtRlMatb1p7enaVIsf5gfBz0vgdlPwb58r2OJSAMQ6YgC59wK59wTzrnHnXPLazOU1Lzk+Bh+cFZgVLGs20+g6CB88levY4lIAxBxUUjDd/3pHWiaFMuf5jro8x348jnYvcnrWCJSz6koGpGU+Bi+f2Ynclfms6zrj8CVBD6EJyIShoqikRl3RgfSk2J5+PODMGAczP8X7FjrdSwRqcdUFI1MSvAMqBkr81nS+WbwxcBHf/Q6lojUYyqKRqh0VPGXWbvhlB/Aolcgf6XXsUSknlJRNEJlRhUdb4TY5MCXG4mIVEBF0Uhdf3p70hJjeeTT7XD6j2HZ25C30OtYIlIPqSgaqdSEWH5wZkemr9jGkvbXQkI6TH/A61giUg+pKBqxcWd0IC0xlr/O3ApDboNVU2H9517HEpF6RkXRiKUmxPL9IR2ZtmIbi9tcBcktYPrvwDmvo4lIPaKiaOTGDQ6MKh6duQnO+l9Y9zF8net1LBGpR1QUjVyT4Kjiw+XbWNLqEmiSrVGFiJShohDGDe5Ak4QY/pb7DZz9S9g0F1a+53UsEaknoqoozGysmT2ze/dur6M0KE0SYvn+mZ0Co4oWoyGjU+BzFSX6bioRibKicM5Ncs7dnJaW5nWUBueG0lHF9HUw9NewdQksfcPrWCJSD0RVUUj1NUmI5aYhnfhw+VaWZJwLLXpA7kNQXOR1NBHxmIpCjigdVTw6fQ0Muwu2r4aFL3sdS0Q8pqKQI9ISY7lxSEc+WLaVJalDIKt/4MqyRYe8jiYiHlJRSBnfG9yR1IQYxk9fDefcDbs3wNx/eh1LRDykopAy0hJjuWlIR6Yu28qShAHQfjB8/Gc4fMDraCLiERWFHKPsqOI3sG8rfPms17FExCMqCjlGWmIsNw4OjCqWxvaALufCJ3+Fgj1eRxMRD6gopEI3DgmOKqatChyrOLgTZj/pdSwR8YCKQiqUlhjL9wZ35P2lW1lGZ+g+Fj57HA7s8DqaiNQxFYVU6qbBHUmND44qht0Fh/fBp3/zOpaI1DEVhVQqLSmW7w3uwH+XbmF5cRvIuRI+fwb2bvE6mojUIRWFhHXjkJBRxdA7oKQQPv6L17FEpA6pKCSs9KQ4vje4A+8t2cLyQ82g37Uw53nYtd7raCJSR1QUclw3DulISumo4qxfgvkCl/YQkUZBRSHHFTqqWHEwFQbdBAtehm9Xex1NROqAikIiclPoqGLILyAmHnJ/73UsEakDKgqJSHpSHDec0YF3F29hxb4EOPUWWPI6yfvWeR1NRGqZikIiVjqqeGzaahh8K8Sn0WfhvfDKdfDxI7Bmuj6QJxKFYrwOIA1H0+Q4xp3RnidmrOHW4SfR7aoX2PXen2ixZREsf+foguntIasvtO579N+kDO+Ci8gJUVFIlXx/SCf+8ek6xk9bxRPfHcqyntBi6NDASCJvIeQtgM0LAv8ue/voE1UeIg2WikKqpGlyHDcM7sCTuWtYuWXv0RlJGdB5WOBWqnx5bJ5fcXlk9QsUR+s+Kg+RekhFIVV2ZFQxfRVXZIVZ8LjlMT9QIMeUR7+yo4/EprX2s4jI8akopMoCxyo68NRHazgjNbFqTw5XHpvnHy2QZW+FvGCHsrusVB4idUpFIdXy/TM78c/P1vHEwgKKMtcxqlcrWjRJqN7KKi2PkOMd4cojq19gt5XKQ6RWqCikWjKS43j4ij78/u353PvOUu6btJRTOmQwJqc1I3u1pnlq/Im9QFIGdD4ncCsVcXn0I32nwUGVh0hNUFFItV3QuzVJ21fSpvsApizOY/KiPH7z9lLufWcpp3bMZHROa0b2akWzlBMsjVIRlcc8WPYWfQEW3hMoj9KD5Vl9NfIQqQYVhZywk1qmclvLVH4+/CS+2rqPKYs2M3lRHne/tYR73l7C6Z0zGZOTxYierchIjqvZF6+kPBb+9wX6NC8JjDo2zYWlbx6d37RjuVN1VR4i4agopMaYGd1apdKtVTd+cV5XVmzZy5RFeUxetJk731jM3W8t4YzOmYzJac35PVrRtKZLo1RSBjsz+sKZQ49OOzLyCJ5pFbY8So95pNdOPpEGRkUhtcLM6N66Cd1bN+F/zu/Ksrw9wdLI41evL+auN5cwuEszRue0ZkSPVqQlxdZuoMp2Wx050ypMeYR+zkPlIY2QikJqnZnRMyuNnllp3D6iG0s27WHy4s1MWZTHL19bxF3+xQzp0owxOVmc26MlaYm1XBqlkjKgy/DArVT58thYUXmEfHWeJhYAABD5SURBVM5D5SGNQL0vCjO7GBgNNAH+7pyb6nEkOQFmRu/sNHpnp3HHyJNZtHE3UxbnMWVRHv/z6kLi/D7O6hoYaZzbvSWpCXVUGqUqKo/92wPFUbrrauMcWPrG0fkZncp+zkPlIVGmVovCzCYAY4BtzrleIdNHAo8CfuA559wfKluHc+4t4C0zawr8GVBRRAkzo0/bdPq0TefOUSezYMMuJi/K493FeXy4fBtxMT7O7tqcMTmtGd69JSnxHv1dk5xZeXmUjj7ClUfpMY+EtLrL7By4ksCtpBhcccj9ctNLikk4uBV2fA0lwXnB6Ufvl58eZn2h08usI5L1lZRZR8dvvgE+B38s+OMC34NSet8fF3K/omlh7vtiwKzu/ns0cLX9zvsH8DjwQukEM/MDTwDnARuBL83sHQKl8VC559/onNsWvH938HkShcyMfu2a0q9dU+66oDvzN+w8UhofLNtKfIyPod2aMzoni+EntyDZq9IoVWl5zD96qm4F5ZHjmsA3aZX8Yq34l2XFv1gr+4Ub8twqOA3g8xrZMjXHfLRzDta72ln/cYul8vnd8rfD3reqV1Ll78fEV76MLxZ83n8bRK2+25xzM82sQ7nJpwCrnXNfA5jZROAi59xDBEYfZZiZAX8A3nPOzavNvFI/+HzGgPYZDGifwW9G92Du+p1MWZTHlMV5vL90KwmxPs45uQWje2cx7OTmJMXVkz2oyZnQ5dzArVS58vBv+gqKEsDnD9wsNvivD8wfct8XvO8vd98qnu7zVbCOcNPLvs6Klas4uXuP479+xK8T+rzK1lduevn1AR/l5jL0rDOh+HDwVljD94P/Fh2qfNmiQ3Bob5lpTQ/shb2Lyy5bUlg7/1/5YiIunpzde2HIBxBTs2cUmnO11NalLxAoismlu57M7HJgpHPu+8HH1wGnOud+WsnzbwXGAV8CC5xzT1ey3M3AzQAtW7YcMHHixGrl3bdvHykpKdV6bm1SLihxjlU7S/h8SxFzthSx5zDE+aFvcz+DWsWQ09xPvN/qPFdVKFfVNKhczmGuCF9JUQX/Fpb7t7L5FT2/MOLprugQCwf+KVC2VTRs2LC5zrmBFc2rJ3+KVc45Nx4YH8FyzwDPAAwcONANHTq0Wq+Xm5tLdZ9bm5Qr4Bzgh0BxiePztduZsiiP/y7ZwhdbDpEU52d495aM7t2auOLl2l5VoFxV09hyeVEUm4C2IY+zg9NEIub3GWd0bsYZnZvx2wt78vnaHUxelMd/l+QxaeFmEvwwMn8+o3OyOPOkZiTEVv0vLBEJ8KIovgROMrOOBAriauAaD3JIlIjx+xjcpRmDuzTj/ot6Mvvr7Tz7/jxyv8rnrQWbSY2P4bweLRmd05ohJzUjPkalIVIVtX167MvAUKCZmW0E7nXO/d3Mfgq8T+BMpwnOuaW1mUMaj1i/jzNPak7xpngGn3kWn67+limL8nh/6RbemL+J1IQYzu/RijE5rRncpRlxMd6fUSJS39X2WU/fqWT6u8C7Nf16ZjYWGNulS5eaXrU0QLF+H0O7tWBotxY8eElvPl39LZMX5TF12RZen7eRtMRYRvRsyeicLM7onEmsX6UhUpF6fzC7Kpxzk4BJAwcO/IHXWaR+iYvxMezkFgw7uQWHinrxyarASOPdxVv4z5yNpCfFMrJnK0bntOb0TpnEqDREjoiqohCJRHxM4Oyo4d1bUlBYzMyv8pmyOHAQfOKXG8hIjmNEz8DuqVM7Zqg0pNFTUUijlhDr5/yerTi/ZysKCovJXRkojbcXbOLlL9aTmRzHyF6tGJOTxSkdM/D7dNkHaXxUFCJBCbF+RvZqxcherTh4uJjclduYvDiPN+Zt4qXP19MsJZ4LerdidO/WDOyg0pDGQ0UhUoHEOD+jerdmVO/WHDhcxPQV25iyKI9XvtzAC7O+oUVqPBf0bs3onNYMaNcUn0pDolhUFYXOepLakBQXw5icLMbkZLH/UBHTVmxjyqLN/PuL9fzjs3W0apLAqN6B3VP92qarNCTqRFVR6KwnqW3J8TFc2CeLC/tksbegkOkrtjFpYR4vzV7P85+uIyst4chIo2/bdEyXspYoEFVFIVKXUhNiuahvGy7q24Y9BYV8uGwrUxbl8c9Z63juk7W0SU9kdE5rRvduTU52mkpDGiwVhUgNaJIQy6X9s7m0fza7DxbywbKtTFm0mQmfrOWZmV+T3TRQGmkHium84wCt0xJ02q00GCoKkRqWlhjL5QOyuXxANrsOHGZqcKTx94/XUlTi+NOXM/D7jNZpCWQ3TSS7aVK5fxNp1URFIvWHikKkFqUnxXHlwLZcObAtO/cf5t/vfUxmu5PYuPMgG3ceYOPOg3yy6lu27i0g9KthVCRSn6goROpI0+Q4ejbzM/SUdsfMO1RUTN6ugjIFEmmRtG2aVKZEsjOSaNUkQZ/zkBoTVUWh02OloYqP8dOhWTIdmiVXOD+0SDbsPBBSJgeZuSqfrXsOlVk+xme0Tk8gO/3Y0YiKRKoqqopCp8dKtIqkSDbvKjhmNBJpkRTtPsyOJhuPFEpLFYmEiKqiEGms4mP8dGyWTMdKiqSgsJi83UeLZMOOo4Xy0Vf5bNtbyJurFx5ZPsZnZKUnHh2FlDtOoiJpXFQUIo1AQmz4Ipk6bQZdcgYdGYWEjkxyV+azbe+xI5KKiqRtRuDfFqkqkmiiohAR4vxGp+YpdGqeUuH8gsJiNu86eEyRbNh5gBkr88kvVySx/pAiKT1OknG0UFQkDYuKQkSOKyHWf9wi2bSr/GgkcH/6ym1VKpK2TZNokRqva2bVIyoKETlhCbF+OjdPoXMNFkmb9ESSKeD9HYvIbppEu4wk2mYE/m2aFKtLotQhFYWI1LpIiqSiEln2TQFTl25l+/7DZZZPjvPTNlgcbZsm0S4j8UiJZDdNIjHOXxc/VqMRVUWhz1GINEwJsX66tEihS4uyRZKbm8vQoUPZf6iIDTsPsGHHQdbvOMCG4O2b7fv5ZNW3HCwsLvO8ZinxZcqjbdNgqWQk0jotUcdHqiiqikKfoxCJTsnxMZzcqgknt2pyzDznHN/uOxwsktJboFDmfrOTSQs3UxLyqfYYn9Em+In20vJoG7JrS7u1jhVVRSEijY+Z0Tw1nuap8fRv1/SY+YXFJeTtKgiMRIJlErh/kPeXbmFHud1aKfExR071DYxGEmmXmXTkUimNcbeWikJEolqs30e7zCTaZSZVOH/foSI27jzA+u2B8gjdrfXxqnwKCkvKLN88NZ40fyFvbZl/5BhJtO/WUlGISKOWEsFurfU7AtfXKh2NLP56M1+u28k75XZrlZ72W3pQvW1G4pFjJO0ykkhvoLu1VBQiIpUI3a01oP3R3Vq5uTsZOnQohcUlbN51kA07Ah8+DD3Q/v7myndrhZ7qW3qMpD7v1lJRiIhUU6zfR/vMZNpnVnxplH2Hio4Ux/odR6+ztfbb/cysZLdW6XGRMqf/Znp7xV8VhYhILUmJj6F76yZ0b13xbq38fYfYsONgyDGSQKFUtlurTXrp9bSOjkZKd22lJ8XW2s+hohAR8YCZ0SI1gRapCWV2a5UK3a1VesbW+h0H2Bhmt1bTuBLeO72IlPia/dWuohARqYci3a1Velxk486DLF6zgeRaOM4RVUWhT2aLSGNR0W6t3Nz8WjmrKqq+nd05N8k5d3NaWprXUUREokZUFYWIiNQ8FYWIiISlohARkbBUFCIiEpaKQkREwlJRiIhIWCoKEREJy5xzx1+qgTGzfOCbaj69GfBtDcapKcpVNcpVNcpVNdGYq71zrnlFM6KyKE6Emc1xzg30Okd5ylU1ylU1ylU1jS2Xdj2JiEhYKgoREQlLRXGsZ7wOUAnlqhrlqhrlqppGlUvHKEREJCyNKEREJKxGWxRmNtLMVprZajO7o4L58Wb2SnD+52bWoZ7kusHM8s1sQfD2/TrINMHMtpnZkkrmm5mND2ZeZGb9aztThLmGmtnukG11Tx3lamtmM8xsmZktNbOfV7BMnW+zCHPV+TYzswQz+8LMFgZz/baCZer8/Rhhrjp/P4a8tt/M5pvZ5Arm1ez2cs41uhvgB9YAnYA4YCHQo9wyPwaeDt6/GnilnuS6AXi8jrfXWUB/YEkl8y8A3gMMOA34vJ7kGgpM9uD/r9ZA/+D9VOCrCv471vk2izBXnW+z4DZICd6PBT4HTiu3jBfvx0hy1fn7MeS1/x/w74r+e9X09mqsI4pTgNXOua+dc4eBicBF5Za5CPhn8P5rwHCrja+OqnquOuecmwnsCLPIRcALLmA2kG5mretBLk845/Kcc/OC9/cCy4E25Rar820WYa46F9wG+4IPY4O38gdP6/z9GGEuT5hZNjAaeK6SRWp0ezXWomgDbAh5vJFj3zBHlnHOFQG7gcx6kAvgsuDuitfMrG0tZ4pEpLm9cHpw18F7Ztazrl88OOTvR+Cv0VCebrMwucCDbRbcjbIA2AZ84JyrdHvV4fsxklzgzfvxb8AvgZJK5tfo9mqsRdGQTQI6OOdygA84+leDHGsegcsS9AEeA96qyxc3sxTgdeA259yeunztcI6Ty5Nt5pwrds71BbKBU8ysV1287vFEkKvO349mNgbY5pybW9uvVaqxFsUmILT5s4PTKlzGzGKANGC717mcc9udc4eCD58DBtRypkhEsj3rnHNuT+muA+fcu0CsmTWri9c2s1gCv4xfcs69UcEinmyz4+XycpsFX3MXMAMYWW6WF+/H4+by6P04GLjQzNYR2D19jpm9WG6ZGt1ejbUovgROMrOOZhZH4GDPO+WWeQcYF7x/OTDdBY8MeZmr3H7sCwnsZ/baO8D1wTN5TgN2O+fyvA5lZq1K98ua2SkE/n+v9V8uwdf8O7DcOfdIJYvV+TaLJJcX28zMmptZevB+InAesKLcYnX+fowklxfvR+fcnc65bOdcBwK/I6Y7564tt1iNbq+Y6j6xIXPOFZnZT4H3CZxpNME5t9TM7gfmOOfeIfCG+peZrSZwwPTqepLrVjO7ECgK5rqhtnOZ2csEzoZpZmYbgXsJHNjDOfc08C6Bs3hWAweA79V2pghzXQ78yMyKgIPA1XVQ9hD4i+86YHFw/zbAr4F2Idm82GaR5PJim7UG/mlmfgLF9B/n3GSv348R5qrz92NlanN76ZPZIiISVmPd9SQiIhFSUYiISFgqChERCUtFISIiYakoREQkLBWFSD1igau3HnM1UBEvqShERCQsFYVINZjZtcHvKlhgZv8XvHjcPjP7a/C7C6aZWfPgsn3NbHbwwnFvmlnT4PQuZvZh8AJ888ysc3D1KcELzK0ws5fq4KrFImGpKESqyMy6A1cBg4MXjCsGvgskE/hkbE/gIwKfFAd4AfhV8MJxi0OmvwQ8EbwA3xlA6SU8+gG3AT0IfDfJ4Fr/oUTCaJSX8BA5QcMJXPzty+Af+4kELkNdArwSXOZF4A0zSwPSnXMfBaf/E3jVzFKBNs65NwGccwUAwfV94ZzbGHy8AOgAfFL7P5ZIxVQUIlVnwD+dc3eWmWj2m3LLVff6OIdC7hej96l4TLueRKpuGnC5mbUAMLMMM2tP4P10eXCZa4BPnHO7gZ1mdmZw+nXAR8FvmNtoZhcH1xFvZkl1+lOIREh/qYhUkXNumZndDUw1Mx9QCPwE2E/gy23uJrAr6qrgU8YBTweL4GuOXin2OuD/glf9LASuqMMfQyRiunqsSA0xs33OuRSvc4jUNO16EhGRsDSiEBGRsDSiEBGRsFQUIiISlopCRETCUlGIiEhYKgoREQlLRSEiImH9f2L6nM9qRO4cAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuF2Oa7wBU1g",
        "outputId": "1030d20d-c4b9-411c-e8b6-587e0e0f4c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit\n",
        "lm.forward(lm.x_train)\n",
        "error = lm[-1].get_error(lm.y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 957 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn0rykExB2QW",
        "outputId": "4a6e8727-9f9b-4793-cf08-dfb2ee790dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit\n",
        "lm.forward(lm.x_test)\n",
        "error = lm[-1].get_error(lm.y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 160 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCnuVQBuC6Gs"
      },
      "source": [
        "rand_index = np.arange(lm.x_train.get().shape[0])\n",
        "np.random.shuffle(rand_index)\n",
        "rand = rand_index[0 : n_batch]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0CnurT7B2aX",
        "outputId": "70c99f15-be7c-4b0d-96c4-613edf12ed49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit\n",
        "lm.forward(lm.x_train[rand])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 loops, best of 3: 1.32 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6OhnpRHB2XO",
        "outputId": "630b5f1b-79f9-4912-e163-603afbf7ad38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit\n",
        "lm.backward(lm.y_train[rand])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 10.3 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Anj0up-Pam"
      },
      "source": [
        "err3 = lm[3].backward(lm.y_train[rand])\n",
        "err2 = lm[2].backward(err3)\n",
        "err2 = err2.reshape(n_batch, *lm[1].O_shape)\n",
        "err1 = lm[1].backward(err2)\n",
        "err0 = lm[0].backward(err1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9rR35FPF2mU",
        "outputId": "ec4d2074-91df-4fa3-f010-17f6dc4dc9ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%%timeit\n",
        "err3 = lm[3].backward(lm.y_train[rand])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 7.33 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 3: 152 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RMEeo5RF2Qi",
        "outputId": "a8ec7782-2a1a-4a20-bff6-fa214099556d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%%timeit\n",
        "err2 = lm[2].backward(err3)\n",
        "err2 = err2.reshape(n_batch, *lm[1].O_shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 10.29 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1000 loops, best of 3: 224 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jzGXtZKF1Lo",
        "outputId": "e219dfc8-2cb6-4174-ff32-7ca05420e9ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit\n",
        "err1 = lm[1].backward(err2)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 loops, best of 3: 9.72 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQiuuptg8TR4"
      },
      "source": [
        "B, C, O_h, O_w = n_batch, *lm[1].O_shape\n",
        "grad = err2.transpose(0, 2, 3, 1).reshape(-1, 1)\n",
        "grad_x = cp.zeros((grad.size, lm[1].pool*lm[1].pool))\n",
        "grad_x1 = grad_x.copy()\n",
        "grad_x1[:, lm[1].max_index] = grad\n",
        "grad_x2 = grad_x1.reshape(B*O_h*O_w, C*lm[1].pool*lm[1].pool).T"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B79uGypLEc1",
        "outputId": "13dccf11-4c53-4d97-ecab-62122ffb67be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%%timeit\n",
        "grad = err2.transpose(0, 2, 3, 1).reshape(-1, 1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 19.62 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100000 loops, best of 3: 17.1 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1dB52PoLLWl",
        "outputId": "e0d90b92-e184-49b3-d743-d0ca5ba871b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%%timeit\n",
        "grad_x = cp.zeros((grad.size, lm[1].pool*lm[1].pool))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 33.51 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100000 loops, best of 3: 7.89 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4ALzA-_MnF6",
        "outputId": "42812314-fc67-4937-a8ec-3b245d193622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit\n",
        "grad_x1[:, lm[1].max_index] = grad"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 loops, best of 3: 9.5 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0fIgP93Mvhz",
        "outputId": "4752958b-e2b1-4812-bcf3-6cb028e3d541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%%timeit\n",
        "grad_x2 = grad_x1.reshape(B*O_h*O_w, C*lm[1].pool*lm[1].pool).T"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 19.13 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1000000 loops, best of 3: 1.86 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9WCivH4M2WU",
        "outputId": "1104a8b0-a771-4f14-b1d8-8fb6e4af5230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%%timeit\n",
        "grad_x3 = lm[1].col2im(grad_x2, (n_batch, *lm[1].I_shape), lm[1].O_shape,\n",
        "                       stride=lm[1].pool, pad=lm[1].pad_state)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 9.34 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 3: 112 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_IOLQUxFVtF",
        "outputId": "90e187e4-0ce5-41e7-d9c8-898d1ba1a9e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%%timeit\n",
        "err0 = lm[0].backward(err1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 11.07 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1000 loops, best of 3: 442 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXyRcLeJDE9P",
        "outputId": "8c67b04b-2743-4d0a-f240-9d85e3dffc64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit\n",
        "lm.update()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 loops, best of 3: 1.64 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfPNG1EgztU_",
        "outputId": "3ee37dbb-057d-4098-d645-b47c9dced7f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        }
      },
      "source": [
        "# 間違ったデータを表示する\n",
        "col=4\n",
        "dpi=125\n",
        "if lm.mode == \"cpu\":\n",
        "    x = lm.x_test*sc.var_.reshape(1, I_h, I_w)**0.5 + sc.mean_.reshape(1, I_h, I_w)\n",
        "    y = lm.pred_func(lm.y_test)\n",
        "elif lm.mode == \"gpu\":\n",
        "    x = (lm.x_test.get()*sc.var_.reshape(1, I_h, I_w)**0.5 \n",
        "         + sc.mean_.reshape(1, I_h, I_w))\n",
        "    y = lm.pred_func(lm.y_test.get())\n",
        "fail_index = np.where(y_pred != y)[0]\n",
        "print(\"incorrect index:\", fail_index)\n",
        "if fail_index.size:\n",
        "    n_image = min(16, fail_index.size)\n",
        "    np.random.shuffle(fail_index)\n",
        "    row = int(np.ceil(n_image/col))\n",
        "    if row * dpi >= 2 ** 16:\n",
        "        row = int(np.ceil((2 ** 16 // dpi - 1)/col))\n",
        "    fig, ax = plt.subplots(row, col, figsize=(col, row + 1), dpi=dpi, facecolor=\"w\")\n",
        "    if row != 1:\n",
        "        for i, f in enumerate(fail_index):\n",
        "            ax[i // col, i % col].imshow(x[f].reshape(I_h, I_w), interpolation='nearest', cmap='gray')\n",
        "            ax[i // col, i % col].tick_params(labelbottom=False, labelleft=False, labelright=False, labeltop=False)\n",
        "            ax[i // col, i % col].set_title(str(y[f]) + \" => \" + str(y_pred[f]))\n",
        "            if i >= row * col - 1:\n",
        "                break\n",
        "    else:\n",
        "        for i, f in enumerate(fail_index):\n",
        "            ax[i % col].imshow(x[f].reshape(I_h, I_w), interpolation='nearest', cmap='gray')\n",
        "            ax[i % col].tick_params(labelbottom=False, labelleft=False, labelright=False, labeltop=False)\n",
        "            ax[i % col].set_title(str(y[f]) + ' => ' + str(y_pred[f]))\n",
        "            if i >= row * col - 1:\n",
        "                break\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(\"incorrect.png\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "incorrect index: [  18  115  149  151  199  217  259  321  340  352  381  445  495  582\n",
            "  583  619  684  691  707  720  726  740  877  882  924  947  951  965\n",
            " 1003 1014 1039 1044 1145 1182 1192 1194 1226 1242 1247 1260 1289 1299\n",
            " 1319 1364 1378 1393 1522 1530 1553 1670 1678 1681 1709 1717 1790 1828\n",
            " 1871 1880 1901 1968 2016 2024 2044 2052 2053 2070 2098 2109 2129 2130\n",
            " 2135 2182 2215 2224 2272 2291 2293 2338 2387 2414 2426 2437 2447 2488\n",
            " 2514 2525 2526 2648 2654 2771 2780 2810 2836 2882 2896 2930 2939 2953\n",
            " 2975 2995 3005 3021 3060 3117 3289 3333 3336 3388 3451 3474 3503 3520\n",
            " 3558 3597 3599 3681 3702 3718 3742 3751 3757 3776 3796 3811 3838 3853\n",
            " 3893 3902 3906 4027 4063 4078 4176 4193 4199 4201 4211 4248 4269 4271\n",
            " 4289 4294 4344 4359 4382 4433 4497 4536 4547 4548 4639 4723 4807 4838\n",
            " 4839 4860 4874 4876 4880 4966 5125 5331 5457 5600 5642 5676 5734 5749\n",
            " 5887 5888 5891 5926 5936 5937 5955 5973 5982 6011 6045 6059 6071 6081\n",
            " 6091 6166 6168 6303 6555 6557 6558 6574 6584 6597 6603 6621 6625 6651\n",
            " 6706 6741 6755 6765 7054 7074 7216 7249 7430 7511 7619 7849 7921 8020\n",
            " 8059 8061 8062 8094 8311 8325 8353 8362 8520 8522 8527 8849 9009 9015\n",
            " 9024 9422 9427 9500 9587 9634 9642 9664 9679 9698 9700 9729 9745 9770\n",
            " 9782 9792 9793 9839]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 500x625 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stoYXTX3ztVB",
        "outputId": "c9c6528f-a53a-4782-a4ca-4e627b9fb47f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        " \n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        " \n",
        "batch_size = 8\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        " \n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        " \n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        " \n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        " \n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        " \n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        " \n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        " \n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        " \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/12\n",
            "7500/7500 [==============================] - 23s 3ms/step - loss: 2.1325 - accuracy: 0.3639 - val_loss: 1.8402 - val_accuracy: 0.7326\n",
            "Epoch 2/12\n",
            "7500/7500 [==============================] - 22s 3ms/step - loss: 1.5273 - accuracy: 0.6181 - val_loss: 1.0368 - val_accuracy: 0.8182\n",
            "Epoch 3/12\n",
            "7500/7500 [==============================] - 23s 3ms/step - loss: 1.0152 - accuracy: 0.7061 - val_loss: 0.6610 - val_accuracy: 0.8493\n",
            "Epoch 4/12\n",
            "7500/7500 [==============================] - 22s 3ms/step - loss: 0.8056 - accuracy: 0.7541 - val_loss: 0.5264 - val_accuracy: 0.8694\n",
            "Epoch 5/12\n",
            "7500/7500 [==============================] - 21s 3ms/step - loss: 0.7074 - accuracy: 0.7808 - val_loss: 0.4593 - val_accuracy: 0.8789\n",
            "Epoch 6/12\n",
            "7500/7500 [==============================] - 21s 3ms/step - loss: 0.6441 - accuracy: 0.8008 - val_loss: 0.4179 - val_accuracy: 0.8892\n",
            "Epoch 7/12\n",
            "7500/7500 [==============================] - 23s 3ms/step - loss: 0.6047 - accuracy: 0.8130 - val_loss: 0.3898 - val_accuracy: 0.8938\n",
            "Epoch 8/12\n",
            "7500/7500 [==============================] - 22s 3ms/step - loss: 0.5726 - accuracy: 0.8236 - val_loss: 0.3675 - val_accuracy: 0.8995\n",
            "Epoch 9/12\n",
            "7500/7500 [==============================] - 22s 3ms/step - loss: 0.5463 - accuracy: 0.8315 - val_loss: 0.3507 - val_accuracy: 0.9022\n",
            "Epoch 10/12\n",
            "7500/7500 [==============================] - 21s 3ms/step - loss: 0.5234 - accuracy: 0.8408 - val_loss: 0.3357 - val_accuracy: 0.9063\n",
            "Epoch 11/12\n",
            "7500/7500 [==============================] - 21s 3ms/step - loss: 0.5042 - accuracy: 0.8448 - val_loss: 0.3242 - val_accuracy: 0.9095\n",
            "Epoch 12/12\n",
            "7500/7500 [==============================] - 21s 3ms/step - loss: 0.4862 - accuracy: 0.8531 - val_loss: 0.3127 - val_accuracy: 0.9118\n",
            "Test loss: 0.31266412138938904\n",
            "Test accuracy: 0.9118000268936157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoEkAuBM94p5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}